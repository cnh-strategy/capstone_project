import numpy as np
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# --------------------------------------------
# 1ï¸âƒ£ ê¸°ë³¸ íšŒê·€ ì§€í‘œ
# --------------------------------------------
def evaluate_regression(y_true, y_pred):
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100
    return {"RMSE": rmse, "MAE": mae, "R2": r2, "MAPE(%)": mape}

# --------------------------------------------
# 2ï¸âƒ£ Agentë³„ ì˜ˆì¸¡ ì„±ëŠ¥ ë¹„êµ
# --------------------------------------------

# --------------------------------------------
# 3ï¸âƒ£ Î² ì‹ ë¢°ë„ ê³„ì‚°
# --------------------------------------------
def compute_beta_confidences(errors_dict):
    """MSE ê¸°ë°˜ ì‹ ë¢°ë„ ê°€ì¤‘ì¹˜ ê³„ì‚°"""
    betas = {k: np.exp(-v) for k, v in errors_dict.items()}
    s = sum(betas.values())
    return {k: v / s for k, v in betas.items()}

# --------------------------------------------
# 4ï¸âƒ£ Debate í•©ì˜ ê²°ê³¼ í‰ê°€
# --------------------------------------------
def evaluate_consensus(agents):
    preds = [a.last_pred for a in agents.values() if a.last_pred is not None]
    avg_pred = np.mean(preds)
    std_pred = np.std(preds)
    print(f"\nğŸ§¾ Consensus Result â†’ Mean: {avg_pred:.4f} | Std: {std_pred:.4f}")
    return {"mean": avg_pred, "std": std_pred}
