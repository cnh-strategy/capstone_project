#!/usr/bin/env python3
"""
ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""
import os
import sys
from pathlib import Path
from datetime import date, timedelta

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).resolve().parent
sys.path.insert(0, str(project_root))

print("=" * 80)
print("ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
print("=" * 80)

# 1. í™˜ê²½ë³€ìˆ˜ í™•ì¸
print("\n1ï¸âƒ£ í™˜ê²½ë³€ìˆ˜ í™•ì¸")
eodhd_key = os.getenv("EODHD_API_KEY")
if eodhd_key:
    print(f"âœ… EODHD_API_KEY ì„¤ì •ë¨: {eodhd_key[:10]}...")
else:
    print("âš ï¸  EODHD_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("   .env íŒŒì¼ì— EODHD_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ì„¸ìš”.")

# 2. ëª¨ë“ˆ import í…ŒìŠ¤íŠ¸
print("\n2ï¸âƒ£ ëª¨ë“ˆ import í…ŒìŠ¤íŠ¸")
try:
    from core.sentimental_classes.finbert_utils import (
        load_or_fetch_news,
        get_news_cache_path,
        _normalize_symbol,
    )
    from core.sentimental_classes.eodhd_client import EODHDNewsClient
    print("âœ… ëª¨ë“ˆ import ì„±ê³µ")
except Exception as e:
    print(f"âŒ ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    sys.exit(1)

# 3. EODHD í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸
print("\n3ï¸âƒ£ EODHD í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸")
try:
    if eodhd_key:
        client = EODHDNewsClient(api_key=eodhd_key)
        print("âœ… EODHDNewsClient ì´ˆê¸°í™” ì„±ê³µ")
    else:
        print("âš ï¸  API í‚¤ê°€ ì—†ì–´ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        client = None
except Exception as e:
    print(f"âŒ EODHDNewsClient ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    client = None

# 4. ë‰´ìŠ¤ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
print("\n4ï¸âƒ£ ë‰´ìŠ¤ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸")
ticker = "NVDA"
end_date = date.today() - timedelta(days=1)  # ì–´ì œ
start_date = end_date - timedelta(days=40)  # 40ì¼ ì „

print(f"   í‹°ì»¤: {ticker}")
print(f"   ê¸°ê°„: {start_date} ~ {end_date}")

try:
    # ìºì‹œ ê²½ë¡œ í™•ì¸
    cache_path = get_news_cache_path(ticker, start_date, end_date)
    print(f"   ìºì‹œ ê²½ë¡œ: {cache_path}")
    print(f"   ìºì‹œ ì¡´ì¬ ì—¬ë¶€: {cache_path.exists()}")
    
    if cache_path.exists():
        print(f"   âœ… ìºì‹œ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {cache_path}")
        # íŒŒì¼ í¬ê¸° í™•ì¸
        size = cache_path.stat().st_size
        print(f"   íŒŒì¼ í¬ê¸°: {size:,} bytes")
        
        # íŒŒì¼ ë‚´ìš© ì¼ë¶€ í™•ì¸
        import json
        with open(cache_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        if isinstance(data, list):
            print(f"   ë‰´ìŠ¤ ê°œìˆ˜: {len(data)}ê±´")
            if len(data) > 0:
                print(f"   ì²« ë²ˆì§¸ ë‰´ìŠ¤ ìƒ˜í”Œ:")
                first = data[0]
                print(f"     - ë‚ ì§œ: {first.get('date', 'N/A')}")
                print(f"     - ì œëª©: {first.get('title', 'N/A')[:50]}...")
        else:
            print(f"   âš ï¸  ìºì‹œ íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤ (listê°€ ì•„ë‹˜)")
    else:
        print(f"   âš ï¸  ìºì‹œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì‹¤ì œ ìˆ˜ì§‘ ì‹œë„
        if eodhd_key:
            print(f"\n   ğŸ“¥ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œë„ ì¤‘...")
            news_data = load_or_fetch_news(
                ticker=ticker,
                start=start_date,
                end=end_date,
                api_key=eodhd_key
            )
            
            if news_data and len(news_data) > 0:
                print(f"   âœ… ë‰´ìŠ¤ ìˆ˜ì§‘ ì„±ê³µ: {len(news_data)}ê±´")
                print(f"   âœ… ìºì‹œ íŒŒì¼ ìƒì„±ë¨: {cache_path}")
                
                # ì²« ë²ˆì§¸ ë‰´ìŠ¤ ìƒ˜í”Œ ì¶œë ¥
                if len(news_data) > 0:
                    first = news_data[0]
                    print(f"\n   ì²« ë²ˆì§¸ ë‰´ìŠ¤ ìƒ˜í”Œ:")
                    print(f"     - ë‚ ì§œ: {first.get('date', 'N/A')}")
                    print(f"     - ì œëª©: {first.get('title', 'N/A')[:80]}")
                    print(f"     - ì¶œì²˜: {first.get('source', 'N/A')}")
            else:
                print(f"   âš ï¸  ë‰´ìŠ¤ ìˆ˜ì§‘ ê²°ê³¼: 0ê±´ (ë˜ëŠ” ìˆ˜ì§‘ ì‹¤íŒ¨)")
        else:
            print(f"   âš ï¸  API í‚¤ê°€ ì—†ì–´ ë‰´ìŠ¤ ìˆ˜ì§‘ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            
except Exception as e:
    print(f"   âŒ ë‰´ìŠ¤ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    import traceback
    traceback.print_exc()

# 5. build_finbert_news_features í…ŒìŠ¤íŠ¸
print("\n5ï¸âƒ£ build_finbert_news_features í…ŒìŠ¤íŠ¸")
try:
    from agents.sentimental_agent import build_finbert_news_features
    
    asof_date = date.today().isoformat()
    print(f"   ê¸°ì¤€ ë‚ ì§œ: {asof_date}")
    
    feats = build_finbert_news_features(
        ticker=ticker,
        asof_kst=asof_date,
        base_dir=os.path.join("data", "raw", "news")
    )
    
    print(f"   âœ… í”¼ì²˜ ìƒì„± ì™„ë£Œ")
    print(f"\n   ìƒì„±ëœ í”¼ì²˜:")
    print(f"     - has_news: {feats.get('has_news', False)}")
    print(f"     - 7ì¼ í‰ê·  ê°ì„±: {feats.get('sentiment_summary', {}).get('mean_7d', 0.0):.4f}")
    print(f"     - 7ì¼ ë‰´ìŠ¤ ê°œìˆ˜: {feats.get('news_count', {}).get('count_7d', 0)}")
    print(f"     - 7ì¼ ê°ì„± ë³€ë™ì„±: {feats.get('sentiment_volatility', {}).get('vol_7d', 0.0):.4f}")
    print(f"     - 7ì¼ ì¶”ì„¸: {feats.get('trend_7d', 0.0):.4f}")
    
except Exception as e:
    print(f"   âŒ build_finbert_news_features í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    import traceback
    traceback.print_exc()

# 6. ìºì‹œ ë””ë ‰í† ë¦¬ í™•ì¸
print("\n6ï¸âƒ£ ìºì‹œ ë””ë ‰í† ë¦¬ í™•ì¸")
cache_dir = project_root / "data" / "raw" / "news"
print(f"   ìºì‹œ ë””ë ‰í† ë¦¬: {cache_dir}")
print(f"   ë””ë ‰í† ë¦¬ ì¡´ì¬: {cache_dir.exists()}")

if cache_dir.exists():
    json_files = list(cache_dir.glob("*.json"))
    print(f"   JSON íŒŒì¼ ê°œìˆ˜: {len(json_files)}")
    if len(json_files) > 0:
        print(f"   íŒŒì¼ ëª©ë¡:")
        for f in sorted(json_files)[:5]:  # ìµœëŒ€ 5ê°œë§Œ
            size = f.stat().st_size
            print(f"     - {f.name} ({size:,} bytes)")
        if len(json_files) > 5:
            print(f"     ... ì™¸ {len(json_files) - 5}ê°œ íŒŒì¼")
else:
    print(f"   âš ï¸  ìºì‹œ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

print("\n" + "=" * 80)
print("í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
print("=" * 80)

