# ===============================================================
# BaseAgent: LLM ê¸°ë°˜ ê³µí†µ ì¸í„°í˜ì´ìŠ¤
# ===============================================================
from __future__ import annotations
from dataclasses import dataclass
from typing import Dict, List, Optional, Literal, Tuple
from collections import defaultdict
import os, json, time, requests, yfinance as yf
from datetime import datetime
from dotenv import load_dotenv
from prompts import OPINION_PROMPTS, REBUTTAL_PROMPTS, REVISION_PROMPTS

# -----------------------------
# ë°ì´í„° êµ¬ì¡° ì •ì˜
# -----------------------------
@dataclass
class Target:
    """ì˜ˆì¸¡ ëª©í‘œê°’ + ë¶ˆí™•ì‹¤ì„± ì •ë³´ í¬í•¨
    - next_close: ë‹¤ìŒ ê±°ë˜ì¼ ì¢…ê°€ ì˜ˆì¸¡ì¹˜
    - uncertainty: Monte Carlo Dropout ê¸°ë°˜ ì˜ˆì¸¡ í‘œì¤€í¸ì°¨(Ïƒ)
    - confidence: ëª¨ë¸ ì‹ ë¢°ë„ Î² (ì •ê·œí™”ëœ ì‹ ë¢°ë„; ì„ íƒì )
    """
    next_close: float
    uncertainty: Optional[float] = None
    confidence: Optional[float] = None

@dataclass
class Opinion:
    agent_id: str
    target: Target
    reason: str

@dataclass
class Rebuttal:
    from_agent_id: str
    to_agent_id: str
    stance: Literal["REBUT", "SUPPORT"]
    message: str

@dataclass
class RoundLog:
    round_no: int
    opinions: List[Opinion]
    rebuttals: List[Rebuttal]
    summary: Dict[str, Target]

@dataclass
class StockData:
    sentimental: Dict
    fundamental: Dict
    technical: Dict
    last_price: Optional[float] = None
    currency: Optional[str] = None

# ===============================================================
# BaseAgent í´ë˜ìŠ¤
# ===============================================================
class BaseAgent:
    """LLM ê¸°ë°˜ Multi-Agent Debate ê³µí†µ í´ë˜ìŠ¤"""

    OPENAI_URL = "https://api.openai.com/v1/responses"

    def __init__(
        self,
        agent_id: str,
        model: Optional[str] = None,
        preferred_models: Optional[List[str]] = None,
        temperature: float = 0.2,
        verbose: bool = False,
    ):
        load_dotenv()
        self.agent_id = agent_id
        self.model = model
        self.temperature = temperature
        self.verbose = verbose

        # ëª¨ë¸ í´ë°± ìš°ì„ ìˆœìœ„
        self.preferred_models = preferred_models or ["gpt-5-mini", "gpt-4.1-mini"]
        if model:
            self.preferred_models = [model] + [
                m for m in self.preferred_models if m != model
            ]

        # API í‚¤ ë¡œë“œ
        self.api_key = os.getenv("CAPSTONE_OPENAI_API")
        if not self.api_key:
            raise RuntimeError("í™˜ê²½ë³€ìˆ˜ CAPSTONE_OPENAI_APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # ê³µí†µ í—¤ë”
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }

        # ìƒíƒœê°’
        self.stockdata: Optional[StockData] = None
        self.opinions: List[Opinion] = []
        self.rebuttals: Dict[int, List[Rebuttal]] = defaultdict(list)

        # JSON Schema
        self.schema_obj_opinion = {
            "type": "object",
            "properties": {
                "next_close": {"type": "number"},
                "reason": {"type": "string"},
            },
            "required": ["next_close", "reason"],
            "additionalProperties": False,
        }
        self.schema_obj_rebuttal = {
            "type": "object",
            "properties": {
                "stance": {"type": "string", "enum": ["REBUT", "SUPPORT"]},
                "message": {"type": "string"},
            },
            "required": ["stance", "message"],
            "additionalProperties": False,
        }

    # -----------------------------
    # ê³µí†µ ìœ í‹¸
    # -----------------------------
    def _p(self, msg: str):
        if self.verbose:
            print(f"[{self.agent_id}] {msg}")

    @staticmethod
    def _msg(role: str, text: str) -> dict:
        return {"role": role, "content": [{"type": "input_text", "text": text}]}

    # -----------------------------
    # ë©”ì¸ ì›Œí¬í”Œë¡œ
    # -----------------------------
    def reviewer_draft(self, stock_data, target: Target) -> Opinion:
        """LLMì„ í†µí•´ 'ì´ ì˜ˆì¸¡ì´ íƒ€ë‹¹í•œ ì´ìœ (reason)' ìƒì„±"""
        prompt_set = OPINION_PROMPTS.get(self.agent_id, OPINION_PROMPTS["technical_agent"])

        context = json.dumps({
            "agent_id": self.agent_id,
            "predicted_next_close": round(target.next_close, 3),
            "uncertainty_sigma": round(target.uncertainty or 0.0, 4),
            "confidence_beta": round(target.confidence or 0.0, 4),
            "latest_data": str(stock_data)
        }, ensure_ascii=False, indent=2)

        sys_text = prompt_set["system"]
        user_text = prompt_set["user"].format(context=context)

        parsed = self._ask_with_fallback(
            self._msg("system", sys_text),
            self._msg("user", user_text),
            {"type": "object", "properties": {"reason": {"type": "string"}}, "required": ["reason"]}
        )

        reason = parsed.get("reason", "(ì‚¬ìœ  ìƒì„± ì‹¤íŒ¨)")
        return Opinion(agent_id=self.agent_id, target=target, reason=reason)

    def reviewer_rebut(self, my_opinion: Opinion, other_opinion: Opinion) -> Rebuttal:
        """LLMì„ í†µí•´ ìƒëŒ€ ì˜ê²¬ì— ëŒ€í•œ ë°˜ë°•/ì§€ì§€ ìƒì„±"""
        prompt_set = REBUTTAL_PROMPTS.get(self.agent_id, REBUTTAL_PROMPTS["technical_agent"])

        context = json.dumps({
            "self_agent": my_opinion.agent_id,
            "self_next_close": my_opinion.target.next_close,
            "self_confidence": my_opinion.target.confidence,
            "self_uncertainty": my_opinion.target.uncertainty,
            "self_reason": my_opinion.reason,
            "other_agent": other_opinion.agent_id,
            "other_next_close": other_opinion.target.next_close,
            "other_confidence": other_opinion.target.confidence,
            "other_uncertainty": other_opinion.target.uncertainty,
            "other_reason": other_opinion.reason
        }, ensure_ascii=False, indent=2)

        sys_text = prompt_set["system"]
        user_text = prompt_set["user"].format(context=context)

        parsed = self._ask_with_fallback(
            self._msg("system", sys_text),
            self._msg("user", user_text),
            {
                "type": "object",
                "properties": {
                    "stance": {"type": "string", "enum": ["REBUT", "SUPPORT"]},
                    "message": {"type": "string"}
                },
                "required": ["stance", "message"]
            }
        )

        return Rebuttal(
            from_agent_id=my_opinion.agent_id,
            to_agent_id=other_opinion.agent_id,
            stance=parsed.get("stance", "REBUT"),
            message=parsed.get("message", "(ë°˜ë°•/ì§€ì§€ ì‚¬ìœ  ìƒì„± ì‹¤íŒ¨)")
        )

    def reviewer_revise(self, my_opinion: Opinion, rebuttals: list, others: list) -> Opinion:
        """LLMì„ í†µí•´ ìˆ˜ì •ëœ reasoning ìƒì„± (ìˆ˜ì¹˜ëŠ” ë‚´ë¶€ ì•Œê³ ë¦¬ì¦˜ì´ ë‹´ë‹¹)"""
        prompt_set = REVISION_PROMPTS.get(self.agent_id, REVISION_PROMPTS["technical_agent"])

        context = json.dumps({
            "agent_id": self.agent_id,
            "my_reason": my_opinion.reason,
            "my_confidence": my_opinion.target.confidence,
            "my_uncertainty": my_opinion.target.uncertainty,
            "others": [
                {"agent": o.agent_id, "reason": o.reason, "confidence": o.target.confidence}
                for o in others
            ],
            "rebuttals": [
                {"from": r.from_agent_id, "stance": r.stance, "message": r.message}
                for r in rebuttals
            ],
        }, ensure_ascii=False, indent=2)

        sys_text = prompt_set["system"]
        user_text = prompt_set["user"].format(context=context)

        parsed = self._ask_with_fallback(
            self._msg("system", sys_text),
            self._msg("user", user_text),
            {"type": "object", "properties": {"reason": {"type": "string"}}, "required": ["reason"]}
        )

        revised_reason = parsed.get("reason", "(ìˆ˜ì • ì‚¬ìœ  ìƒì„± ì‹¤íŒ¨)")
        return Opinion(agent_id=self.agent_id, target=my_opinion.target, reason=revised_reason)

    # -----------------------------
    # êµ¬í˜„ í•„ìš” í•¨ìˆ˜ (ì¶”ìƒ)
    # -----------------------------
    def searcher(self, ticker: str) -> StockData:
        """í‹°ì»¤ ê¸°ë°˜ ì›ì²œ ë°ì´í„° ìˆ˜ì§‘ â†’ StockData ë°˜í™˜(êµ¬í˜„ í•„ìš”)"""
        self._p(f"searcher(ticker={ticker})")
        raise NotImplementedError(f"{self.__class__.__name__} must implement searcher method")
    
    def predicter(self, stock_data: StockData) -> Target:
        """ì…ë ¥ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ Target(next_close) ìƒì„±(êµ¬í˜„ í•„ìš”)"""
        self._p("predicter(stock_data)")
        raise NotImplementedError(f"{self.__class__.__name__} must implement predicter method")
    
    def _build_messages_opinion(self, stock_data: StockData, target: Target) -> Tuple[str, str]:
        """LLM(system/user) ë©”ì‹œì§€ ìƒì„±(êµ¬í˜„ í•„ìš”)"""
        raise NotImplementedError(f"{self.__class__.__name__} must implement _build_messages_opinion method")
    
    def _build_messages_rebuttal(self, *args, **kwargs) -> Tuple[str, str]:
        """LLM(system/user) ë©”ì‹œì§€ ìƒì„±(êµ¬í˜„ í•„ìš”)"""
        raise NotImplementedError(f"{self.__class__.__name__} must implement _build_messages_rebuttal method")

    # -----------------------------
    # OpenAI API í˜¸ì¶œ
    # -----------------------------
    def _ask_with_fallback(self, msg_sys: dict, msg_user: dict, schema_obj: dict) -> dict:
        """ëª¨ë¸ í´ë°± í¬í•¨ OpenAI Responses API í˜¸ì¶œ"""
        payload_base = {
            "input": [msg_sys, msg_user],
            "text": {
                "format": {
                    "type": "json_schema",
                    "name": "Response",
                    "strict": True,
                    "schema": schema_obj,
                }
            },
            "temperature": self.temperature,
        }
        last_err = None
        for model in self.preferred_models:
            payload = dict(payload_base, model=model)
            try:
                r = requests.post(self.OPENAI_URL, headers=self.headers, json=payload, timeout=120)
                if r.ok:
                    data = r.json()
                    # 1) output_text ìš°ì„  ì‚¬ìš©
                    if isinstance(data.get("output_text"), str) and data["output_text"].strip():
                        try:
                            return json.loads(data["output_text"])
                        except Exception:
                            return {"reason": data["output_text"]}  # JSON ì‹¤íŒ¨ ì‹œ ì›ë¬¸ í…ìŠ¤íŠ¸ ë³´ì¡´
                    # 2) output ë°°ì—´ì—ì„œ í…ìŠ¤íŠ¸ ëª¨ìœ¼ê¸°
                    out = data.get("output")
                    if isinstance(out, list) and out:
                        texts = []
                        for blk in out:
                            for c in blk.get("content", []):
                                if "text" in c:
                                    texts.append(c["text"])
                        joined = "\n".join(t for t in texts if t)
                        if joined.strip():
                            try:
                                return json.loads(joined)
                            except Exception:
                                return {"reason": joined}
                    # ë¹„ì •ìƒ ì‘ë‹µ
                    return {}
                # 400/404ëŠ” ë‹¤ìŒ ëª¨ë¸ë¡œ í´ë°±
                if r.status_code in (400, 404):
                    last_err = (r.status_code, r.text)
                    continue
                # ê¸°íƒ€ ì—ëŸ¬ëŠ” ì¦‰ì‹œ ì˜ˆì™¸
                r.raise_for_status()
            except Exception as e:
                self._p(f"âš ï¸ ëª¨ë¸ {model} ì‹¤íŒ¨: {e}")
                last_err = str(e)
                continue
        raise RuntimeError(f"ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨. ë§ˆì§€ë§‰ ì˜¤ë¥˜: {last_err}")
    # -----------------------------------------
    # ğŸ”¹ ì¶”ê°€: Monte Carlo Dropout ê¸°ë°˜ ë¶ˆí™•ì‹¤ì„± ì¶”ì •
    # -----------------------------------------
    def predict_with_uncertainty(self, X, n_samples: int = 30):
        """Monte Carlo Dropout ê¸°ë°˜ ì˜ˆì¸¡ + ë¶ˆí™•ì‹¤ì„± ê³„ì‚°"""
        if not hasattr(self, "model"):
            raise AttributeError("BaseAgentì— self.modelì´ ì •ì˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
        
        if isinstance(X, np.ndarray):
            X_tensor = torch.tensor(X, dtype=torch.float32)
        else:
            X_tensor = X.float()

        device = next(self.model.parameters()).device
        X_tensor = X_tensor.to(device)
        self.model.train()  # Dropout í™œì„±í™”

        preds = []
        with torch.no_grad():
            for _ in range(n_samples):
                y_pred = self.model(X_tensor).cpu().numpy().flatten()
                preds.append(y_pred)
        
        preds = np.stack(preds)
        mean_pred = preds.mean(axis=0)
        std_pred = preds.std(axis=0)
        
        # ë¡œì»¬ confidence (Ïƒì˜ ì—­ìˆ˜)
        confidence = 1 / (std_pred + 1e-8)
        
        return mean_pred, std_pred, confidence

    def searcher(self, ticker: str, rebuild: bool = False):
        """
        preprocessing.py ê¸°ë°˜ ë°ì´í„° ê²€ìƒ‰ê¸°
        - CSVê°€ ì—†ì„ ê²½ìš° build_dataset()ìœ¼ë¡œ ìë™ ìƒì„±
        - ë§ˆì§€ë§‰ window ì‹œí€€ìŠ¤ë¥¼ torch.tensorë¡œ ë°˜í™˜
        """
        dataset_path = os.path.join(self.data_dir, f"{ticker}_{self.agent_type}_dataset.csv")

        # ë°ì´í„°ì…‹ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
        if not os.path.exists(dataset_path) or rebuild:
            print(f"âš™ï¸ {ticker} {self.agent_type} dataset not found. Building new dataset...")
            build_dataset(ticker, save_dir=self.data_dir, window_size=self.window_size)

        # CSVì—ì„œ ë°ì´í„°ì…‹ ë¡œë“œ
        X, y, scaler_X, _, feature_cols = load_csv_dataset(
            ticker, agent_type=self.agent_type, save_dir=self.data_dir
        )

        # ê°€ì¥ ìµœê·¼ window ë°ì´í„°ë§Œ ì‚¬ìš©
        X_latest = X[-1:]  # shape: (1, window_size, n_features)
        X_tensor = torch.tensor(X_latest, dtype=torch.float32)

        print(f"âœ… {ticker} {self.agent_type} searcher loaded shape: {X_tensor.shape}")
        return X_tensor

    def predicter(self, X):
        """ì…ë ¥ í…ì„œë¥¼ ë°›ì•„ Monte Carlo Dropout ê¸°ë°˜ ì˜ˆì¸¡ ìˆ˜í–‰"""
        mean_pred, std_pred, confidence = self.predict_with_uncertainty(X)
        return Target(
            next_close=float(mean_pred),
            uncertainty=float(std_pred),
            confidence=float(confidence)
        )
#         a
#     import torch
# import torch.nn as nn
# import numpy as np

# class BaseAgent:
#     def __init__(self, model: nn.Module, feature_cols: list[str], name: str):
#         self.model = model
#         self.feature_cols = feature_cols
#         self.name = name
#         self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
#         self.model.to(self.device)
    
#     # -----------------------------------------
#     # ğŸ”¹ ê¸°ì¡´: ë‹¨ì¼ ì˜ˆì¸¡ (Deterministic)
#     # -----------------------------------------
#     def predict(self, X: np.ndarray) -> np.ndarray:
#         """í‰ê·  ì˜ˆì¸¡(ë“œë¡­ì•„ì›ƒ ë¹„í™œì„±í™” ìƒíƒœ)"""
#         self.model.eval()
#         with torch.no_grad():
#             X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)
#             preds = self.model(X_tensor).cpu().numpy().flatten()
#         return preds

#     # -----------------------------------------
#     # ğŸ”¹ ì¶”ê°€: Monte Carlo Dropout ê¸°ë°˜ ë¶ˆí™•ì‹¤ì„± ì¶”ì •
#     # -----------------------------------------
#     def predict_with_uncertainty(self, X, n_samples: int = 30):
#         """Monte Carlo Dropout ê¸°ë°˜ ì˜ˆì¸¡ + ë¶ˆí™•ì‹¤ì„± ê³„ì‚°"""
#         if not hasattr(self, "model"):
#             raise AttributeError("BaseAgentì— self.modelì´ ì •ì˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
        
#         if isinstance(X, np.ndarray):
#             X_tensor = torch.tensor(X, dtype=torch.float32)
#         else:
#             X_tensor = X.float()

#         device = next(self.model.parameters()).device
#         X_tensor = X_tensor.to(device)
#         self.model.train()  # Dropout í™œì„±í™”

#         preds = []
#         with torch.no_grad():
#             for _ in range(n_samples):
#                 y_pred = self.model(X_tensor).cpu().numpy().flatten()
#                 preds.append(y_pred)
        
#         preds = np.stack(preds)
#         mean_pred = preds.mean(axis=0)
#         std_pred = preds.std(axis=0)
        
#         # ë¡œì»¬ confidence (Ïƒì˜ ì—­ìˆ˜)
#         confidence = 1 / (std_pred + 1e-8)
        
#         return mean_pred, std_pred, confidence