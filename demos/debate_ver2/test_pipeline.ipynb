{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🚀 MCP Hybrid System Pipeline Test\n",
        "\n",
        "이 노트북은 `debate_ver2` 시스템의 전체 파이프라인을 단계별로 테스트할 수 있도록 구성되었습니다.\n",
        "\n",
        "## 📋 테스트 단계\n",
        "1. **Stage 0**: 데이터 수집 및 전처리\n",
        "2. **Stage 1**: 에이전트 사전 훈련\n",
        "3. **Stage 2**: 상호 학습 (Mutual Learning)\n",
        "4. **Stage 3**: 토론 및 합의 (Debate & Consensus)\n",
        "5. **평가**: 최종 성능 평가\n",
        "\n",
        "## 🎯 테스트할 티커\n",
        "- 기본값: **TSLA** (테슬라)\n",
        "- 다른 티커로 변경 가능\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 테스트 설정:\n",
            "   - 티커: TSLA\n",
            "   - 사전 훈련 에포크: 20\n",
            "   - 상호 학습 라운드: 3\n",
            "   - 토론 라운드: 2\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리 import\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 프로젝트 경로 추가\n",
        "sys.path.append('/home/ubuntu/Projects/ml-ai/capstone/demos/debate_ver2')\n",
        "\n",
        "# 설정\n",
        "TICKER = \"TSLA\"  # 테스트할 티커 (변경 가능)\n",
        "PRE_EPOCHS = 20  # 사전 훈련 에포크 수\n",
        "MUTUAL_ROUNDS = 3  # 상호 학습 라운드 수\n",
        "DEBATE_ROUNDS = 2  # 토론 라운드 수\n",
        "\n",
        "print(f\"🎯 테스트 설정:\")\n",
        "print(f\"   - 티커: {TICKER}\")\n",
        "print(f\"   - 사전 훈련 에포크: {PRE_EPOCHS}\")\n",
        "print(f\"   - 상호 학습 라운드: {MUTUAL_ROUNDS}\")\n",
        "print(f\"   - 토론 라운드: {DEBATE_ROUNDS}\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🚀 [MCP Hybrid System Orchestration Start]\n",
            "Ticker: RZLV\n",
            "======================================================================\n",
            "⚠️  [technical] CSV 없음 → build_dataset() 실행\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ RZLV raw data saved to CSV (482 samples)\n",
            "   technical Agent: 10개 피처 사용 - ['Open', 'High', 'Low', 'Close', 'Volume', 'returns', 'sma_5', 'sma_20', 'rsi', 'volume_z']\n",
            "✅ RZLV technical dataset saved to CSV (475 samples, 10 features)\n",
            "   fundamental Agent: 16개 피처 사용 - ['Open', 'High', 'Low', 'Close', 'Volume', 'returns', 'sma_5', 'sma_20', 'rsi', 'volume_z', 'USD_KRW', 'NASDAQ', 'VIX', 'priceEarningsRatio', 'forwardPE', 'priceToBook']\n",
            "✅ RZLV fundamental dataset saved to CSV (475 samples, 16 features)\n",
            "   sentimental Agent: 8개 피처 사용 - ['returns', 'sentiment_mean', 'sentiment_vol', 'Close', 'Volume', 'Open', 'High', 'Low']\n",
            "✅ RZLV sentimental dataset saved to CSV (475 samples, 8 features)\n",
            "✅ RZLV base dataset saved to CSV (475 samples)\n",
            "✅ [technical] 데이터 생성 완료: X=(475, 7, 10), y=(475, 1)\n",
            "⚠️  [fundamental] CSV 없음 → build_dataset() 실행\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ RZLV raw data saved to CSV (482 samples)\n",
            "   technical Agent: 10개 피처 사용 - ['Open', 'High', 'Low', 'Close', 'Volume', 'returns', 'sma_5', 'sma_20', 'rsi', 'volume_z']\n",
            "✅ RZLV technical dataset saved to CSV (475 samples, 10 features)\n",
            "   fundamental Agent: 16개 피처 사용 - ['Open', 'High', 'Low', 'Close', 'Volume', 'returns', 'sma_5', 'sma_20', 'rsi', 'volume_z', 'USD_KRW', 'NASDAQ', 'VIX', 'priceEarningsRatio', 'forwardPE', 'priceToBook']\n",
            "✅ RZLV fundamental dataset saved to CSV (475 samples, 16 features)\n",
            "   sentimental Agent: 8개 피처 사용 - ['returns', 'sentiment_mean', 'sentiment_vol', 'Close', 'Volume', 'Open', 'High', 'Low']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ RZLV sentimental dataset saved to CSV (475 samples, 8 features)\n",
            "✅ RZLV base dataset saved to CSV (475 samples)\n",
            "✅ [fundamental] 데이터 생성 완료: X=(475, 7, 10), y=(475, 1)\n",
            "⚠️  [sentimental] CSV 없음 → build_dataset() 실행\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ RZLV raw data saved to CSV (482 samples)\n",
            "   technical Agent: 10개 피처 사용 - ['Open', 'High', 'Low', 'Close', 'Volume', 'returns', 'sma_5', 'sma_20', 'rsi', 'volume_z']\n",
            "✅ RZLV technical dataset saved to CSV (475 samples, 10 features)\n",
            "   fundamental Agent: 16개 피처 사용 - ['Open', 'High', 'Low', 'Close', 'Volume', 'returns', 'sma_5', 'sma_20', 'rsi', 'volume_z', 'USD_KRW', 'NASDAQ', 'VIX', 'priceEarningsRatio', 'forwardPE', 'priceToBook']\n",
            "✅ RZLV fundamental dataset saved to CSV (475 samples, 16 features)\n",
            "   sentimental Agent: 8개 피처 사용 - ['returns', 'sentiment_mean', 'sentiment_vol', 'Close', 'Volume', 'Open', 'High', 'Low']\n",
            "✅ RZLV sentimental dataset saved to CSV (475 samples, 8 features)\n",
            "✅ RZLV base dataset saved to CSV (475 samples)\n",
            "✅ [sentimental] 데이터 생성 완료: X=(475, 7, 10), y=(475, 1)\n",
            "\n",
            "🧠 Stage 1: Pretraining Agents\n",
            "[13:38:16] 🧠 Pretraining TechnicalAgent\n",
            "  Epoch 005 | Loss: 0.003926\n",
            "  Epoch 010 | Loss: 0.003357\n",
            "  Epoch 015 | Loss: 0.002998\n",
            "  Epoch 020 | Loss: 0.002810\n",
            "✅ TechnicalAgent pretraining finished.\n",
            "\n",
            "💾 TechnicalAgent 모델 저장됨: models/technical_agent.pt\n",
            "[13:38:19] 🧠 Pretraining FundamentalAgent\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "input.size(-1) must be equal to input_size. Expected 16, got 10",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrun\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_mcp_pipeline\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrun_mcp_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRZLV\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/demos/debate_ver2/run.py:51\u001b[0m, in \u001b[0;36mrun_mcp_pipeline\u001b[0;34m(ticker, pre_epochs, mutual_rounds, debate_rounds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# 2️⃣ Stage 1: 사전학습\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🧠 Stage 1: Pretraining Agents\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m \u001b[43mpretrain_all_agents\u001b[49m\u001b[43m(\u001b[49m\u001b[43magents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# 3️⃣ Stage 2: Selective Mutual Learning\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🔁 Stage 2: Selective Mutual Learning\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/demos/debate_ver2/core/training.py:91\u001b[0m, in \u001b[0;36mpretrain_all_agents\u001b[0;34m(agents, datasets, epochs, lr, save_models, model_dir)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, agent \u001b[38;5;129;01min\u001b[39;00m agents\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     90\u001b[0m     X_train, y_train \u001b[38;5;241m=\u001b[39m datasets[name]\n\u001b[0;32m---> 91\u001b[0m     \u001b[43mpretrain_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# 모델 저장\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m save_models:\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/demos/debate_ver2/core/training.py:21\u001b[0m, in \u001b[0;36mpretrain_agent\u001b[0;34m(agent, train_X, train_y, val_X, val_y, epochs, lr, batch_size)\u001b[0m\n\u001b[1;32m     19\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m Xb, yb \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m---> 21\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, yb)\n\u001b[1;32m     23\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/demos/debate_ver2/agents/fundamental_agent.py:26\u001b[0m, in \u001b[0;36mFundamentalAgent.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass for the model\"\"\"\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# x shape: (batch, time, features)\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m lstm_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Use the last time step output\u001b[39;00m\n\u001b[1;32m     28\u001b[0m last_output \u001b[38;5;241m=\u001b[39m lstm_out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1101\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     c_zeros \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m   1094\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m*\u001b[39m num_directions,\n\u001b[1;32m   1095\u001b[0m         max_batch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1098\u001b[0m         device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m   1099\u001b[0m     )\n\u001b[1;32m   1100\u001b[0m     hx \u001b[38;5;241m=\u001b[39m (h_zeros, c_zeros)\n\u001b[0;32m-> 1101\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_batched:\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1002\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_forward_args\u001b[39m(\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[1;32m    999\u001b[0m     hidden: \u001b[38;5;28mtuple\u001b[39m[Tensor, Tensor],  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m     batch_sizes: Optional[Tensor],\n\u001b[1;32m   1001\u001b[0m ):\n\u001b[0;32m-> 1002\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(\n\u001b[1;32m   1004\u001b[0m         hidden[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1005\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m   1006\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1007\u001b[0m     )\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(\n\u001b[1;32m   1009\u001b[0m         hidden[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1012\u001b[0m     )\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:315\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m     )\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    317\u001b[0m     )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 16, got 10"
          ]
        }
      ],
      "source": [
        "from run import run_mcp_pipeline\n",
        "\n",
        "run_mcp_pipeline(\"RZLV\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 Stage 0: 데이터 수집 및 전처리\n",
        "\n",
        "이 단계에서는 주식 데이터를 수집하고 각 에이전트별로 필요한 피처를 생성합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 Stage 0: 데이터 수집 및 전처리 시작...\n",
            "티커: TSLA\n",
            "📁 기존 CSV 파일에서 데이터 로드 시도...\n",
            "📁 CSV 파일이 없어서 새로 생성합니다...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ TSLA raw data saved to CSV (483 samples)\n",
            "   technical Agent: 10개 피처 사용 - ['Open', 'High', 'Low', 'Close', 'Volume', 'returns', 'sma_5', 'sma_20', 'rsi', 'volume_z']\n",
            "✅ TSLA technical dataset saved to CSV (476 samples, 10 features)\n",
            "   fundamental Agent: 16개 피처 사용 - ['Open', 'High', 'Low', 'Close', 'Volume', 'returns', 'sma_5', 'sma_20', 'rsi', 'volume_z', 'USD_KRW', 'NASDAQ', 'VIX', 'priceEarningsRatio', 'forwardPE', 'priceToBook']\n",
            "✅ TSLA fundamental dataset saved to CSV (476 samples, 16 features)\n",
            "   sentimental Agent: 8개 피처 사용 - ['returns', 'sentiment_mean', 'sentiment_vol', 'Close', 'Volume', 'Open', 'High', 'Low']\n",
            "✅ TSLA sentimental dataset saved to CSV (476 samples, 8 features)\n",
            "✅ TSLA base dataset saved to CSV (476 samples)\n",
            "✅ 데이터 생성 및 로드 완료: (476, 7, 10)\n",
            "   - 피처 수: 10\n",
            "   - 시퀀스 길이: 7\n",
            "   - 샘플 수: 476\n",
            "🔢 PyTorch 텐서 변환 완료: X_ttorch.Size([476, 7, 10]), y_ttorch.Size([476, 1])\n",
            "\n",
            "📊 데이터 통계:\n",
            "   - X 범위: [0.0000, 1.0000]\n",
            "   - y 범위: [0.0000, 1.0000]\n",
            "   - X 평균: 0.3761\n",
            "   - y 평균: 0.3868\n",
            "\n",
            "✅ Stage 0 완료!\n"
          ]
        }
      ],
      "source": [
        "# Stage 0: 데이터 수집 및 전처리\n",
        "from core.preprocessing import build_dataset, load_csv_dataset\n",
        "from runners.single_ticker_builder import build_single_ticker\n",
        "\n",
        "print(\"🔄 Stage 0: 데이터 수집 및 전처리 시작...\")\n",
        "print(f\"티커: {TICKER}\")\n",
        "\n",
        "try:\n",
        "    # CSV에서 데이터 로드 시도\n",
        "    print(\"📁 기존 CSV 파일에서 데이터 로드 시도...\")\n",
        "    X, y, scaler_X, scaler_y, feature_cols = load_csv_dataset(TICKER, \"base\")\n",
        "    print(f\"✅ CSV에서 데이터 로드 완료: {X.shape}\")\n",
        "    print(f\"   - 피처 수: {X.shape[2]}\")\n",
        "    print(f\"   - 시퀀스 길이: {X.shape[1]}\")\n",
        "    print(f\"   - 샘플 수: {X.shape[0]}\")\n",
        "    \n",
        "except FileNotFoundError:\n",
        "    # CSV 파일이 없으면 새로 생성\n",
        "    print(\"📁 CSV 파일이 없어서 새로 생성합니다...\")\n",
        "    X, y, scaler_X, scaler_y = build_dataset(TICKER)\n",
        "    print(f\"✅ 데이터 생성 및 로드 완료: {X.shape}\")\n",
        "    print(f\"   - 피처 수: {X.shape[2]}\")\n",
        "    print(f\"   - 시퀀스 길이: {X.shape[1]}\")\n",
        "    print(f\"   - 샘플 수: {X.shape[0]}\")\n",
        "\n",
        "# PyTorch 텐서로 변환\n",
        "X_t, y_t = torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
        "print(f\"🔢 PyTorch 텐서 변환 완료: X_t{X_t.shape}, y_t{y_t.shape}\")\n",
        "\n",
        "# 데이터 통계\n",
        "print(f\"\\n📊 데이터 통계:\")\n",
        "print(f\"   - X 범위: [{X_t.min():.4f}, {X_t.max():.4f}]\")\n",
        "print(f\"   - y 범위: [{y_t.min():.4f}, {y_t.max():.4f}]\")\n",
        "print(f\"   - X 평균: {X_t.mean():.4f}\")\n",
        "print(f\"   - y 평균: {y_t.mean():.4f}\")\n",
        "\n",
        "print(\"\\n✅ Stage 0 완료!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🧠 Stage 1: 에이전트 사전 훈련\n",
        "\n",
        "각 에이전트(Technical, Fundamental, Sentimental)를 개별적으로 사전 훈련합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧠 Stage 1: 에이전트 사전 훈련 시작...\n",
            "🤖 에이전트 초기화...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 3개 에이전트 초기화 완료:\n",
            "   - technical: TechnicalAgent\n",
            "   - fundamental: FundamentalAgent\n",
            "   - sentimental: SentimentalAgent\n",
            "\n",
            "📊 각 에이전트별 데이터셋 준비...\n",
            "✅ technical: torch.Size([476, 7, 10]) (피처 수: 10)\n",
            "✅ fundamental: torch.Size([476, 7, 16]) (피처 수: 16)\n",
            "✅ sentimental: torch.Size([476, 7, 8]) (피처 수: 8)\n",
            "\n",
            "🚀 사전 훈련 시작 (에포크: 20)...\n",
            "[13:20:34] 🧠 Pretraining TechnicalAgent\n",
            "  Epoch 005 | Loss: 0.004981\n",
            "  Epoch 010 | Loss: 0.003547\n",
            "  Epoch 015 | Loss: 0.002881\n",
            "  Epoch 020 | Loss: 0.002816\n",
            "✅ TechnicalAgent pretraining finished.\n",
            "\n",
            "💾 TechnicalAgent 모델 저장됨: models/technical_agent.pt\n",
            "[13:20:36] 🧠 Pretraining FundamentalAgent\n",
            "  Epoch 005 | Loss: 0.004119\n",
            "  Epoch 010 | Loss: 0.003590\n",
            "  Epoch 015 | Loss: 0.002755\n",
            "  Epoch 020 | Loss: 0.002807\n",
            "✅ FundamentalAgent pretraining finished.\n",
            "\n",
            "💾 FundamentalAgent 모델 저장됨: models/fundamental_agent.pt\n",
            "[13:20:37] 🧠 Pretraining SentimentalAgent\n",
            "  Epoch 005 | Loss: 0.017978\n",
            "  Epoch 010 | Loss: 0.010186\n",
            "  Epoch 015 | Loss: 0.005927\n",
            "  Epoch 020 | Loss: 0.004743\n",
            "✅ SentimentalAgent pretraining finished.\n",
            "\n",
            "💾 SentimentalAgent 모델 저장됨: models/sentimental_agent.pt\n",
            "\n",
            "✅ Stage 1 완료!\n",
            "💾 훈련된 모델들이 models/ 디렉토리에 저장되었습니다.\n"
          ]
        }
      ],
      "source": [
        "# Stage 1: 에이전트 사전 훈련\n",
        "from agents.technical_agent import TechnicalAgent\n",
        "from agents.fundamental_agent import FundamentalAgent\n",
        "from agents.sentimental_agent import SentimentalAgent\n",
        "from core.training import pretrain_all_agents\n",
        "\n",
        "print(\"🧠 Stage 1: 에이전트 사전 훈련 시작...\")\n",
        "\n",
        "# 에이전트 초기화\n",
        "print(\"🤖 에이전트 초기화...\")\n",
        "agents = {\n",
        "    \"technical\": TechnicalAgent(\"TechnicalAgent\"),\n",
        "    \"fundamental\": FundamentalAgent(\"FundamentalAgent\"),\n",
        "    \"sentimental\": SentimentalAgent(\"SentimentalAgent\"),\n",
        "}\n",
        "\n",
        "print(f\"✅ {len(agents)}개 에이전트 초기화 완료:\")\n",
        "for name, agent in agents.items():\n",
        "    print(f\"   - {name}: {agent.agent_id}\")\n",
        "\n",
        "# 각 에이전트별 데이터셋 준비\n",
        "print(\"\\n📊 각 에이전트별 데이터셋 준비...\")\n",
        "datasets = {}\n",
        "\n",
        "# 각 에이전트가 기대하는 피처 수 확인\n",
        "for agent_name, agent in agents.items():\n",
        "    try:\n",
        "        # 각 에이전트별 데이터셋 로드 시도\n",
        "        X_agent, y_agent, _, _, _ = load_csv_dataset(TICKER, agent_name)\n",
        "        X_agent_t = torch.tensor(X_agent, dtype=torch.float32)\n",
        "        y_agent_t = torch.tensor(y_agent, dtype=torch.float32)\n",
        "        datasets[agent_name] = (X_agent_t, y_agent_t)\n",
        "        print(f\"✅ {agent_name}: {X_agent_t.shape} (피처 수: {X_agent_t.shape[2]})\")\n",
        "    except FileNotFoundError:\n",
        "        # 에이전트별 데이터가 없으면 기본 데이터 사용\n",
        "        datasets[agent_name] = (X_t, y_t)\n",
        "        print(f\"⚠️ {agent_name}: 기본 데이터 사용 {X_t.shape} (피처 수: {X_t.shape[2]})\")\n",
        "\n",
        "# 사전 훈련 실행\n",
        "print(f\"\\n🚀 사전 훈련 시작 (에포크: {PRE_EPOCHS})...\")\n",
        "pretrain_all_agents(agents, datasets, epochs=PRE_EPOCHS)\n",
        "\n",
        "print(\"\\n✅ Stage 1 완료!\")\n",
        "print(\"💾 훈련된 모델들이 models/ 디렉토리에 저장되었습니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔁 Stage 2: 상호 학습 (Mutual Learning)\n",
        "\n",
        "에이전트들이 서로의 지식을 공유하여 성능을 향상시킵니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔁 Stage 2: 상호 학습 시작...\n",
            "📊 상호 학습 전 성능 측정...\n",
            "   - technical: MSE = 0.002538\n",
            "   - fundamental: MSE = 0.002556\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   - sentimental: MSE = 0.004498\n",
            "\n",
            "🚀 상호 학습 시작 (라운드: 3)...\n",
            "🔍 Agent별 입력 데이터 shape 확인:\n",
            "  📥 X shape: torch.Size([476, 7, 10]) / y shape: torch.Size([476, 1])\n",
            "  - TechnicalAgent: ✅ 출력 shape = torch.Size([476, 1])\n",
            "  - FundamentalAgent: ❌ forward 실패 → input.size(-1) must be equal to input_size. Expected 16, got 10\n",
            "  - SentimentalAgent: ❌ forward 실패 → mat1 and mat2 shapes cannot be multiplied (3332x10 and 8x64)\n",
            "[13:20:48] 🔁 Stage 2: Mutual Learning Start\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "input.size(-1) must be equal to input_size. Expected 16, got 10",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🚀 상호 학습 시작 (라운드: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMUTUAL_ROUNDS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m print_agent_input_shapes(agents, X_t, y_t)  \u001b[38;5;66;03m# <- shape 확인용 디버깅 출력\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43mmutual_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[43magents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMUTUAL_ROUNDS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 상호 학습 후 성능 측정\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m📊 상호 학습 후 성능 측정...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/demos/debate_ver2/core/debate_engine.py:24\u001b[0m, in \u001b[0;36mmutual_learning\u001b[0;34m(agents, X, y, rounds, save_models, model_dir)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Agent가 nn.Module을 상속받는지 확인\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(agent, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(agent, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 24\u001b[0m         preds[name] \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m         preds[name] \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mmodel(X)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/demos/debate_ver2/agents/fundamental_agent.py:26\u001b[0m, in \u001b[0;36mFundamentalAgent.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass for the model\"\"\"\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# x shape: (batch, time, features)\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m lstm_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Use the last time step output\u001b[39;00m\n\u001b[1;32m     28\u001b[0m last_output \u001b[38;5;241m=\u001b[39m lstm_out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1101\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     c_zeros \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m   1094\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m*\u001b[39m num_directions,\n\u001b[1;32m   1095\u001b[0m         max_batch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1098\u001b[0m         device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m   1099\u001b[0m     )\n\u001b[1;32m   1100\u001b[0m     hx \u001b[38;5;241m=\u001b[39m (h_zeros, c_zeros)\n\u001b[0;32m-> 1101\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_batched:\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1002\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_forward_args\u001b[39m(\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[1;32m    999\u001b[0m     hidden: \u001b[38;5;28mtuple\u001b[39m[Tensor, Tensor],  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m     batch_sizes: Optional[Tensor],\n\u001b[1;32m   1001\u001b[0m ):\n\u001b[0;32m-> 1002\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(\n\u001b[1;32m   1004\u001b[0m         hidden[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1005\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m   1006\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1007\u001b[0m     )\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(\n\u001b[1;32m   1009\u001b[0m         hidden[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1012\u001b[0m     )\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:315\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m     )\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    317\u001b[0m     )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 16, got 10"
          ]
        }
      ],
      "source": [
        "# Stage 2: 상호 학습\n",
        "from core.debate_engine import mutual_learning, print_agent_input_shapes\n",
        "\n",
        "print(\"🔁 Stage 2: 상호 학습 시작...\")\n",
        "\n",
        "# 상호 학습 전 성능 측정\n",
        "print(\"📊 상호 학습 전 성능 측정...\")\n",
        "pre_mutual_performance = {}\n",
        "for agent_name, agent in agents.items():\n",
        "    with torch.no_grad():\n",
        "        X_agent, y_agent = datasets[agent_name]\n",
        "        predictions = agent.forward(X_agent)\n",
        "        mse = torch.mean((predictions - y_agent) ** 2).item()\n",
        "        pre_mutual_performance[agent_name] = mse\n",
        "        print(f\"   - {agent_name}: MSE = {mse:.6f}\")\n",
        "\n",
        "# 상호 학습 실행\n",
        "print(f\"\\n🚀 상호 학습 시작 (라운드: {MUTUAL_ROUNDS})...\")\n",
        "print_agent_input_shapes(agents, X_t, y_t)  # <- shape 확인용 디버깅 출력\n",
        "mutual_learning(agents, X_t, y_t, rounds=MUTUAL_ROUNDS)\n",
        "\n",
        "# 상호 학습 후 성능 측정\n",
        "print(\"\\n📊 상호 학습 후 성능 측정...\")\n",
        "post_mutual_performance = {}\n",
        "for agent_name, agent in agents.items():\n",
        "    with torch.no_grad():\n",
        "        X_agent, y_agent = datasets[agent_name]\n",
        "        predictions = agent.forward(X_agent)\n",
        "        mse = torch.mean((predictions - y_agent) ** 2).item()\n",
        "        post_mutual_performance[agent_name] = mse\n",
        "        improvement = ((pre_mutual_performance[agent_name] - mse) / pre_mutual_performance[agent_name]) * 100\n",
        "        print(f\"   - {agent_name}: MSE = {mse:.6f} (개선: {improvement:+.2f}%)\")\n",
        "\n",
        "print(\"\\n✅ Stage 2 완료!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 💬 Stage 3: 토론 및 합의 (Debate & Consensus)\n",
        "\n",
        "에이전트들이 토론을 통해 최종 예측을 도출합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stage 3: 토론 및 합의\n",
        "from core.orchestrator import run_debate_rounds\n",
        "\n",
        "print(\"💬 Stage 3: 토론 및 합의 시작...\")\n",
        "\n",
        "# 토론 실행\n",
        "print(f\"🚀 토론 시작 (라운드: {DEBATE_ROUNDS})...\")\n",
        "debate_results = run_debate_rounds(agents, TICKER, max_rounds=DEBATE_ROUNDS)\n",
        "\n",
        "print(\"\\n📊 토론 결과:\")\n",
        "if debate_results:\n",
        "    for round_num, round_result in enumerate(debate_results, 1):\n",
        "        print(f\"\\n🔄 라운드 {round_num}:\")\n",
        "        if 'predictions' in round_result:\n",
        "            for agent_name, prediction in round_result['predictions'].items():\n",
        "                print(f\"   - {agent_name}: {prediction:.4f}\")\n",
        "        if 'consensus' in round_result:\n",
        "            print(f\"   - 합의: {round_result['consensus']:.4f}\")\n",
        "        if 'confidence' in round_result:\n",
        "            print(f\"   - 신뢰도: {round_result['confidence']:.4f}\")\n",
        "else:\n",
        "    print(\"   ⚠️ 토론 결과를 가져올 수 없습니다.\")\n",
        "\n",
        "print(\"\\n✅ Stage 3 완료!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 최종 평가 및 시각화\n",
        "\n",
        "전체 파이프라인의 성능을 평가하고 결과를 시각화합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 최종 평가\n",
        "from core.evaluation import evaluate_agents, evaluate_consensus\n",
        "\n",
        "print(\"📊 최종 평가 시작...\")\n",
        "\n",
        "# 개별 에이전트 평가\n",
        "print(\"\\n🤖 개별 에이전트 평가:\")\n",
        "evaluate_agents(agents, X_t, y_t)\n",
        "\n",
        "# 합의 평가\n",
        "print(\"\\n🤝 합의 평가:\")\n",
        "evaluate_consensus(agents)\n",
        "\n",
        "print(\"\\n✅ 최종 평가 완료!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 성능 개선 시각화\n",
        "print(\"📈 성능 개선 시각화...\")\n",
        "\n",
        "# 상호 학습 전후 성능 비교\n",
        "if 'pre_mutual_performance' in locals() and 'post_mutual_performance' in locals():\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "    \n",
        "    # MSE 비교\n",
        "    agents_list = list(pre_mutual_performance.keys())\n",
        "    pre_mse = [pre_mutual_performance[agent] for agent in agents_list]\n",
        "    post_mse = [post_mutual_performance[agent] for agent in agents_list]\n",
        "    \n",
        "    x = np.arange(len(agents_list))\n",
        "    width = 0.35\n",
        "    \n",
        "    ax1.bar(x - width/2, pre_mse, width, label='상호 학습 전', alpha=0.8)\n",
        "    ax1.bar(x + width/2, post_mse, width, label='상호 학습 후', alpha=0.8)\n",
        "    ax1.set_xlabel('에이전트')\n",
        "    ax1.set_ylabel('MSE')\n",
        "    ax1.set_title('상호 학습 전후 MSE 비교')\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels(agents_list)\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 개선율 계산\n",
        "    improvements = [((pre - post) / pre) * 100 for pre, post in zip(pre_mse, post_mse)]\n",
        "    colors = ['green' if imp > 0 else 'red' for imp in improvements]\n",
        "    \n",
        "    ax2.bar(agents_list, improvements, color=colors, alpha=0.7)\n",
        "    ax2.set_xlabel('에이전트')\n",
        "    ax2.set_ylabel('개선율 (%)')\n",
        "    ax2.set_title('상호 학습 성능 개선율')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # 개선율 출력\n",
        "    print(\"\\n📊 상호 학습 성능 개선율:\")\n",
        "    for agent, improvement in zip(agents_list, improvements):\n",
        "        print(f\"   - {agent}: {improvement:+.2f}%\")\n",
        "else:\n",
        "    print(\"⚠️ 상호 학습 성능 데이터가 없습니다.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 예측 결과 시각화\n",
        "print(\"📊 예측 결과 시각화...\")\n",
        "\n",
        "# 최근 데이터로 예측 수행\n",
        "recent_data = X_t[-10:]  # 최근 10개 샘플\n",
        "recent_targets = y_t[-10:]\n",
        "\n",
        "predictions = {}\n",
        "for agent_name, agent in agents.items():\n",
        "    with torch.no_grad():\n",
        "        pred = agent.forward(recent_data)\n",
        "        predictions[agent_name] = pred.numpy()\n",
        "\n",
        "# 시각화\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
        "\n",
        "# 실제 vs 예측 비교\n",
        "time_steps = range(len(recent_targets))\n",
        "ax1.plot(time_steps, recent_targets.numpy(), 'o-', label='실제값', linewidth=2, markersize=6)\n",
        "for agent_name, pred in predictions.items():\n",
        "    ax1.plot(time_steps, pred, 's-', label=f'{agent_name} 예측', alpha=0.7, markersize=4)\n",
        "\n",
        "ax1.set_xlabel('시간 단계')\n",
        "ax1.set_ylabel('정규화된 가격')\n",
        "ax1.set_title(f'{TICKER} 최근 예측 결과 비교')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 예측 오차 분석\n",
        "errors = {}\n",
        "for agent_name, pred in predictions.items():\n",
        "    error = np.abs(pred - recent_targets.numpy())\n",
        "    errors[agent_name] = error\n",
        "    ax2.plot(time_steps, error, 'o-', label=f'{agent_name} 오차', alpha=0.7, markersize=4)\n",
        "\n",
        "ax2.set_xlabel('시간 단계')\n",
        "ax2.set_ylabel('절대 오차')\n",
        "ax2.set_title('예측 오차 분석')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 오차 통계\n",
        "print(\"\\n📊 예측 오차 통계:\")\n",
        "for agent_name, error in errors.items():\n",
        "    mae = np.mean(error)\n",
        "    rmse = np.sqrt(np.mean(error**2))\n",
        "    print(f\"   - {agent_name}: MAE={mae:.4f}, RMSE={rmse:.4f}\")\n",
        "\n",
        "print(\"\\n🎉 전체 파이프라인 테스트 완료!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔧 문제 해결 및 디버깅\n",
        "\n",
        "만약 오류가 발생한다면, 다음 셀들을 사용하여 문제를 진단하고 해결할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터 차원 문제 진단\n",
        "print(\"🔍 데이터 차원 문제 진단...\")\n",
        "\n",
        "# 각 에이전트가 기대하는 입력 차원 확인\n",
        "for agent_name, agent in agents.items():\n",
        "    print(f\"\\n🤖 {agent_name} Agent:\")\n",
        "    print(f\"   - 모델 타입: {type(agent).__name__}\")\n",
        "    \n",
        "    # 모델 구조 확인\n",
        "    if hasattr(agent, 'lstm'):\n",
        "        print(f\"   - LSTM 입력 크기: {agent.lstm.input_size}\")\n",
        "    if hasattr(agent, 'tcn'):\n",
        "        print(f\"   - TCN 입력 크기: {agent.tcn.input_size}\")\n",
        "    if hasattr(agent, 'transformer'):\n",
        "        print(f\"   - Transformer 입력 크기: {agent.transformer.input_size}\")\n",
        "    \n",
        "    # 실제 데이터 차원\n",
        "    X_agent, y_agent = datasets[agent_name]\n",
        "    print(f\"   - 실제 데이터 차원: {X_agent.shape}\")\n",
        "    print(f\"   - 피처 수: {X_agent.shape[2]}\")\n",
        "\n",
        "print(\"\\n💡 해결 방법:\")\n",
        "print(\"   - 각 에이전트별로 적절한 데이터셋을 사용해야 합니다.\")\n",
        "print(\"   - Technical Agent: 10개 피처\")\n",
        "print(\"   - Fundamental Agent: 16개 피처\") \n",
        "print(\"   - Sentimental Agent: 8개 피처\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 개별 단계 테스트\n",
        "print(\"🧪 개별 단계 테스트...\")\n",
        "\n",
        "# Stage 0만 테스트\n",
        "print(\"\\n📊 Stage 0 테스트 (데이터 수집):\")\n",
        "try:\n",
        "    from core.preprocessing import build_dataset\n",
        "    X_test, y_test, scaler_X_test, scaler_y_test = build_dataset(\"AAPL\")  # 다른 티커로 테스트\n",
        "    print(f\"✅ Stage 0 성공: {X_test.shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Stage 0 실패: {e}\")\n",
        "\n",
        "# Stage 1만 테스트 (단일 에이전트)\n",
        "print(\"\\n🧠 Stage 1 테스트 (단일 에이전트 훈련):\")\n",
        "try:\n",
        "    from agents.technical_agent import TechnicalAgent\n",
        "    from core.training import pretrain_agent\n",
        "    \n",
        "    test_agent = TechnicalAgent(\"TestAgent\")\n",
        "    X_small = X_t[:10]  # 작은 데이터셋으로 테스트\n",
        "    y_small = y_t[:10]\n",
        "    \n",
        "    pretrain_agent(test_agent, X_small, y_small, epochs=2)\n",
        "    print(\"✅ Stage 1 성공\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Stage 1 실패: {e}\")\n",
        "\n",
        "print(\"\\n💡 각 단계를 개별적으로 테스트하여 문제를 격리할 수 있습니다.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
