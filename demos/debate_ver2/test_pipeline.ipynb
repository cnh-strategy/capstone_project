{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸš€ MCP Hybrid System Pipeline Test\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ `debate_ver2` ì‹œìŠ¤í…œì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ë‹¨ê³„ë³„ë¡œ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "## ğŸ“‹ í…ŒìŠ¤íŠ¸ ë‹¨ê³„\n",
        "1. **Stage 0**: ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬\n",
        "2. **Stage 1**: ì—ì´ì „íŠ¸ ì‚¬ì „ í›ˆë ¨\n",
        "3. **Stage 2**: ìƒí˜¸ í•™ìŠµ (Mutual Learning)\n",
        "4. **Stage 3**: í† ë¡  ë° í•©ì˜ (Debate & Consensus)\n",
        "5. **í‰ê°€**: ìµœì¢… ì„±ëŠ¥ í‰ê°€\n",
        "\n",
        "## ğŸ¯ í…ŒìŠ¤íŠ¸í•  í‹°ì»¤\n",
        "- ê¸°ë³¸ê°’: **TSLA** (í…ŒìŠ¬ë¼)\n",
        "- ë‹¤ë¥¸ í‹°ì»¤ë¡œ ë³€ê²½ ê°€ëŠ¥\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¯ í…ŒìŠ¤íŠ¸ ì„¤ì •:\n",
            "   - í‹°ì»¤: TSLA\n",
            "   - ì‚¬ì „ í›ˆë ¨ ì—í¬í¬: 20\n",
            "   - ìƒí˜¸ í•™ìŠµ ë¼ìš´ë“œ: 3\n",
            "   - í† ë¡  ë¼ìš´ë“œ: 2\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€\n",
        "sys.path.append('/home/ubuntu/Projects/ml-ai/capstone/demos/debate_ver2')\n",
        "\n",
        "# ì„¤ì •\n",
        "TICKER = \"TSLA\"  # í…ŒìŠ¤íŠ¸í•  í‹°ì»¤ (ë³€ê²½ ê°€ëŠ¥)\n",
        "PRE_EPOCHS = 20  # ì‚¬ì „ í›ˆë ¨ ì—í¬í¬ ìˆ˜\n",
        "MUTUAL_ROUNDS = 3  # ìƒí˜¸ í•™ìŠµ ë¼ìš´ë“œ ìˆ˜\n",
        "DEBATE_ROUNDS = 2  # í† ë¡  ë¼ìš´ë“œ ìˆ˜\n",
        "\n",
        "print(f\"ğŸ¯ í…ŒìŠ¤íŠ¸ ì„¤ì •:\")\n",
        "print(f\"   - í‹°ì»¤: {TICKER}\")\n",
        "print(f\"   - ì‚¬ì „ í›ˆë ¨ ì—í¬í¬: {PRE_EPOCHS}\")\n",
        "print(f\"   - ìƒí˜¸ í•™ìŠµ ë¼ìš´ë“œ: {MUTUAL_ROUNDS}\")\n",
        "print(f\"   - í† ë¡  ë¼ìš´ë“œ: {DEBATE_ROUNDS}\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸš€ [MCP Hybrid System Orchestration Start]\n",
            "Ticker: RZLV\n",
            "======================================================================\n",
            "âš ï¸  [technical] CSV ì—†ìŒ â†’ build_dataset() ì‹¤í–‰\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… RZLV raw data saved to CSV (482 samples)\n",
            "   technical Agent: 10ê°œ í”¼ì²˜ ì‚¬ìš© - ['Open', 'High', 'Low', 'Close', 'Volume', 'returns', 'sma_5', 'sma_20', 'rsi', 'volume_z']\n",
            "âœ… RZLV technical dataset saved to CSV (475 samples, 10 features)\n",
            "   fundamental Agent: 16ê°œ í”¼ì²˜ ì‚¬ìš© - ['Open', 'High', 'Low', 'Close', 'Volume', 'returns', 'sma_5', 'sma_20', 'rsi', 'volume_z', 'USD_KRW', 'NASDAQ', 'VIX', 'priceEarningsRatio', 'forwardPE', 'priceToBook']\n",
            "âœ… RZLV fundamental dataset saved to CSV (475 samples, 16 features)\n",
            "   sentimental Agent: 8ê°œ í”¼ì²˜ ì‚¬ìš© - ['returns', 'sentiment_mean', 'sentiment_vol', 'Close', 'Volume', 'Open', 'High', 'Low']\n",
            "âœ… RZLV sentimental dataset saved to CSV (475 samples, 8 features)\n",
            "âœ… RZLV base dataset saved to CSV (475 samples)\n",
            "âœ… [technical] ë°ì´í„° ìƒì„± ì™„ë£Œ: X=(475, 7, 10), y=(475, 1)\n",
            "âš ï¸  [fundamental] CSV ì—†ìŒ â†’ build_dataset() ì‹¤í–‰\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… RZLV raw data saved to CSV (482 samples)\n",
            "   technical Agent: 10ê°œ í”¼ì²˜ ì‚¬ìš© - ['Open', 'High', 'Low', 'Close', 'Volume', 'returns', 'sma_5', 'sma_20', 'rsi', 'volume_z']\n",
            "âœ… RZLV technical dataset saved to CSV (475 samples, 10 features)\n",
            "   fundamental Agent: 16ê°œ í”¼ì²˜ ì‚¬ìš© - ['Open', 'High', 'Low', 'Close', 'Volume', 'returns', 'sma_5', 'sma_20', 'rsi', 'volume_z', 'USD_KRW', 'NASDAQ', 'VIX', 'priceEarningsRatio', 'forwardPE', 'priceToBook']\n",
            "âœ… RZLV fundamental dataset saved to CSV (475 samples, 16 features)\n",
            "   sentimental Agent: 8ê°œ í”¼ì²˜ ì‚¬ìš© - ['returns', 'sentiment_mean', 'sentiment_vol', 'Close', 'Volume', 'Open', 'High', 'Low']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… RZLV sentimental dataset saved to CSV (475 samples, 8 features)\n",
            "âœ… RZLV base dataset saved to CSV (475 samples)\n",
            "âœ… [fundamental] ë°ì´í„° ìƒì„± ì™„ë£Œ: X=(475, 7, 10), y=(475, 1)\n",
            "âš ï¸  [sentimental] CSV ì—†ìŒ â†’ build_dataset() ì‹¤í–‰\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… RZLV raw data saved to CSV (482 samples)\n",
            "   technical Agent: 10ê°œ í”¼ì²˜ ì‚¬ìš© - ['Open', 'High', 'Low', 'Close', 'Volume', 'returns', 'sma_5', 'sma_20', 'rsi', 'volume_z']\n",
            "âœ… RZLV technical dataset saved to CSV (475 samples, 10 features)\n",
            "   fundamental Agent: 16ê°œ í”¼ì²˜ ì‚¬ìš© - ['Open', 'High', 'Low', 'Close', 'Volume', 'returns', 'sma_5', 'sma_20', 'rsi', 'volume_z', 'USD_KRW', 'NASDAQ', 'VIX', 'priceEarningsRatio', 'forwardPE', 'priceToBook']\n",
            "âœ… RZLV fundamental dataset saved to CSV (475 samples, 16 features)\n",
            "   sentimental Agent: 8ê°œ í”¼ì²˜ ì‚¬ìš© - ['returns', 'sentiment_mean', 'sentiment_vol', 'Close', 'Volume', 'Open', 'High', 'Low']\n",
            "âœ… RZLV sentimental dataset saved to CSV (475 samples, 8 features)\n",
            "âœ… RZLV base dataset saved to CSV (475 samples)\n",
            "âœ… [sentimental] ë°ì´í„° ìƒì„± ì™„ë£Œ: X=(475, 7, 10), y=(475, 1)\n",
            "\n",
            "ğŸ§  Stage 1: Pretraining Agents\n",
            "[13:38:16] ğŸ§  Pretraining TechnicalAgent\n",
            "  Epoch 005 | Loss: 0.003926\n",
            "  Epoch 010 | Loss: 0.003357\n",
            "  Epoch 015 | Loss: 0.002998\n",
            "  Epoch 020 | Loss: 0.002810\n",
            "âœ… TechnicalAgent pretraining finished.\n",
            "\n",
            "ğŸ’¾ TechnicalAgent ëª¨ë¸ ì €ì¥ë¨: models/technical_agent.pt\n",
            "[13:38:19] ğŸ§  Pretraining FundamentalAgent\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "input.size(-1) must be equal to input_size. Expected 16, got 10",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrun\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_mcp_pipeline\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrun_mcp_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRZLV\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/demos/debate_ver2/run.py:51\u001b[0m, in \u001b[0;36mrun_mcp_pipeline\u001b[0;34m(ticker, pre_epochs, mutual_rounds, debate_rounds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# 2ï¸âƒ£ Stage 1: ì‚¬ì „í•™ìŠµ\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mğŸ§  Stage 1: Pretraining Agents\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m \u001b[43mpretrain_all_agents\u001b[49m\u001b[43m(\u001b[49m\u001b[43magents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# 3ï¸âƒ£ Stage 2: Selective Mutual Learning\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mğŸ” Stage 2: Selective Mutual Learning\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/demos/debate_ver2/core/training.py:91\u001b[0m, in \u001b[0;36mpretrain_all_agents\u001b[0;34m(agents, datasets, epochs, lr, save_models, model_dir)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, agent \u001b[38;5;129;01min\u001b[39;00m agents\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     90\u001b[0m     X_train, y_train \u001b[38;5;241m=\u001b[39m datasets[name]\n\u001b[0;32m---> 91\u001b[0m     \u001b[43mpretrain_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# ëª¨ë¸ ì €ì¥\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m save_models:\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/demos/debate_ver2/core/training.py:21\u001b[0m, in \u001b[0;36mpretrain_agent\u001b[0;34m(agent, train_X, train_y, val_X, val_y, epochs, lr, batch_size)\u001b[0m\n\u001b[1;32m     19\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m Xb, yb \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m---> 21\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, yb)\n\u001b[1;32m     23\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/demos/debate_ver2/agents/fundamental_agent.py:26\u001b[0m, in \u001b[0;36mFundamentalAgent.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass for the model\"\"\"\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# x shape: (batch, time, features)\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m lstm_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Use the last time step output\u001b[39;00m\n\u001b[1;32m     28\u001b[0m last_output \u001b[38;5;241m=\u001b[39m lstm_out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1101\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     c_zeros \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m   1094\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m*\u001b[39m num_directions,\n\u001b[1;32m   1095\u001b[0m         max_batch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1098\u001b[0m         device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m   1099\u001b[0m     )\n\u001b[1;32m   1100\u001b[0m     hx \u001b[38;5;241m=\u001b[39m (h_zeros, c_zeros)\n\u001b[0;32m-> 1101\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_batched:\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1002\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_forward_args\u001b[39m(\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[1;32m    999\u001b[0m     hidden: \u001b[38;5;28mtuple\u001b[39m[Tensor, Tensor],  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m     batch_sizes: Optional[Tensor],\n\u001b[1;32m   1001\u001b[0m ):\n\u001b[0;32m-> 1002\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(\n\u001b[1;32m   1004\u001b[0m         hidden[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1005\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m   1006\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1007\u001b[0m     )\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(\n\u001b[1;32m   1009\u001b[0m         hidden[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1012\u001b[0m     )\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:315\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m     )\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    317\u001b[0m     )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 16, got 10"
          ]
        }
      ],
      "source": [
        "from run import run_mcp_pipeline\n",
        "\n",
        "run_mcp_pipeline(\"RZLV\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š Stage 0: ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬\n",
        "\n",
        "ì´ ë‹¨ê³„ì—ì„œëŠ” ì£¼ì‹ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ê° ì—ì´ì „íŠ¸ë³„ë¡œ í•„ìš”í•œ í”¼ì²˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Stage 0: ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬ ì‹œì‘...\n",
            "í‹°ì»¤: TSLA\n",
            "ğŸ“ ê¸°ì¡´ CSV íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ ì‹œë„...\n",
            "ğŸ“ CSV íŒŒì¼ì´ ì—†ì–´ì„œ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… TSLA raw data saved to CSV (483 samples)\n",
            "   technical Agent: 10ê°œ í”¼ì²˜ ì‚¬ìš© - ['Open', 'High', 'Low', 'Close', 'Volume', 'returns', 'sma_5', 'sma_20', 'rsi', 'volume_z']\n",
            "âœ… TSLA technical dataset saved to CSV (476 samples, 10 features)\n",
            "   fundamental Agent: 16ê°œ í”¼ì²˜ ì‚¬ìš© - ['Open', 'High', 'Low', 'Close', 'Volume', 'returns', 'sma_5', 'sma_20', 'rsi', 'volume_z', 'USD_KRW', 'NASDAQ', 'VIX', 'priceEarningsRatio', 'forwardPE', 'priceToBook']\n",
            "âœ… TSLA fundamental dataset saved to CSV (476 samples, 16 features)\n",
            "   sentimental Agent: 8ê°œ í”¼ì²˜ ì‚¬ìš© - ['returns', 'sentiment_mean', 'sentiment_vol', 'Close', 'Volume', 'Open', 'High', 'Low']\n",
            "âœ… TSLA sentimental dataset saved to CSV (476 samples, 8 features)\n",
            "âœ… TSLA base dataset saved to CSV (476 samples)\n",
            "âœ… ë°ì´í„° ìƒì„± ë° ë¡œë“œ ì™„ë£Œ: (476, 7, 10)\n",
            "   - í”¼ì²˜ ìˆ˜: 10\n",
            "   - ì‹œí€€ìŠ¤ ê¸¸ì´: 7\n",
            "   - ìƒ˜í”Œ ìˆ˜: 476\n",
            "ğŸ”¢ PyTorch í…ì„œ ë³€í™˜ ì™„ë£Œ: X_ttorch.Size([476, 7, 10]), y_ttorch.Size([476, 1])\n",
            "\n",
            "ğŸ“Š ë°ì´í„° í†µê³„:\n",
            "   - X ë²”ìœ„: [0.0000, 1.0000]\n",
            "   - y ë²”ìœ„: [0.0000, 1.0000]\n",
            "   - X í‰ê· : 0.3761\n",
            "   - y í‰ê· : 0.3868\n",
            "\n",
            "âœ… Stage 0 ì™„ë£Œ!\n"
          ]
        }
      ],
      "source": [
        "# Stage 0: ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬\n",
        "from core.preprocessing import build_dataset, load_csv_dataset\n",
        "from runners.single_ticker_builder import build_single_ticker\n",
        "\n",
        "print(\"ğŸ”„ Stage 0: ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬ ì‹œì‘...\")\n",
        "print(f\"í‹°ì»¤: {TICKER}\")\n",
        "\n",
        "try:\n",
        "    # CSVì—ì„œ ë°ì´í„° ë¡œë“œ ì‹œë„\n",
        "    print(\"ğŸ“ ê¸°ì¡´ CSV íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ ì‹œë„...\")\n",
        "    X, y, scaler_X, scaler_y, feature_cols = load_csv_dataset(TICKER, \"base\")\n",
        "    print(f\"âœ… CSVì—ì„œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {X.shape}\")\n",
        "    print(f\"   - í”¼ì²˜ ìˆ˜: {X.shape[2]}\")\n",
        "    print(f\"   - ì‹œí€€ìŠ¤ ê¸¸ì´: {X.shape[1]}\")\n",
        "    print(f\"   - ìƒ˜í”Œ ìˆ˜: {X.shape[0]}\")\n",
        "    \n",
        "except FileNotFoundError:\n",
        "    # CSV íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±\n",
        "    print(\"ğŸ“ CSV íŒŒì¼ì´ ì—†ì–´ì„œ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...\")\n",
        "    X, y, scaler_X, scaler_y = build_dataset(TICKER)\n",
        "    print(f\"âœ… ë°ì´í„° ìƒì„± ë° ë¡œë“œ ì™„ë£Œ: {X.shape}\")\n",
        "    print(f\"   - í”¼ì²˜ ìˆ˜: {X.shape[2]}\")\n",
        "    print(f\"   - ì‹œí€€ìŠ¤ ê¸¸ì´: {X.shape[1]}\")\n",
        "    print(f\"   - ìƒ˜í”Œ ìˆ˜: {X.shape[0]}\")\n",
        "\n",
        "# PyTorch í…ì„œë¡œ ë³€í™˜\n",
        "X_t, y_t = torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
        "print(f\"ğŸ”¢ PyTorch í…ì„œ ë³€í™˜ ì™„ë£Œ: X_t{X_t.shape}, y_t{y_t.shape}\")\n",
        "\n",
        "# ë°ì´í„° í†µê³„\n",
        "print(f\"\\nğŸ“Š ë°ì´í„° í†µê³„:\")\n",
        "print(f\"   - X ë²”ìœ„: [{X_t.min():.4f}, {X_t.max():.4f}]\")\n",
        "print(f\"   - y ë²”ìœ„: [{y_t.min():.4f}, {y_t.max():.4f}]\")\n",
        "print(f\"   - X í‰ê· : {X_t.mean():.4f}\")\n",
        "print(f\"   - y í‰ê· : {y_t.mean():.4f}\")\n",
        "\n",
        "print(\"\\nâœ… Stage 0 ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§  Stage 1: ì—ì´ì „íŠ¸ ì‚¬ì „ í›ˆë ¨\n",
        "\n",
        "ê° ì—ì´ì „íŠ¸(Technical, Fundamental, Sentimental)ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì‚¬ì „ í›ˆë ¨í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ§  Stage 1: ì—ì´ì „íŠ¸ ì‚¬ì „ í›ˆë ¨ ì‹œì‘...\n",
            "ğŸ¤– ì—ì´ì „íŠ¸ ì´ˆê¸°í™”...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… 3ê°œ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ:\n",
            "   - technical: TechnicalAgent\n",
            "   - fundamental: FundamentalAgent\n",
            "   - sentimental: SentimentalAgent\n",
            "\n",
            "ğŸ“Š ê° ì—ì´ì „íŠ¸ë³„ ë°ì´í„°ì…‹ ì¤€ë¹„...\n",
            "âœ… technical: torch.Size([476, 7, 10]) (í”¼ì²˜ ìˆ˜: 10)\n",
            "âœ… fundamental: torch.Size([476, 7, 16]) (í”¼ì²˜ ìˆ˜: 16)\n",
            "âœ… sentimental: torch.Size([476, 7, 8]) (í”¼ì²˜ ìˆ˜: 8)\n",
            "\n",
            "ğŸš€ ì‚¬ì „ í›ˆë ¨ ì‹œì‘ (ì—í¬í¬: 20)...\n",
            "[13:20:34] ğŸ§  Pretraining TechnicalAgent\n",
            "  Epoch 005 | Loss: 0.004981\n",
            "  Epoch 010 | Loss: 0.003547\n",
            "  Epoch 015 | Loss: 0.002881\n",
            "  Epoch 020 | Loss: 0.002816\n",
            "âœ… TechnicalAgent pretraining finished.\n",
            "\n",
            "ğŸ’¾ TechnicalAgent ëª¨ë¸ ì €ì¥ë¨: models/technical_agent.pt\n",
            "[13:20:36] ğŸ§  Pretraining FundamentalAgent\n",
            "  Epoch 005 | Loss: 0.004119\n",
            "  Epoch 010 | Loss: 0.003590\n",
            "  Epoch 015 | Loss: 0.002755\n",
            "  Epoch 020 | Loss: 0.002807\n",
            "âœ… FundamentalAgent pretraining finished.\n",
            "\n",
            "ğŸ’¾ FundamentalAgent ëª¨ë¸ ì €ì¥ë¨: models/fundamental_agent.pt\n",
            "[13:20:37] ğŸ§  Pretraining SentimentalAgent\n",
            "  Epoch 005 | Loss: 0.017978\n",
            "  Epoch 010 | Loss: 0.010186\n",
            "  Epoch 015 | Loss: 0.005927\n",
            "  Epoch 020 | Loss: 0.004743\n",
            "âœ… SentimentalAgent pretraining finished.\n",
            "\n",
            "ğŸ’¾ SentimentalAgent ëª¨ë¸ ì €ì¥ë¨: models/sentimental_agent.pt\n",
            "\n",
            "âœ… Stage 1 ì™„ë£Œ!\n",
            "ğŸ’¾ í›ˆë ¨ëœ ëª¨ë¸ë“¤ì´ models/ ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "# Stage 1: ì—ì´ì „íŠ¸ ì‚¬ì „ í›ˆë ¨\n",
        "from agents.technical_agent import TechnicalAgent\n",
        "from agents.fundamental_agent import FundamentalAgent\n",
        "from agents.sentimental_agent import SentimentalAgent\n",
        "from core.training import pretrain_all_agents\n",
        "\n",
        "print(\"ğŸ§  Stage 1: ì—ì´ì „íŠ¸ ì‚¬ì „ í›ˆë ¨ ì‹œì‘...\")\n",
        "\n",
        "# ì—ì´ì „íŠ¸ ì´ˆê¸°í™”\n",
        "print(\"ğŸ¤– ì—ì´ì „íŠ¸ ì´ˆê¸°í™”...\")\n",
        "agents = {\n",
        "    \"technical\": TechnicalAgent(\"TechnicalAgent\"),\n",
        "    \"fundamental\": FundamentalAgent(\"FundamentalAgent\"),\n",
        "    \"sentimental\": SentimentalAgent(\"SentimentalAgent\"),\n",
        "}\n",
        "\n",
        "print(f\"âœ… {len(agents)}ê°œ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ:\")\n",
        "for name, agent in agents.items():\n",
        "    print(f\"   - {name}: {agent.agent_id}\")\n",
        "\n",
        "# ê° ì—ì´ì „íŠ¸ë³„ ë°ì´í„°ì…‹ ì¤€ë¹„\n",
        "print(\"\\nğŸ“Š ê° ì—ì´ì „íŠ¸ë³„ ë°ì´í„°ì…‹ ì¤€ë¹„...\")\n",
        "datasets = {}\n",
        "\n",
        "# ê° ì—ì´ì „íŠ¸ê°€ ê¸°ëŒ€í•˜ëŠ” í”¼ì²˜ ìˆ˜ í™•ì¸\n",
        "for agent_name, agent in agents.items():\n",
        "    try:\n",
        "        # ê° ì—ì´ì „íŠ¸ë³„ ë°ì´í„°ì…‹ ë¡œë“œ ì‹œë„\n",
        "        X_agent, y_agent, _, _, _ = load_csv_dataset(TICKER, agent_name)\n",
        "        X_agent_t = torch.tensor(X_agent, dtype=torch.float32)\n",
        "        y_agent_t = torch.tensor(y_agent, dtype=torch.float32)\n",
        "        datasets[agent_name] = (X_agent_t, y_agent_t)\n",
        "        print(f\"âœ… {agent_name}: {X_agent_t.shape} (í”¼ì²˜ ìˆ˜: {X_agent_t.shape[2]})\")\n",
        "    except FileNotFoundError:\n",
        "        # ì—ì´ì „íŠ¸ë³„ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ë°ì´í„° ì‚¬ìš©\n",
        "        datasets[agent_name] = (X_t, y_t)\n",
        "        print(f\"âš ï¸ {agent_name}: ê¸°ë³¸ ë°ì´í„° ì‚¬ìš© {X_t.shape} (í”¼ì²˜ ìˆ˜: {X_t.shape[2]})\")\n",
        "\n",
        "# ì‚¬ì „ í›ˆë ¨ ì‹¤í–‰\n",
        "print(f\"\\nğŸš€ ì‚¬ì „ í›ˆë ¨ ì‹œì‘ (ì—í¬í¬: {PRE_EPOCHS})...\")\n",
        "pretrain_all_agents(agents, datasets, epochs=PRE_EPOCHS)\n",
        "\n",
        "print(\"\\nâœ… Stage 1 ì™„ë£Œ!\")\n",
        "print(\"ğŸ’¾ í›ˆë ¨ëœ ëª¨ë¸ë“¤ì´ models/ ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ” Stage 2: ìƒí˜¸ í•™ìŠµ (Mutual Learning)\n",
        "\n",
        "ì—ì´ì „íŠ¸ë“¤ì´ ì„œë¡œì˜ ì§€ì‹ì„ ê³µìœ í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ” Stage 2: ìƒí˜¸ í•™ìŠµ ì‹œì‘...\n",
            "ğŸ“Š ìƒí˜¸ í•™ìŠµ ì „ ì„±ëŠ¥ ì¸¡ì •...\n",
            "   - technical: MSE = 0.002538\n",
            "   - fundamental: MSE = 0.002556\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   - sentimental: MSE = 0.004498\n",
            "\n",
            "ğŸš€ ìƒí˜¸ í•™ìŠµ ì‹œì‘ (ë¼ìš´ë“œ: 3)...\n",
            "ğŸ” Agentë³„ ì…ë ¥ ë°ì´í„° shape í™•ì¸:\n",
            "  ğŸ“¥ X shape: torch.Size([476, 7, 10]) / y shape: torch.Size([476, 1])\n",
            "  - TechnicalAgent: âœ… ì¶œë ¥ shape = torch.Size([476, 1])\n",
            "  - FundamentalAgent: âŒ forward ì‹¤íŒ¨ â†’ input.size(-1) must be equal to input_size. Expected 16, got 10\n",
            "  - SentimentalAgent: âŒ forward ì‹¤íŒ¨ â†’ mat1 and mat2 shapes cannot be multiplied (3332x10 and 8x64)\n",
            "[13:20:48] ğŸ” Stage 2: Mutual Learning Start\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "input.size(-1) must be equal to input_size. Expected 16, got 10",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mğŸš€ ìƒí˜¸ í•™ìŠµ ì‹œì‘ (ë¼ìš´ë“œ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMUTUAL_ROUNDS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m print_agent_input_shapes(agents, X_t, y_t)  \u001b[38;5;66;03m# <- shape í™•ì¸ìš© ë””ë²„ê¹… ì¶œë ¥\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43mmutual_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[43magents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMUTUAL_ROUNDS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# ìƒí˜¸ í•™ìŠµ í›„ ì„±ëŠ¥ ì¸¡ì •\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mğŸ“Š ìƒí˜¸ í•™ìŠµ í›„ ì„±ëŠ¥ ì¸¡ì •...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/demos/debate_ver2/core/debate_engine.py:24\u001b[0m, in \u001b[0;36mmutual_learning\u001b[0;34m(agents, X, y, rounds, save_models, model_dir)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Agentê°€ nn.Moduleì„ ìƒì†ë°›ëŠ”ì§€ í™•ì¸\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(agent, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(agent, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 24\u001b[0m         preds[name] \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m         preds[name] \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mmodel(X)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/demos/debate_ver2/agents/fundamental_agent.py:26\u001b[0m, in \u001b[0;36mFundamentalAgent.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass for the model\"\"\"\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# x shape: (batch, time, features)\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m lstm_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Use the last time step output\u001b[39;00m\n\u001b[1;32m     28\u001b[0m last_output \u001b[38;5;241m=\u001b[39m lstm_out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1101\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     c_zeros \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m   1094\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m*\u001b[39m num_directions,\n\u001b[1;32m   1095\u001b[0m         max_batch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1098\u001b[0m         device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m   1099\u001b[0m     )\n\u001b[1;32m   1100\u001b[0m     hx \u001b[38;5;241m=\u001b[39m (h_zeros, c_zeros)\n\u001b[0;32m-> 1101\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_batched:\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1002\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_forward_args\u001b[39m(\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[1;32m    999\u001b[0m     hidden: \u001b[38;5;28mtuple\u001b[39m[Tensor, Tensor],  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m     batch_sizes: Optional[Tensor],\n\u001b[1;32m   1001\u001b[0m ):\n\u001b[0;32m-> 1002\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(\n\u001b[1;32m   1004\u001b[0m         hidden[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1005\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m   1006\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1007\u001b[0m     )\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(\n\u001b[1;32m   1009\u001b[0m         hidden[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1012\u001b[0m     )\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:315\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m     )\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    317\u001b[0m     )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 16, got 10"
          ]
        }
      ],
      "source": [
        "# Stage 2: ìƒí˜¸ í•™ìŠµ\n",
        "from core.debate_engine import mutual_learning, print_agent_input_shapes\n",
        "\n",
        "print(\"ğŸ” Stage 2: ìƒí˜¸ í•™ìŠµ ì‹œì‘...\")\n",
        "\n",
        "# ìƒí˜¸ í•™ìŠµ ì „ ì„±ëŠ¥ ì¸¡ì •\n",
        "print(\"ğŸ“Š ìƒí˜¸ í•™ìŠµ ì „ ì„±ëŠ¥ ì¸¡ì •...\")\n",
        "pre_mutual_performance = {}\n",
        "for agent_name, agent in agents.items():\n",
        "    with torch.no_grad():\n",
        "        X_agent, y_agent = datasets[agent_name]\n",
        "        predictions = agent.forward(X_agent)\n",
        "        mse = torch.mean((predictions - y_agent) ** 2).item()\n",
        "        pre_mutual_performance[agent_name] = mse\n",
        "        print(f\"   - {agent_name}: MSE = {mse:.6f}\")\n",
        "\n",
        "# ìƒí˜¸ í•™ìŠµ ì‹¤í–‰\n",
        "print(f\"\\nğŸš€ ìƒí˜¸ í•™ìŠµ ì‹œì‘ (ë¼ìš´ë“œ: {MUTUAL_ROUNDS})...\")\n",
        "print_agent_input_shapes(agents, X_t, y_t)  # <- shape í™•ì¸ìš© ë””ë²„ê¹… ì¶œë ¥\n",
        "mutual_learning(agents, X_t, y_t, rounds=MUTUAL_ROUNDS)\n",
        "\n",
        "# ìƒí˜¸ í•™ìŠµ í›„ ì„±ëŠ¥ ì¸¡ì •\n",
        "print(\"\\nğŸ“Š ìƒí˜¸ í•™ìŠµ í›„ ì„±ëŠ¥ ì¸¡ì •...\")\n",
        "post_mutual_performance = {}\n",
        "for agent_name, agent in agents.items():\n",
        "    with torch.no_grad():\n",
        "        X_agent, y_agent = datasets[agent_name]\n",
        "        predictions = agent.forward(X_agent)\n",
        "        mse = torch.mean((predictions - y_agent) ** 2).item()\n",
        "        post_mutual_performance[agent_name] = mse\n",
        "        improvement = ((pre_mutual_performance[agent_name] - mse) / pre_mutual_performance[agent_name]) * 100\n",
        "        print(f\"   - {agent_name}: MSE = {mse:.6f} (ê°œì„ : {improvement:+.2f}%)\")\n",
        "\n",
        "print(\"\\nâœ… Stage 2 ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ’¬ Stage 3: í† ë¡  ë° í•©ì˜ (Debate & Consensus)\n",
        "\n",
        "ì—ì´ì „íŠ¸ë“¤ì´ í† ë¡ ì„ í†µí•´ ìµœì¢… ì˜ˆì¸¡ì„ ë„ì¶œí•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stage 3: í† ë¡  ë° í•©ì˜\n",
        "from core.orchestrator import run_debate_rounds\n",
        "\n",
        "print(\"ğŸ’¬ Stage 3: í† ë¡  ë° í•©ì˜ ì‹œì‘...\")\n",
        "\n",
        "# í† ë¡  ì‹¤í–‰\n",
        "print(f\"ğŸš€ í† ë¡  ì‹œì‘ (ë¼ìš´ë“œ: {DEBATE_ROUNDS})...\")\n",
        "debate_results = run_debate_rounds(agents, TICKER, max_rounds=DEBATE_ROUNDS)\n",
        "\n",
        "print(\"\\nğŸ“Š í† ë¡  ê²°ê³¼:\")\n",
        "if debate_results:\n",
        "    for round_num, round_result in enumerate(debate_results, 1):\n",
        "        print(f\"\\nğŸ”„ ë¼ìš´ë“œ {round_num}:\")\n",
        "        if 'predictions' in round_result:\n",
        "            for agent_name, prediction in round_result['predictions'].items():\n",
        "                print(f\"   - {agent_name}: {prediction:.4f}\")\n",
        "        if 'consensus' in round_result:\n",
        "            print(f\"   - í•©ì˜: {round_result['consensus']:.4f}\")\n",
        "        if 'confidence' in round_result:\n",
        "            print(f\"   - ì‹ ë¢°ë„: {round_result['confidence']:.4f}\")\n",
        "else:\n",
        "    print(\"   âš ï¸ í† ë¡  ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "print(\"\\nâœ… Stage 3 ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š ìµœì¢… í‰ê°€ ë° ì‹œê°í™”\n",
        "\n",
        "ì „ì²´ íŒŒì´í”„ë¼ì¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ìµœì¢… í‰ê°€\n",
        "from core.evaluation import evaluate_agents, evaluate_consensus\n",
        "\n",
        "print(\"ğŸ“Š ìµœì¢… í‰ê°€ ì‹œì‘...\")\n",
        "\n",
        "# ê°œë³„ ì—ì´ì „íŠ¸ í‰ê°€\n",
        "print(\"\\nğŸ¤– ê°œë³„ ì—ì´ì „íŠ¸ í‰ê°€:\")\n",
        "evaluate_agents(agents, X_t, y_t)\n",
        "\n",
        "# í•©ì˜ í‰ê°€\n",
        "print(\"\\nğŸ¤ í•©ì˜ í‰ê°€:\")\n",
        "evaluate_consensus(agents)\n",
        "\n",
        "print(\"\\nâœ… ìµœì¢… í‰ê°€ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì„±ëŠ¥ ê°œì„  ì‹œê°í™”\n",
        "print(\"ğŸ“ˆ ì„±ëŠ¥ ê°œì„  ì‹œê°í™”...\")\n",
        "\n",
        "# ìƒí˜¸ í•™ìŠµ ì „í›„ ì„±ëŠ¥ ë¹„êµ\n",
        "if 'pre_mutual_performance' in locals() and 'post_mutual_performance' in locals():\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "    \n",
        "    # MSE ë¹„êµ\n",
        "    agents_list = list(pre_mutual_performance.keys())\n",
        "    pre_mse = [pre_mutual_performance[agent] for agent in agents_list]\n",
        "    post_mse = [post_mutual_performance[agent] for agent in agents_list]\n",
        "    \n",
        "    x = np.arange(len(agents_list))\n",
        "    width = 0.35\n",
        "    \n",
        "    ax1.bar(x - width/2, pre_mse, width, label='ìƒí˜¸ í•™ìŠµ ì „', alpha=0.8)\n",
        "    ax1.bar(x + width/2, post_mse, width, label='ìƒí˜¸ í•™ìŠµ í›„', alpha=0.8)\n",
        "    ax1.set_xlabel('ì—ì´ì „íŠ¸')\n",
        "    ax1.set_ylabel('MSE')\n",
        "    ax1.set_title('ìƒí˜¸ í•™ìŠµ ì „í›„ MSE ë¹„êµ')\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels(agents_list)\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # ê°œì„ ìœ¨ ê³„ì‚°\n",
        "    improvements = [((pre - post) / pre) * 100 for pre, post in zip(pre_mse, post_mse)]\n",
        "    colors = ['green' if imp > 0 else 'red' for imp in improvements]\n",
        "    \n",
        "    ax2.bar(agents_list, improvements, color=colors, alpha=0.7)\n",
        "    ax2.set_xlabel('ì—ì´ì „íŠ¸')\n",
        "    ax2.set_ylabel('ê°œì„ ìœ¨ (%)')\n",
        "    ax2.set_title('ìƒí˜¸ í•™ìŠµ ì„±ëŠ¥ ê°œì„ ìœ¨')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # ê°œì„ ìœ¨ ì¶œë ¥\n",
        "    print(\"\\nğŸ“Š ìƒí˜¸ í•™ìŠµ ì„±ëŠ¥ ê°œì„ ìœ¨:\")\n",
        "    for agent, improvement in zip(agents_list, improvements):\n",
        "        print(f\"   - {agent}: {improvement:+.2f}%\")\n",
        "else:\n",
        "    print(\"âš ï¸ ìƒí˜¸ í•™ìŠµ ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\n",
        "print(\"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”...\")\n",
        "\n",
        "# ìµœê·¼ ë°ì´í„°ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰\n",
        "recent_data = X_t[-10:]  # ìµœê·¼ 10ê°œ ìƒ˜í”Œ\n",
        "recent_targets = y_t[-10:]\n",
        "\n",
        "predictions = {}\n",
        "for agent_name, agent in agents.items():\n",
        "    with torch.no_grad():\n",
        "        pred = agent.forward(recent_data)\n",
        "        predictions[agent_name] = pred.numpy()\n",
        "\n",
        "# ì‹œê°í™”\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
        "\n",
        "# ì‹¤ì œ vs ì˜ˆì¸¡ ë¹„êµ\n",
        "time_steps = range(len(recent_targets))\n",
        "ax1.plot(time_steps, recent_targets.numpy(), 'o-', label='ì‹¤ì œê°’', linewidth=2, markersize=6)\n",
        "for agent_name, pred in predictions.items():\n",
        "    ax1.plot(time_steps, pred, 's-', label=f'{agent_name} ì˜ˆì¸¡', alpha=0.7, markersize=4)\n",
        "\n",
        "ax1.set_xlabel('ì‹œê°„ ë‹¨ê³„')\n",
        "ax1.set_ylabel('ì •ê·œí™”ëœ ê°€ê²©')\n",
        "ax1.set_title(f'{TICKER} ìµœê·¼ ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„ì„\n",
        "errors = {}\n",
        "for agent_name, pred in predictions.items():\n",
        "    error = np.abs(pred - recent_targets.numpy())\n",
        "    errors[agent_name] = error\n",
        "    ax2.plot(time_steps, error, 'o-', label=f'{agent_name} ì˜¤ì°¨', alpha=0.7, markersize=4)\n",
        "\n",
        "ax2.set_xlabel('ì‹œê°„ ë‹¨ê³„')\n",
        "ax2.set_ylabel('ì ˆëŒ€ ì˜¤ì°¨')\n",
        "ax2.set_title('ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„ì„')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ì˜¤ì°¨ í†µê³„\n",
        "print(\"\\nğŸ“Š ì˜ˆì¸¡ ì˜¤ì°¨ í†µê³„:\")\n",
        "for agent_name, error in errors.items():\n",
        "    mae = np.mean(error)\n",
        "    rmse = np.sqrt(np.mean(error**2))\n",
        "    print(f\"   - {agent_name}: MAE={mae:.4f}, RMSE={rmse:.4f}\")\n",
        "\n",
        "print(\"\\nğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”§ ë¬¸ì œ í•´ê²° ë° ë””ë²„ê¹…\n",
        "\n",
        "ë§Œì•½ ì˜¤ë¥˜ê°€ ë°œìƒí•œë‹¤ë©´, ë‹¤ìŒ ì…€ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì œë¥¼ ì§„ë‹¨í•˜ê³  í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë°ì´í„° ì°¨ì› ë¬¸ì œ ì§„ë‹¨\n",
        "print(\"ğŸ” ë°ì´í„° ì°¨ì› ë¬¸ì œ ì§„ë‹¨...\")\n",
        "\n",
        "# ê° ì—ì´ì „íŠ¸ê°€ ê¸°ëŒ€í•˜ëŠ” ì…ë ¥ ì°¨ì› í™•ì¸\n",
        "for agent_name, agent in agents.items():\n",
        "    print(f\"\\nğŸ¤– {agent_name} Agent:\")\n",
        "    print(f\"   - ëª¨ë¸ íƒ€ì…: {type(agent).__name__}\")\n",
        "    \n",
        "    # ëª¨ë¸ êµ¬ì¡° í™•ì¸\n",
        "    if hasattr(agent, 'lstm'):\n",
        "        print(f\"   - LSTM ì…ë ¥ í¬ê¸°: {agent.lstm.input_size}\")\n",
        "    if hasattr(agent, 'tcn'):\n",
        "        print(f\"   - TCN ì…ë ¥ í¬ê¸°: {agent.tcn.input_size}\")\n",
        "    if hasattr(agent, 'transformer'):\n",
        "        print(f\"   - Transformer ì…ë ¥ í¬ê¸°: {agent.transformer.input_size}\")\n",
        "    \n",
        "    # ì‹¤ì œ ë°ì´í„° ì°¨ì›\n",
        "    X_agent, y_agent = datasets[agent_name]\n",
        "    print(f\"   - ì‹¤ì œ ë°ì´í„° ì°¨ì›: {X_agent.shape}\")\n",
        "    print(f\"   - í”¼ì²˜ ìˆ˜: {X_agent.shape[2]}\")\n",
        "\n",
        "print(\"\\nğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
        "print(\"   - ê° ì—ì´ì „íŠ¸ë³„ë¡œ ì ì ˆí•œ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\")\n",
        "print(\"   - Technical Agent: 10ê°œ í”¼ì²˜\")\n",
        "print(\"   - Fundamental Agent: 16ê°œ í”¼ì²˜\") \n",
        "print(\"   - Sentimental Agent: 8ê°œ í”¼ì²˜\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê°œë³„ ë‹¨ê³„ í…ŒìŠ¤íŠ¸\n",
        "print(\"ğŸ§ª ê°œë³„ ë‹¨ê³„ í…ŒìŠ¤íŠ¸...\")\n",
        "\n",
        "# Stage 0ë§Œ í…ŒìŠ¤íŠ¸\n",
        "print(\"\\nğŸ“Š Stage 0 í…ŒìŠ¤íŠ¸ (ë°ì´í„° ìˆ˜ì§‘):\")\n",
        "try:\n",
        "    from core.preprocessing import build_dataset\n",
        "    X_test, y_test, scaler_X_test, scaler_y_test = build_dataset(\"AAPL\")  # ë‹¤ë¥¸ í‹°ì»¤ë¡œ í…ŒìŠ¤íŠ¸\n",
        "    print(f\"âœ… Stage 0 ì„±ê³µ: {X_test.shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Stage 0 ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "# Stage 1ë§Œ í…ŒìŠ¤íŠ¸ (ë‹¨ì¼ ì—ì´ì „íŠ¸)\n",
        "print(\"\\nğŸ§  Stage 1 í…ŒìŠ¤íŠ¸ (ë‹¨ì¼ ì—ì´ì „íŠ¸ í›ˆë ¨):\")\n",
        "try:\n",
        "    from agents.technical_agent import TechnicalAgent\n",
        "    from core.training import pretrain_agent\n",
        "    \n",
        "    test_agent = TechnicalAgent(\"TestAgent\")\n",
        "    X_small = X_t[:10]  # ì‘ì€ ë°ì´í„°ì…‹ìœ¼ë¡œ í…ŒìŠ¤íŠ¸\n",
        "    y_small = y_t[:10]\n",
        "    \n",
        "    pretrain_agent(test_agent, X_small, y_small, epochs=2)\n",
        "    print(\"âœ… Stage 1 ì„±ê³µ\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Stage 1 ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "print(\"\\nğŸ’¡ ê° ë‹¨ê³„ë¥¼ ê°œë³„ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ì—¬ ë¬¸ì œë¥¼ ê²©ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
