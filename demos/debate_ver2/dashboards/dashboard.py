import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import numpy as np
import os
import sys
import torch
import subprocess
import json
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ì‹œìŠ¤í…œ import
from core.preprocessing import build_dataset, load_csv_dataset
from core.training import pretrain_all_agents
from core.debate_engine import mutual_learning_with_individual_data
from agents.technical_agent import TechnicalAgent
from agents.fundamental_agent import FundamentalAgent
from agents.sentimental_agent import SentimentalAgent

# ë¡œê·¸ ìº¡ì²˜ë¥¼ ìœ„í•œ í´ë˜ìŠ¤
class StreamlitLogger:
    def __init__(self):
        self.logs = []
        self.max_logs = 1000
    
    def write(self, message):
        if message.strip():
            timestamp = datetime.now().strftime("%H:%M:%S")
            self.logs.append(f"[{timestamp}] {message.strip()}")
            if len(self.logs) > self.max_logs:
                self.logs.pop(0)
    
    def flush(self):
        pass
    
    def get_logs(self):
        return self.logs
    
    def clear(self):
        self.logs = []

# ì „ì—­ ë¡œê±° ì¸ìŠ¤í„´ìŠ¤
if 'logger' not in st.session_state:
    st.session_state.logger = StreamlitLogger()

def log_msg(message):
    """ë¡œê·¸ ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì¶”ê°€"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    log_entry = f"[{timestamp}] {message}"
    st.session_state.logger.logs.append(log_entry)
    if len(st.session_state.logger.logs) > 1000:
        st.session_state.logger.logs.pop(0)

# --------------------------------------------
# ë°ì´í„° ìˆ˜ì§‘ ë‹¨ê³„
# --------------------------------------------
def collect_data_stage(ticker):
    """Stage 0: ë°ì´í„° ìˆ˜ì§‘"""
    log_msg(f"ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {ticker}")
    
    try:
        # CSVì—ì„œ ë°ì´í„° ë¡œë“œ ì‹œë„
        try:
            X, y, scaler_X, scaler_y, feature_cols = load_csv_dataset(ticker)
            data_info = {
                "processed_data": X,
                "targets": y,
                "scaler_X": scaler_X,
                "scaler_y": scaler_y,
                "feature_cols": feature_cols
            }
            log_msg(f"âœ… CSVì—ì„œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {X.shape}")
        except FileNotFoundError:
            log_msg("ğŸ“¥ CSV íŒŒì¼ì´ ì—†ì–´ì„œ ìƒˆë¡œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...")
            data_info = build_dataset(ticker)
            log_msg(f"âœ… ìƒˆ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {data_info['processed_data'].shape}")
        
        # ë‚ ì§œ ë²”ìœ„ ì²˜ë¦¬
        raw_df = pd.read_csv(f"data/processed/{ticker}_raw_data.csv", index_col=0, parse_dates=True)
        min_date = raw_df.index.min()
        max_date = raw_df.index.max()
        
        # ë‚ ì§œê°€ ì´ë¯¸ datetime ê°ì²´ì¸ì§€ í™•ì¸
        if hasattr(min_date, 'strftime'):
            date_range = f"{min_date.strftime('%Y-%m-%d')} ~ {max_date.strftime('%Y-%m-%d')}"
        else:
            date_range = f"{str(min_date)[:10]} ~ {str(max_date)[:10]}"
        
        st.session_state.data_info = data_info
        st.session_state.data_info["date_range"] = date_range
        st.session_state.data_info["ticker"] = ticker
        
        log_msg("âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        return True
        
    except Exception as e:
        log_msg(f"âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return False

# --------------------------------------------
# ì‚¬ì „í•™ìŠµ ë‹¨ê³„
# --------------------------------------------
def pretraining_stage(epochs, ticker):
    """Stage 1: ì‚¬ì „í•™ìŠµ"""
    log_msg("ğŸ§  ì‚¬ì „í•™ìŠµ ì‹œì‘")
    
    try:
        # Agent ì´ˆê¸°í™”
        agents = {
            "technical": TechnicalAgent("TechnicalAgent"),
            "fundamental": FundamentalAgent("FundamentalAgent"),
            "sentimental": SentimentalAgent("SentimentalAgent"),
        }
        
        # ê° ì—ì´ì „íŠ¸ë³„ë¡œ ì ì ˆí•œ ë°ì´í„°ì…‹ ì¤€ë¹„
        datasets = {}
        scalers = {}
        for name, agent in agents.items():
            try:
                X, y, scaler_X, scaler_y, _ = load_csv_dataset(ticker, name)
                X_t = torch.tensor(X, dtype=torch.float32)
                y_t = torch.tensor(y, dtype=torch.float32)
                datasets[name] = (X_t, y_t)
                scalers[name] = scaler_y
                log_msg(f"âœ… {name} ë°ì´í„°ì…‹ ë¡œë“œ: {X_t.shape}")
            except FileNotFoundError:
                log_msg(f"âš ï¸ {name} ë°ì´í„°ì…‹ ì—†ìŒ, ê¸°ë³¸ ë°ì´í„° ì‚¬ìš©")
                # ê¸°ë³¸ ë°ì´í„° ì‚¬ìš© (ëª¨ë“  ì—ì´ì „íŠ¸ê°€ ê³µí†µìœ¼ë¡œ ì‚¬ìš©)
                data_info = st.session_state.data_info
                X, y = data_info["processed_data"], data_info["targets"]
                X_t, y_t = torch.tensor(X), torch.tensor(y)
                datasets[name] = (X_t, y_t)
                scalers[name] = data_info.get("scaler_y", None)
        
        # Agent ì •ë³´ ì €ì¥
        agents_info = {}
        for name, agent in agents.items():
            agents_info[name] = {
                "agent_id": agent.agent_id,
                "parameters": sum(p.numel() for p in agent.parameters() if p.requires_grad),
                "model_type": type(agent).__name__
            }
        
        st.session_state.agents_info = agents_info
        
        # ì‚¬ì „í•™ìŠµ
        pretrain_all_agents(agents, datasets, epochs=epochs, save_models=True)
        
        # í•™ìŠµ í›„ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ì£¼ê°€ì™€ ë¹„êµ ê°€ëŠ¥í•˜ë„ë¡)
        predictions = {}
        actual_prices = {}
        
        for name, agent in agents.items():
            X_agent, y_agent = datasets[name]
            with torch.no_grad():
                # ìŠ¤ì¼€ì¼ë§ëœ ì˜ˆì¸¡ê°’
                preds_scaled = agent.forward(X_agent[:10]).detach().numpy().flatten()
                predictions[name] = preds_scaled
                
                # ì‹¤ì œ ì£¼ê°€ ë°ì´í„°ë¡œ ì˜ˆì¸¡ (ìŠ¤ì¼€ì¼ë§ í•´ì œëœ ê°’)
                try:
                    stock_data = agent.searcher(ticker)
                    target = agent.predicter(stock_data)
                    # ì •ê·œí™”ëœ ì˜ˆì¸¡ê°’ì„ ì‹¤ì œ ì£¼ê°€ë¡œ ë³€í™˜
                    if name in scalers and scalers[name] is not None:
                        scaler_y = scalers[name]
                        # ì •ê·œí™”ëœ ê°’ì„ ì‹¤ì œ ì£¼ê°€ë¡œ ì—­ë³€í™˜
                        normalized_pred = np.array([[target.next_close]])
                        actual_price = scaler_y.inverse_transform(normalized_pred)[0][0]
                        log_msg(f"ğŸ” {name} Agent: ì •ê·œí™”ê°’={target.next_close:.6f} â†’ ì‹¤ì œì£¼ê°€={actual_price:.2f}")
                        actual_prices[name] = actual_price
                    else:
                        log_msg(f"âš ï¸ {name} Agent: ìŠ¤ì¼€ì¼ëŸ¬ ì—†ìŒ, ì •ê·œí™”ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš©={target.next_close:.6f}")
                        actual_prices[name] = target.next_close
                except Exception as e:
                    log_msg(f"âš ï¸ {name} Agent ì‹¤ì œ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                    actual_prices[name] = 100.0
        
        st.session_state.pipeline_results["pretraining"] = {
            "agents": agents,
            "predictions": predictions,
            "actual_prices": actual_prices,
            "epochs": epochs
        }
        
        log_msg("âœ… ì‚¬ì „í•™ìŠµ ì™„ë£Œ")
        return True
        
    except Exception as e:
        log_msg(f"âŒ ì‚¬ì „í•™ìŠµ ì‹¤íŒ¨: {e}")
        return False

    # --------------------------------------------
# ìƒí˜¸í•™ìŠµ ë‹¨ê³„
# --------------------------------------------
def mutual_learning_stage(rounds, ticker):
    """Stage 2: ìƒí˜¸í•™ìŠµ"""
    log_msg("ğŸ” ìƒí˜¸í•™ìŠµ ì‹œì‘")
    
    try:
        agents = st.session_state.pipeline_results["pretraining"]["agents"]
        
        # ê° ì—ì´ì „íŠ¸ë³„ë¡œ ì ì ˆí•œ ë°ì´í„°ì…‹ ì¤€ë¹„
        datasets = {}
        scalers = {}
        for name, agent in agents.items():
            try:
                X, y, scaler_X, scaler_y, _ = load_csv_dataset(ticker, name)
                X_t = torch.tensor(X, dtype=torch.float32)
                y_t = torch.tensor(y, dtype=torch.float32)
                datasets[name] = (X_t, y_t)
                scalers[name] = scaler_y
                log_msg(f"âœ… {name} ë°ì´í„°ì…‹ ë¡œë“œ: {X_t.shape}")
            except FileNotFoundError:
                log_msg(f"âš ï¸ {name} ë°ì´í„°ì…‹ ì—†ìŒ, ê¸°ë³¸ ë°ì´í„° ì‚¬ìš©")
                # ê¸°ë³¸ ë°ì´í„° ì‚¬ìš© (ëª¨ë“  ì—ì´ì „íŠ¸ê°€ ê³µí†µìœ¼ë¡œ ì‚¬ìš©)
                data_info = st.session_state.data_info
                X, y = data_info["processed_data"], data_info["targets"]
                X_t, y_t = torch.tensor(X), torch.tensor(y)
                datasets[name] = (X_t, y_t)
                scalers[name] = data_info.get("scaler_y", None)
        
        # ìƒí˜¸í•™ìŠµ ì „ ì˜ˆì¸¡ê°’ ì €ì¥
        initial_predictions = {}
        initial_actual_prices = {}
        for name, agent in agents.items():
            X_agent, y_agent = datasets[name]
            with torch.no_grad():
                preds = agent.forward(X_agent).detach().numpy()
                initial_predictions[name] = preds.flatten()
                
                try:
                    stock_data = agent.searcher(ticker)
                    target = agent.predicter(stock_data)
                    # ì •ê·œí™”ëœ ì˜ˆì¸¡ê°’ì„ ì‹¤ì œ ì£¼ê°€ë¡œ ë³€í™˜
                    if name in scalers and scalers[name] is not None:
                        scaler_y = scalers[name]
                        normalized_pred = np.array([[target.next_close]])
                        actual_price = scaler_y.inverse_transform(normalized_pred)[0][0]
                        initial_actual_prices[name] = actual_price
                    else:
                        initial_actual_prices[name] = target.next_close
                except Exception as e:
                    log_msg(f"âš ï¸ {name} Agent ì´ˆê¸° ì‹¤ì œ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                    initial_actual_prices[name] = 100.0
        
        # ìƒí˜¸í•™ìŠµ ì‹¤í–‰
        mutual_learning_with_individual_data(agents, datasets, rounds=rounds, save_models=True)
        
        # ìƒí˜¸í•™ìŠµ í›„ ì˜ˆì¸¡ê°’ ì €ì¥
        final_predictions = {}
        final_actual_prices = {}
        for name, agent in agents.items():
            X_agent, y_agent = datasets[name]
            with torch.no_grad():
                preds = agent.forward(X_agent).detach().numpy()
                final_predictions[name] = preds.flatten()
                
                try:
                    stock_data = agent.searcher(ticker)
                    target = agent.predicter(stock_data)
                    # ì •ê·œí™”ëœ ì˜ˆì¸¡ê°’ì„ ì‹¤ì œ ì£¼ê°€ë¡œ ë³€í™˜
                    if name in scalers and scalers[name] is not None:
                        scaler_y = scalers[name]
                        normalized_pred = np.array([[target.next_close]])
                        actual_price = scaler_y.inverse_transform(normalized_pred)[0][0]
                        final_actual_prices[name] = actual_price
                    else:
                        final_actual_prices[name] = target.next_close
                except Exception as e:
                    log_msg(f"âš ï¸ {name} Agent ìµœì¢… ì‹¤ì œ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                    final_actual_prices[name] = 100.0
        
        st.session_state.pipeline_results["mutual_learning"] = {
            "agents": agents,
            "initial_predictions": initial_predictions,
            "final_predictions": final_predictions,
            "initial_actual_prices": initial_actual_prices,
            "final_actual_prices": final_actual_prices,
            "rounds": rounds
        }
        
        log_msg("âœ… ìƒí˜¸í•™ìŠµ ì™„ë£Œ")
        return True
        
    except Exception as e:
        log_msg(f"âŒ ìƒí˜¸í•™ìŠµ ì‹¤íŒ¨: {e}")
        return False

# --------------------------------------------
# ë””ë² ì´íŠ¸ ë‹¨ê³„
    # --------------------------------------------
def debate_stage(ticker, rounds):
    """Stage 3: ë””ë² ì´íŠ¸"""
    log_msg("ğŸ’¬ ë””ë² ì´íŠ¸ ì‹œì‘")
    
    try:
        agents = st.session_state.pipeline_results["mutual_learning"]["agents"]
        data_info = st.session_state.data_info
        
        # ê° ì—ì´ì „íŠ¸ë³„ ìŠ¤ì¼€ì¼ëŸ¬ ì¤€ë¹„
        scalers = {}
        for name, agent in agents.items():
            try:
                _, _, _, scaler_y, _ = load_csv_dataset(ticker, name)
                scalers[name] = scaler_y
            except FileNotFoundError:
                scalers[name] = data_info.get("scaler_y", None)
        
        # ë¼ìš´ë“œë³„ ê²°ê³¼ ìˆ˜ì§‘
        debate_results = []
        for round_num in range(1, rounds + 1):
            log_msg(f"ğŸ’¬ ë””ë² ì´íŠ¸ ë¼ìš´ë“œ {round_num} ì‹œì‘")
            
            round_predictions = {}
            for name, agent in agents.items():
                try:
                    stock_data = agent.searcher(ticker)
                    target = agent.predicter(stock_data)
                    # ì •ê·œí™”ëœ ì˜ˆì¸¡ê°’ì„ ì‹¤ì œ ì£¼ê°€ë¡œ ë³€í™˜
                    if hasattr(st.session_state, 'data_info') and 'scaler_y' in st.session_state.data_info:
                        scaler_y = st.session_state.data_info['scaler_y']
                        normalized_pred = np.array([[target.next_close]])
                        actual_price = scaler_y.inverse_transform(normalized_pred)[0][0]
                        round_predictions[name] = actual_price
                    else:
                        round_predictions[name] = target.next_close
                except Exception as e:
                    log_msg(f"âš ï¸ {name} Agent ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                    round_predictions[name] = 100.0
            
            round_consensus = sum(round_predictions.values()) / len(round_predictions)
            debate_results.append({
                "round": round_num,
                "predictions": round_predictions,
                "consensus": round_consensus
            })
            log_msg(f"ğŸ“Š ë¼ìš´ë“œ {round_num} í•©ì˜: {round_consensus:.2f}")
        
        # ìµœì¢… í‰ê°€ (ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„° ì‚¬ìš©)
        X, y = data_info["processed_data"], data_info["targets"]
        X_t, y_t = torch.tensor(X), torch.tensor(y)
        
        evaluation_results = {}
        for name, agent in agents.items():
            try:
                with torch.no_grad():
                    preds = agent.forward(X_t).detach().numpy().flatten()
                    y_true = y_t.numpy().flatten()
                    
                    mse = np.mean((preds - y_true) ** 2)
                    rmse = np.sqrt(mse)
                    mae = np.mean(np.abs(preds - y_true))
                    ss_res = np.sum((y_true - preds) ** 2)
                    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)
                    r2 = 1 - (ss_res / (ss_tot + 1e-8))
                    
                    evaluation_results[name] = {
                        "RMSE": rmse,
                        "MAE": mae,
                        "R2": r2,
                        "MSE": mse
                    }
            except Exception as e:
                log_msg(f"âš ï¸ {name} Agent í‰ê°€ ì‹¤íŒ¨: {e}")
                evaluation_results[name] = {
                    "RMSE": 0.0, "MAE": 0.0, "R2": 0.0, "MSE": 0.0
                }
        
        final_consensus = {
            "mean": debate_results[-1]["consensus"] if debate_results else 0.0,
            "std": np.std([r["consensus"] for r in debate_results]) if debate_results else 0.0,
            "rounds": rounds
        }
        
        st.session_state.pipeline_results["debate"] = {
            "agents": agents,
            "evaluation_results": evaluation_results,
            "consensus": final_consensus,
            "round_results": debate_results,
            "rounds": rounds
        }
        
        log_msg("âœ… ë””ë² ì´íŠ¸ ì™„ë£Œ")
        return True
        
    except Exception as e:
        log_msg(f"âŒ ë””ë² ì´íŠ¸ ì‹¤íŒ¨: {e}")
        return False

# --------------------------------------------
# ë©”ì¸ ëŒ€ì‹œë³´ë“œ
# --------------------------------------------
def main():
    st.set_page_config(
        page_title="MCP Hybrid System Dashboard",
        page_icon="ğŸ¤–",
        layout="wide"
    )
    
    st.title("ğŸ¤– MCP Hybrid System Dashboard")
    st.markdown("**Multi-Agent Collaborative Prediction System**")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.header("ğŸ›ï¸ ì‹œìŠ¤í…œ ì„¤ì •")
    
    with st.sidebar.expander("â„¹ï¸ ì‚¬ìš©ë²•"):
        st.markdown("""
        **MCP Hybrid System ì‚¬ìš©ë²•:**
        
        1. **Ticker**: ë¶„ì„í•  ì¢…ëª© ì½”ë“œ ì…ë ¥
        2. **Epochs**: ì‚¬ì „í•™ìŠµ ë°˜ë³µ íšŸìˆ˜ (ë†’ì„ìˆ˜ë¡ ì •í™•í•˜ì§€ë§Œ ì‹œê°„ ì†Œìš”)
        3. **Mutual Rounds**: ìƒí˜¸í•™ìŠµ ë¼ìš´ë“œ ìˆ˜
        4. **Debate Rounds**: LLM í† ë¡  ë¼ìš´ë“œ ìˆ˜
        5. **ë¶„ì„ ì‹œì‘** ë²„íŠ¼ í´ë¦­
        
        **ê¶Œì¥ ì„¤ì •:**
        - ë¹ ë¥¸ í…ŒìŠ¤íŠ¸: Epochs=5, Rounds=1
        - ì •í™•í•œ ë¶„ì„: Epochs=20, Rounds=3
        """)
    
    ticker = st.sidebar.text_input("Ticker Symbol", "TSLA", help="ì˜ˆ: TSLA, AAPL, MSFT")
    epochs = st.sidebar.slider("Pretraining Epochs", 5, 50, 20, help="ì‚¬ì „í•™ìŠµ ë°˜ë³µ íšŸìˆ˜")
    mutual_rounds = st.sidebar.slider("Mutual Learning Rounds", 1, 10, 3, help="ìƒí˜¸í•™ìŠµ ë¼ìš´ë“œ ìˆ˜")
    debate_rounds = st.sidebar.slider("Debate Rounds", 1, 5, 2, help="LLM í† ë¡  ë¼ìš´ë“œ ìˆ˜")
    
    run_button = st.sidebar.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "pipeline_results" not in st.session_state:
        st.session_state.pipeline_results = {}
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    if run_button:
        st.session_state.pipeline_results = {}
        st.session_state.logger.clear()
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # Stage 0: ë°ì´í„° ìˆ˜ì§‘
        status_text.text("ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        progress_bar.progress(10)
        if collect_data_stage(ticker):
            progress_bar.progress(25)
            
            # Stage 1: ì‚¬ì „í•™ìŠµ
            status_text.text("ğŸ§  ì‚¬ì „í•™ìŠµ ì¤‘...")
            if pretraining_stage(epochs, ticker):
                progress_bar.progress(50)
                
                # Stage 2: ìƒí˜¸í•™ìŠµ
                status_text.text("ğŸ” ìƒí˜¸í•™ìŠµ ì¤‘...")
                if mutual_learning_stage(mutual_rounds, ticker):
                    progress_bar.progress(75)
                    
                    # Stage 3: ë””ë² ì´íŠ¸
                    status_text.text("ğŸ’¬ ë””ë² ì´íŠ¸ ì¤‘...")
                    if debate_stage(ticker, debate_rounds):
                        progress_bar.progress(100)
                        status_text.text("âœ… ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ!")
                    else:
                        status_text.text("âŒ ë””ë² ì´íŠ¸ ì‹¤íŒ¨")
                else:
                    status_text.text("âŒ ìƒí˜¸í•™ìŠµ ì‹¤íŒ¨")
            else:
                status_text.text("âŒ ì‚¬ì „í•™ìŠµ ì‹¤íŒ¨")
        else:
            status_text.text("âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
    
    # ë¡œê·¸ í‘œì‹œ
    with st.sidebar.expander("ğŸ§¾ ì‹¤í–‰ ë¡œê·¸", expanded=False):
        logs = st.session_state.logger.get_logs()
        if logs:
            # ìµœê·¼ 10ê°œ ë¡œê·¸ë§Œ í‘œì‹œ
            recent_logs = logs[-10:] if len(logs) > 10 else logs
            for log in recent_logs:
                st.text(log)
        else:
            st.text("ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # íƒ­ êµ¬ì„±
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ë°ì´í„° ìˆ˜ì§‘", "ì‚¬ì „í•™ìŠµ", "ìƒí˜¸í•™ìŠµ", "ë””ë² ì´íŠ¸", "ì¢…í•© ê²°ê³¼"])
    
    # ë°ì´í„° ìˆ˜ì§‘ íƒ­
    with tab1:
        st.header("ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ê²°ê³¼")
        
        if "data_info" in st.session_state:
            data_info = st.session_state.data_info
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Ticker", data_info.get("ticker", "N/A"))
            with col2:
                st.metric("ë°ì´í„° í¬ì¸íŠ¸", f"{data_info['processed_data'].shape[0]:,}")
            with col3:
                st.metric("í”¼ì²˜ ìˆ˜", data_info['processed_data'].shape[1])
            
            if "date_range" in data_info:
                st.info(f"ğŸ“… ë°ì´í„° ê¸°ê°„: {data_info['date_range']}")
            
            # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
            st.subheader("ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
            raw_df = pd.read_csv(f"data/processed/{data_info.get('ticker', 'TSLA')}_raw_data.csv", index_col=0, parse_dates=True)
            st.dataframe(raw_df.head(10), width='stretch')
            
            # ê°€ê²© ì°¨íŠ¸
            st.subheader("ğŸ“ˆ ê°€ê²© ì°¨íŠ¸")
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=raw_df.index,
                y=raw_df['Close'],
                mode='lines',
                name='Close Price',
                line=dict(color='blue', width=2)
            ))
            fig.update_layout(
                title=f"{data_info.get('ticker', 'TSLA')} ì£¼ê°€ ì°¨íŠ¸",
                xaxis_title="ë‚ ì§œ",
                yaxis_title="ê°€ê²© ($)",
                height=400
            )
            st.plotly_chart(fig, width='stretch')
        else:
            st.info("ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ë ¤ë©´ 'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
    
    # ì‚¬ì „í•™ìŠµ íƒ­
    with tab2:
        st.header("ğŸ§  ì‚¬ì „í•™ìŠµ ê²°ê³¼")
        
        if "pretraining" in st.session_state.pipeline_results:
            pretraining_data = st.session_state.pipeline_results["pretraining"]
            
            # Agent ì •ë³´
            if "agents_info" in st.session_state:
                st.subheader("ğŸ¤– Agent ì •ë³´")
                agents_info = st.session_state.agents_info
                
                for name, info in agents_info.items():
                    with st.expander(f"{info['agent_id']} ({info['model_type']})"):
                        st.write(f"**íŒŒë¼ë¯¸í„° ìˆ˜**: {info['parameters']:,}")
                        st.write(f"**ëª¨ë¸ íƒ€ì…**: {info['model_type']}")
            
            # ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ
            st.subheader("ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ")
            
            if "actual_prices" in pretraining_data:
                actual_prices = pretraining_data["actual_prices"]
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write("**ì‹¤ì œ ì£¼ê°€ ì˜ˆì¸¡ê°’**")
                    for name, price in actual_prices.items():
                        st.metric(f"{name.title()} Agent", f"${price:.2f}")
                
                with col2:
                    st.write("**ìŠ¤ì¼€ì¼ë§ëœ ì˜ˆì¸¡ê°’**")
                    predictions = pretraining_data["predictions"]
                    for name, preds in predictions.items():
                        avg_pred = np.mean(preds)
                        st.metric(f"{name.title()} Agent", f"{avg_pred:.4f}")
            
            # í•™ìŠµ ì§„í–‰ë„
            st.subheader("ğŸ“ˆ í•™ìŠµ ì§„í–‰ë„")
            epochs = pretraining_data.get("epochs", 0)
            st.info(f"âœ… {epochs} ì—í¬í¬ ì‚¬ì „í•™ìŠµ ì™„ë£Œ")
            
        else:
            st.info("ì‚¬ì „í•™ìŠµì„ ì‹¤í–‰í•˜ë ¤ë©´ 'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
    
    # ìƒí˜¸í•™ìŠµ íƒ­
    with tab3:
        st.header("ğŸ” ìƒí˜¸í•™ìŠµ ê²°ê³¼")
        
        if "mutual_learning" in st.session_state.pipeline_results:
            mutual_data = st.session_state.pipeline_results["mutual_learning"]
            
            # ìƒí˜¸í•™ìŠµ ì „í›„ ë¹„êµ
            st.subheader("ğŸ“Š ìƒí˜¸í•™ìŠµ ì „í›„ ë¹„êµ")
            
            if "initial_actual_prices" in mutual_data and "final_actual_prices" in mutual_data:
                initial_prices = mutual_data["initial_actual_prices"]
                final_prices = mutual_data["final_actual_prices"]
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.write("**ìƒí˜¸í•™ìŠµ ì „**")
                    for name, price in initial_prices.items():
                        st.metric(f"{name.title()} Agent", f"${price:.2f}")
                
                with col2:
                    st.write("**ìƒí˜¸í•™ìŠµ í›„**")
                    for name, price in final_prices.items():
                        st.metric(f"{name.title()} Agent", f"${price:.2f}")
                
                with col3:
                    st.write("**ë³€í™”ëŸ‰**")
                    for name in initial_prices.keys():
                        change = final_prices[name] - initial_prices[name]
                        st.metric(f"{name.title()} Agent", f"{change:+.2f}")
            
            # ìƒí˜¸í•™ìŠµ ì§„í–‰ë„
            st.subheader("ğŸ“ˆ ìƒí˜¸í•™ìŠµ ì§„í–‰ë„")
            rounds = mutual_data.get("rounds", 0)
            st.info(f"âœ… {rounds} ë¼ìš´ë“œ ìƒí˜¸í•™ìŠµ ì™„ë£Œ")
            
        else:
            st.info("ìƒí˜¸í•™ìŠµì„ ì‹¤í–‰í•˜ë ¤ë©´ 'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
    
    # ë””ë² ì´íŠ¸ íƒ­
    with tab4:
        st.header("ğŸ’¬ ë””ë² ì´íŠ¸ ê²°ê³¼")
        
        if "debate" in st.session_state.pipeline_results:
            debate_data = st.session_state.pipeline_results["debate"]
            
            # ë¼ìš´ë“œë³„ ê²°ê³¼
            if "round_results" in debate_data:
                st.subheader("ğŸ“Š ë¼ìš´ë“œë³„ ë””ë² ì´íŠ¸ ê²°ê³¼")
                
                round_results = debate_data["round_results"]
                
                # ë¼ìš´ë“œë³„ ì°¨íŠ¸
                rounds = [r["round"] for r in round_results]
                consensus_values = [r["consensus"] for r in round_results]
                
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=rounds,
                    y=consensus_values,
                    mode='lines+markers',
                    name='Consensus',
                    line=dict(color='red', width=3),
                    marker=dict(size=8)
                ))
                
                fig.update_layout(
                    title="ë¼ìš´ë“œë³„ í•©ì˜ ê°€ê²©",
                    xaxis_title="ë¼ìš´ë“œ",
                    yaxis_title="í•©ì˜ ê°€ê²© ($)",
                    height=400
                )
                st.plotly_chart(fig, width='stretch')
                
                # ë¼ìš´ë“œë³„ ìƒì„¸ ê²°ê³¼ í…Œì´ë¸”
                st.subheader("ğŸ“‹ ë¼ìš´ë“œë³„ ìƒì„¸ ê²°ê³¼")
                round_data = []
                for result in round_results:
                    row = {"ë¼ìš´ë“œ": result["round"], "í•©ì˜": f"${result['consensus']:.2f}"}
                    for name, pred in result["predictions"].items():
                        row[f"{name.title()} Agent"] = f"${pred:.2f}"
                    round_data.append(row)
                
                round_df = pd.DataFrame(round_data)
                st.dataframe(round_df, width='stretch')
            
            # ì„±ëŠ¥ í‰ê°€
            if "evaluation_results" in debate_data:
                st.subheader("ğŸ“ˆ ì„±ëŠ¥ í‰ê°€")
                
                evaluation_results = debate_data["evaluation_results"]
                
                col1, col2, col3 = st.columns(3)
                
                for i, (name, metrics) in enumerate(evaluation_results.items()):
                    with [col1, col2, col3][i]:
                        st.write(f"**{name.title()} Agent**")
                        st.metric("RMSE", f"{metrics['RMSE']:.4f}")
                        st.metric("MAE", f"{metrics['MAE']:.4f}")
                        st.metric("RÂ²", f"{metrics['R2']:.4f}")
            
            # ìµœì¢… í•©ì˜
            if "consensus" in debate_data:
                st.subheader("ğŸ¯ ìµœì¢… í•©ì˜")
                consensus = debate_data["consensus"]
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("í‰ê·  í•©ì˜", f"${consensus['mean']:.2f}")
                with col2:
                    st.metric("í‘œì¤€í¸ì°¨", f"${consensus['std']:.2f}")
            
        else:
            st.info("ë””ë² ì´íŠ¸ë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ 'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
    
    # ì¢…í•© ê²°ê³¼ íƒ­
    with tab5:
        st.header("ğŸ¯ ì¢…í•© ê²°ê³¼")
        
        if st.session_state.pipeline_results:
            st.success("âœ… ëª¨ë“  ë‹¨ê³„ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            # ì „ì²´ íŒŒì´í”„ë¼ì¸ ìš”ì•½
            st.subheader("ğŸ“Š íŒŒì´í”„ë¼ì¸ ìš”ì•½")
            
            if "data_info" in st.session_state:
                data_info = st.session_state.data_info
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("Ticker", data_info.get("ticker", "N/A"))
                with col2:
                    st.metric("ë°ì´í„° í¬ì¸íŠ¸", f"{data_info['processed_data'].shape[0]:,}")
                with col3:
                    st.metric("í”¼ì²˜ ìˆ˜", data_info['processed_data'].shape[1])
                with col4:
                    if "debate" in st.session_state.pipeline_results:
                        consensus = st.session_state.pipeline_results["debate"]["consensus"]
                        st.metric("ìµœì¢… í•©ì˜", f"${consensus['mean']:.2f}")
            
            # ìµœì¢… ì˜ˆì¸¡ê°’ ë¹„êµ
            if "debate" in st.session_state.pipeline_results and "round_results" in st.session_state.pipeline_results["debate"]:
                st.subheader("ğŸ¯ ìµœì¢… ì˜ˆì¸¡ê°’")
                
                final_round = st.session_state.pipeline_results["debate"]["round_results"][-1]
                final_predictions = final_round["predictions"]
                final_consensus = final_round["consensus"]
                
                col1, col2, col3, col4 = st.columns(4)
                
                for i, (name, pred) in enumerate(final_predictions.items()):
                    with [col1, col2, col3][i]:
                        st.metric(f"{name.title()} Agent", f"${pred:.2f}")
                
                with col4:
                    st.metric("ìµœì¢… í•©ì˜", f"${final_consensus:.2f}", delta=f"${final_consensus - np.mean(list(final_predictions.values())):+.2f}")
            
        else:
            st.info("ì¢…í•© ê²°ê³¼ë¥¼ ë³´ë ¤ë©´ 'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()
