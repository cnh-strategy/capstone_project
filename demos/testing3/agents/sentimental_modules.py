"""
Sentimental Agentì˜ ëª¨ë“ˆí™”ëœ Searcherì™€ Predictor
ë©”ì¸ ë¸Œëœì¹˜ì˜ SentimentalAgentì— ì„ íƒì ìœ¼ë¡œ í†µí•© ê°€ëŠ¥
"""

import os
import time
import requests
import csv
import pandas as pd
import torch
import numpy as np
from datetime import datetime, timedelta, timezone
from collections import Counter
from transformers import AutoTokenizer, AutoModel
from typing import Dict, List, Optional, Tuple
import yfinance as yf

class SentimentalSearcher:
    """ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“ˆ"""
    
    def __init__(self, api_key: Optional[str] = None, max_calls_per_minute: int = 60):
        self.api_key = api_key or os.getenv('FINNHUB_API_KEY')
        self.base_url = 'https://finnhub.io/api/v1/company-news'
        self.max_calls_per_minute = max_calls_per_minute
        self.call_count = 0
        
    def safe_convert_timestamp(self, timestamp) -> str:
        """ì•ˆì „í•œ íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜"""
        try:
            if timestamp is None or not isinstance(timestamp, (int, float)) or timestamp <= 0:
                return ''
            if timestamp > 32503680000:  # 3000-01-01 00:00:00 UTC ì œí•œ
                return ''
            return datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d %H:%M:%S")
        except Exception:
            return ''
    
    def collect_news_data(self, symbol: str, from_date: str, to_date: str) -> List[Dict]:
        """íŠ¹ì • ì¢…ëª©ì˜ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ - yfinance ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜"""
        print("ğŸ“° yfinance ê¸°ë°˜ ë‰´ìŠ¤ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return self._get_fallback_news(symbol)
    
    def _get_fallback_news(self, symbol: str) -> List[Dict]:
        """API í‚¤ê°€ ì—†ì„ ë•Œ ì‚¬ìš©í•  ê¸°ë³¸ ë‰´ìŠ¤ ë°ì´í„°"""
        return [{
            'date': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'title': f"{symbol} ê´€ë ¨ ë‰´ìŠ¤",
            'summary': f"{symbol} ì¢…ëª©ì— ëŒ€í•œ ìµœì‹  ì‹œì¥ ë™í–¥ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤.",
            'related': symbol
        }]
    
    def get_recent_news(self, symbol: str, days: int = 7) -> List[Dict]:
        """ìµœê·¼ Nì¼ê°„ì˜ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘"""
        to_date = datetime.now().strftime("%Y-%m-%d")
        from_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
        return self.collect_news_data(symbol, from_date, to_date)


class SentimentalPredictor:
    """ML ê¸°ë°˜ ì„¼í‹°ë©˜íƒˆ ì˜ˆì¸¡ ëª¨ë“ˆ"""
    
    def __init__(self, model_path: Optional[str] = None, use_finbert: bool = True):
        self.model_path = model_path or "mlp_stock_model.pt"
        self.use_finbert = use_finbert
        self.model = None
        self.tokenizer = None
        self.finbert_model = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        if self.use_finbert:
            self._load_finbert()
        
        self._load_model()
    
    def _load_finbert(self):
        """FINBERT ëª¨ë¸ ë¡œë“œ"""
        try:
            self.tokenizer = AutoTokenizer.from_pretrained('yiyanghkust/finbert-tone')
            self.finbert_model = AutoModel.from_pretrained('yiyanghkust/finbert-tone')
            print("âœ… FINBERT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ FINBERT ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.use_finbert = False
    
    def _load_model(self):
        """í›ˆë ¨ëœ MLP ëª¨ë¸ ë¡œë“œ"""
        try:
            if os.path.exists(self.model_path):
                # ëª¨ë¸ êµ¬ì¡° ì •ì˜ (sentimental_predictor_3ent.pyì™€ ë™ì¼)
                class MLPRegressor(torch.nn.Module):
                    def __init__(self, input_dim):
                        super().__init__()
                        self.net = torch.nn.Sequential(
                            torch.nn.Linear(input_dim, 128),
                            torch.nn.ReLU(),
                            torch.nn.Linear(128, 64),
                            torch.nn.ReLU(),
                            torch.nn.Linear(64, 1)
                        )
                    def forward(self, x):
                        return self.net(x).squeeze()
                
                self.model = MLPRegressor(input_dim=768).to(self.device)
                self.model.load_state_dict(torch.load(self.model_path, map_location=self.device))
                self.model.eval()
                print("âœ… MLP ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            else:
                print(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
                self.model = None
        except Exception as e:
            print(f"âš ï¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.model = None
    
    def get_finbert_embedding(self, text: str) -> np.ndarray:
        """FINBERTë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì„ë² ë”©"""
        if not self.use_finbert or not self.tokenizer or not self.finbert_model:
            # ê¸°ë³¸ ì„ë² ë”© (768ì°¨ì› 0ìœ¼ë¡œ ì±„ì›€)
            return np.zeros(768)
        
        try:
            inputs = self.tokenizer(text, return_tensors='pt', truncation=True, max_length=512)
            with torch.no_grad():
                outputs = self.finbert_model(**inputs)
            return outputs.last_hidden_state[:, 0, :].squeeze().numpy()
        except Exception as e:
            print(f"âš ï¸ FINBERT ì„ë² ë”© ì‹¤íŒ¨: {e}")
            return np.zeros(768)
    
    def predict_log_return(self, news_texts: List[str]) -> float:
        """ë‰´ìŠ¤ í…ìŠ¤íŠ¸ë“¤ë¡œë¶€í„° ë¡œê·¸ ìˆ˜ìµë¥  ì˜ˆì¸¡"""
        if not self.model:
            print("âš ï¸ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 0.0 ë°˜í™˜")
            return 0.0
        
        try:
            # ëª¨ë“  ë‰´ìŠ¤ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
            combined_text = " ".join(news_texts)
            
            # FINBERT ì„ë² ë”©
            embedding = self.get_finbert_embedding(combined_text)
            
            # ëª¨ë¸ ì˜ˆì¸¡
            with torch.no_grad():
                input_tensor = torch.tensor(embedding, dtype=torch.float32).unsqueeze(0).to(self.device)
                prediction = self.model(input_tensor)
                log_return = prediction.cpu().item()
            
            return log_return
        except Exception as e:
            print(f"âš ï¸ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return 0.0
    
    def predict_next_close(self, current_price: float, news_texts: List[str]) -> float:
        """í˜„ì¬ê°€ì™€ ë‰´ìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì¢…ê°€ ì˜ˆì¸¡"""
        log_return = self.predict_log_return(news_texts)
        predicted_close = current_price * np.exp(log_return)
        return predicted_close


class SentimentalModuleManager:
    """ì„¼í‹°ë©˜íƒˆ ëª¨ë“ˆ í†µí•© ê´€ë¦¬ì"""
    
    def __init__(self, 
                 use_ml_searcher: bool = False,
                 use_ml_predictor: bool = False,
                 finnhub_api_key: Optional[str] = None,
                 model_path: Optional[str] = None):
        
        self.use_ml_searcher = use_ml_searcher
        self.use_ml_predictor = use_ml_predictor
        
        # ëª¨ë“ˆ ì´ˆê¸°í™”
        if self.use_ml_searcher:
            self.searcher = SentimentalSearcher(api_key=finnhub_api_key)
        else:
            self.searcher = None
            
        if self.use_ml_predictor:
            self.predictor = SentimentalPredictor(model_path=model_path)
        else:
            self.predictor = None
    
    def get_enhanced_sentimental_data(self, ticker: str, current_price: float) -> Dict:
        """ML ëª¨ë“ˆì„ í™œìš©í•œ í–¥ìƒëœ ì„¼í‹°ë©˜íƒˆ ë°ì´í„° ìƒì„±"""
        result = {
            "sentiment": "neutral",
            "positives": [],
            "negatives": [],
            "evidence": [],
            "summary": "",
            "ml_prediction": None,
            "ml_confidence": 0.0
        }
        
        # ML Searcher ì‚¬ìš©
        if self.use_ml_searcher and self.searcher:
            try:
                news_data = self.searcher.get_recent_news(ticker, days=7)
                news_texts = [f"{news['title']} {news['summary']}" for news in news_data]
                
                # ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ì„¼í‹°ë©˜íƒˆ ë¶„ì„ì— í™œìš©
                result["evidence"] = [news['title'] for news in news_data[:5]]  # ìµœê·¼ 5ê°œ ë‰´ìŠ¤
                result["summary"] = f"ìµœê·¼ {len(news_data)}ê°œì˜ ë‰´ìŠ¤ê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤."
                
                # ML Predictor ì‚¬ìš©
                if self.use_ml_predictor and self.predictor:
                    try:
                        predicted_close = self.predictor.predict_next_close(current_price, news_texts)
                        log_return = np.log(predicted_close / current_price)
                        
                        result["ml_prediction"] = predicted_close
                        result["ml_confidence"] = min(abs(log_return) * 10, 1.0)  # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
                        
                        # ë¡œê·¸ ìˆ˜ìµë¥ ì— ë”°ë¥¸ ì„¼í‹°ë©˜íƒˆ ë¶„ë¥˜
                        if log_return > 0.02:  # 2% ì´ìƒ ìƒìŠ¹ ì˜ˆì¸¡
                            result["sentiment"] = "positive"
                            result["positives"] = ["ML ëª¨ë¸ì´ ìƒìŠ¹ì„ ì˜ˆì¸¡"]
                        elif log_return < -0.02:  # 2% ì´ìƒ í•˜ë½ ì˜ˆì¸¡
                            result["sentiment"] = "negative"
                            result["negatives"] = ["ML ëª¨ë¸ì´ í•˜ë½ì„ ì˜ˆì¸¡"]
                        else:
                            result["sentiment"] = "neutral"
                            
                    except Exception as e:
                        print(f"âš ï¸ ML ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                        
            except Exception as e:
                print(f"âš ï¸ ML ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return result
    
    def train_model(self, ticker: str) -> bool:
        """ëª¨ë¸ í•™ìŠµ (ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜)"""
        try:
            # ê°„ë‹¨í•œ í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜
            print(f"ğŸ¯ {ticker} ê°ì • ë¶„ì„ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
            print(f"âœ… {ticker} ê°ì • ë¶„ì„ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ (ì‹œë®¬ë ˆì´ì…˜)")
            return True
        except Exception as e:
            print(f"âŒ {ticker} ê°ì • ë¶„ì„ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def predict_price(self, ticker: str) -> tuple:
        """ê°€ê²© ì˜ˆì¸¡ (ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜)"""
        try:
            # ê°„ë‹¨í•œ ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜
            import random
            base_price = 100.0
            prediction = base_price * random.uniform(0.90, 1.10)  # Â±10% ë³€ë™ (ê°ì •ì€ ë” ë³€ë™ì )
            uncertainty = random.uniform(0.2, 0.4)
            
            return prediction, uncertainty
        except Exception as e:
            print(f"âŒ {ticker} ê°ì • ë¶„ì„ ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")
            return 0.0, 1.0


# ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    # ëª¨ë“ˆ ë§¤ë‹ˆì € ì´ˆê¸°í™”
    manager = SentimentalModuleManager(
        use_ml_searcher=True,
        use_ml_predictor=True,
        finnhub_api_key=os.getenv('FINNHUB_API_KEY'),
        model_path="mlp_stock_model.pt"
    )
    
    # í…ŒìŠ¤íŠ¸
    ticker = "AAPL"
    current_price = 150.0
    
    enhanced_data = manager.get_enhanced_sentimental_data(ticker, current_price)
    print("í–¥ìƒëœ ì„¼í‹°ë©˜íƒˆ ë°ì´í„°:", enhanced_data)
