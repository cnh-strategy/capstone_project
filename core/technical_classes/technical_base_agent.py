# core/technical_classes/technical_base_agent.py
# ===============================================================
# TechnicalBaseAgent: LLM ê¸°ë°˜ ê³µí†µ ì¸í„°í˜ì´ìŠ¤ (í…Œí¬ë‹ˆì»¬ ì „ìš© ë² ì´ìŠ¤)
# ===============================================================
from __future__ import annotations
from dataclasses import dataclass
from typing import Dict, List, Optional, Literal, Tuple, Any
from dataclasses import field
from collections import defaultdict
import os, json, time, requests, yfinance as yf
from datetime import datetime
from dotenv import load_dotenv
from prompts import OPINION_PROMPTS, REBUTTAL_PROMPTS, REVISION_PROMPTS
from config.agents import agents_info, dir_info
from core.technical_classes.technical_data_set import (
    build_dataset, load_dataset)
import torch
import torch.nn as nn # ì•„ì—°ìˆ˜ì •
import numpy as np
from torch.utils.data import DataLoader, TensorDataset
from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler
import joblib

# ===============================================================
# utils
# ===============================================================
def r4(x):
    """ì†Œìˆ˜ì  4ìë¦¬ ë°˜ì˜¬ë¦¼"""
    try: return float(f"{float(x):.4f}")
    except: return x

def pct4(x):
    """ë¹„ìœ¨ì„ %ë¡œ í™˜ì‚°í•´ 4ìë¦¬ ë°˜ì˜¬ë¦¼"""
    return float(f"{float(x)*100:.4f}")


# ===============================================================
# ë°ì´í„° êµ¬ì¡° ì •ì˜
# ===============================================================

@dataclass
class Target:
    """ì˜ˆì¸¡ ëª©í‘œê°’ + ë¶ˆí™•ì‹¤ì„± ì •ë³´ í¬í•¨
    - next_close: ë‹¤ìŒ ê±°ë˜ì¼ ì¢…ê°€ ì˜ˆì¸¡ì¹˜
    - uncertainty: Monte Carlo Dropout ê¸°ë°˜ ì˜ˆì¸¡ í‘œì¤€í¸ì°¨(Ïƒ)
    - confidence: ëª¨ë¸ ì‹ ë¢°ë„ Î² (ì •ê·œí™”ëœ ì‹ ë¢°ë„; ì„ íƒì )
    - idea: ëª¨ë¸ íŒë‹¨ ê·¼ê±°(ì„¤ëª… íŒ¨í‚·)
    """
    next_close: float
    uncertainty: float | None = None
    confidence: float | None = None
    idea: dict | None = None

    def __repr__(self):
        return (
            f"Target(next_close={self.next_close:.4f}, "
            f"uncertainty={(self.uncertainty or 0):.4f}, "
            f"confidence={(self.confidence or 0):.4f}, "
            f"idea={self.idea})"
        )

@dataclass
class Opinion:
    agent_id: str
    target: Target
    reason: str

@dataclass
class Rebuttal:
    from_agent_id: str
    to_agent_id: str
    stance: Literal["REBUT", "SUPPORT"]
    message: str

@dataclass
class RoundLog:
    round_no: int
    opinions: List[Opinion]
    rebuttals: List[Rebuttal]
    summary: Dict[str, Target]

@dataclass
class StockData:
    """ì—ì´ì „íŠ¸ ì…ë ¥ ì›ì²œ ë°ì´í„°(í•„ìš” ì‹œ ììœ  í™•ì¥)
    - sentimental: ì‹¬ë¦¬/ì»¤ë®¤ë‹ˆí‹°/ë‰´ìŠ¤ ìŠ¤ëƒ…ìƒ·
    - fundamental: ì¬ë¬´/ë°¸ë¥˜ì—ì´ì…˜ ìš”ì•½
    - technical  : ê°€ê²©/ì§€í‘œ ìŠ¤ëƒ…ìƒ·
    - last_price : ìµœì‹  ì¢…ê°€
    - currency   : í†µí™”ì½”ë“œ
    """
    ticker: Optional[str] = None
    SentimentalAgent: Optional[Dict[str, Any]] = field(default_factory=dict)
    FundamentalAgent: Optional[Dict[str, Any]] = field(default_factory=dict)
    TechnicalAgent: Optional[Dict[str, Any]] = field(default_factory=dict)
    last_price: Optional[float] = None
    currency: Optional[str] = None
    feature_cols: Optional[List[str]] = field(default_factory=list) # ì•„ì—°ì¶”ê°€
    TechnicalAgent_dates: Optional[List[str]] = field(default_factory=list) # ì•„ì—°ì¶”ê°€
    

# ===============================================================
# TechnicalBaseAgent
# ===============================================================
class TechnicalBaseAgent:
    OPENAI_URL = "https://api.openai.com/v1/responses"

    def __init__(
        self,
        agent_id: str,
        model: Optional[str] = None,
        preferred_models: Optional[List[str]] = None,
        temperature: float = 0.2,
        verbose: bool = False,
        need_training: bool = True,
        data_dir: str = dir_info["data_dir"],
        model_dir: str = dir_info["model_dir"],
        ticker: str=None,
        gamma: float = 0.3,
        delta_limit: float = 0.05,
    ):

        load_dotenv()
        self.agent_id = agent_id # ì—ì´ì „íŠ¸ ì‹ë³„ì
        self.model = model # ëª¨ë¸ ì´ë¦„
        self.temperature = temperature # Temperature ì„¤ì •
        self.verbose = verbose            # ë””ë²„ê¹… ëª¨ë“œ
        self.need_training = need_training # ëª¨ë¸ í•™ìŠµ í•„ìš” ì—¬ë¶€
        self.data_dir = data_dir
        self.model_dir = model_dir
        self.ticker = ticker
        self.scaler = DataScaler(agent_id)
        self.window_size = agents_info[agent_id]["window_size"]
        # ëª¨ë¸ í´ë°± ìš°ì„ ìˆœìœ„
        self.preferred_models = preferred_models or ["gpt-5-mini", "gpt-4.1-mini"]
        if model:
            self.preferred_models = [model] + [
                m for m in self.preferred_models if m != model
            ]

        # API í‚¤ ë¡œë“œ
        self.api_key = os.getenv("CAPSTONE_OPENAI_API")
        if not self.api_key:
            self.api_key = ""

        # ê³µí†µ í—¤ë”
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }

        # ìƒíƒœê°’
        self.stockdata: Optional[StockData] = None
        self.targets: List[Target] = []
        self.opinions: List[Opinion] = []
        self.rebuttals: Dict[int, List[Rebuttal]] = defaultdict(list)

        # ìˆ˜ë ´ìœ¨ ë° ì´ë™ í•œê³„
        self.gamma = agents_info[agent_id]["gamma"]
        self.delta_limit = agents_info[agent_id]["delta_limit"]

        # JSON Schema
        self.schema_obj_opinion = {
            "type": "object",
            "properties": {
                "next_close": {"type": "number"},
                "reason": {"type": "string"},
            },
            "required": ["next_close", "reason"],
            "additionalProperties": False,
        }
        self.schema_obj_rebuttal = {
            "type": "object",
            "properties": {
                "stance": {"type": "string", "enum": ["REBUT", "SUPPORT"]},
                "message": {"type": "string"},
            },
            "required": ["stance", "message"],
            "additionalProperties": False,
        }


    # -----------------------------------------------------------
    # ë°ì´í„° ìˆ˜ì§‘
    # -----------------------------------------------------------
    def searcher(self, ticker: Optional[str] = None, rebuild: bool = False):
        import yfinance as yf
        import pandas as pd

        agent_id = self.agent_id
        ticker = ticker or self.ticker

        dataset_path = os.path.join(self.data_dir, f"{ticker}_{agent_id}_dataset.csv")
        cfg = agents_info.get(self.agent_id, {}) 

        need_build = rebuild or (not os.path.exists(dataset_path))
        if need_build:
            print(f"âš™ï¸ {ticker} {agent_id} dataset not found. Building new dataset..." if not os.path.exists(dataset_path) else f"âš™ï¸ {ticker} {agent_id} rebuild requested. Building dataset...")
            build_dataset(
                ticker=ticker,
                save_dir=self.data_dir,
                period=cfg.get("period", "5y"),
                interval=cfg.get("interval", "1d"),
            )
    
        # CSV ë¡œë“œ (ì•„ì—°ìˆ˜ì •)
        X, y, feature_cols, dates_all = load_dataset(ticker, agent_id=agent_id, save_dir=self.data_dir)

        # StockData êµ¬ì„± (ì•„ì—°ìˆ˜ì •)
        self.stockdata = StockData(ticker=ticker, feature_cols=feature_cols)
        setattr(self.stockdata, f"{agent_id}_dates", dates_all[-1] if dates_all else [])

        # ìµœê·¼ window
        X_latest = X[-1:]
        # last_price ì•ˆì „ ë³€í™˜ (+ë¹ˆ DF ê°€ë“œ)
        try:
            data = yf.download(ticker, period="5y", interval="1d", auto_adjust=True, progress=False)
            if data is not None and not data.empty:
                last_val = data["Close"].iloc[-1]
                self.stockdata.last_price = float(last_val.item() if hasattr(last_val, "item") else last_val)
            else:
                self.stockdata.last_price = None
        except Exception:
            self.stockdata.last_price = None

        # í†µí™”ì½”ë“œ
        try:
            self.stockdata.currency = yf.Ticker(ticker).info.get("currency", "USD")
        except Exception:
            self.stockdata.currency = "USD"

        print(f"â–  {agent_id} StockData ìƒì„± ì™„ë£Œ ({ticker}, {self.stockdata.currency})")
        return torch.tensor(X_latest, dtype=torch.float32)


    def pretrain(self):
        """Agentë³„ ì‚¬ì „í•™ìŠµ ë£¨í‹´ (ëª¨ë¸ ìƒì„±, í•™ìŠµ, ì €ì¥, self.model ì—°ê²°ê¹Œì§€ í¬í•¨)"""
        epochs = agents_info[self.agent_id]["epochs"]
        lr = agents_info[self.agent_id]["learning_rate"]
        batch_size = agents_info[self.agent_id]["batch_size"]

        # --------------------------
        # ë°ì´í„° ë¡œë“œ
        # --------------------------
        X, y, cols, _ = load_dataset(self.ticker, self.agent_id, save_dir=self.data_dir) # ì•„ì—°ìˆ˜ì • ì»¬ëŸ¼ 4ê°œ
        print(f"[{datetime.now().strftime('%H:%M:%S')}] Pretraining {self.agent_id}")

        split_idx = int(len(X) * 0.8)
        X_train, X_val = X[:split_idx], X[split_idx:]
        y_train, y_val = y[:split_idx], y[split_idx:]

        # ğŸ”¹ íƒ€ê¹ƒ ìŠ¤ì¼€ì¼ ì¡°ì • ë³µì› - ìƒìŠ¹/í•˜ë½ìœ¨ì„ 100ë°°ë¡œ ìŠ¤ì¼€ì¼ë§
        # ê¸°ì¡´: ì›ë³¸ ìƒìŠ¹/í•˜ë½ìœ¨ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ë¬¸ì œ: ë„ˆë¬´ ì‘ì€ ê°’ìœ¼ë¡œ ê³¼ì í•©)
        # ìˆ˜ì •: Â±0.04 â†’ Â±4.0ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§í•˜ì—¬ ì ì ˆí•œ í•™ìŠµ ë²”ìœ„ í™•ë³´
        y_train *= 100.0
        y_val   *= 100.0

        self.scaler.fit_scalers(X_train, y_train)
        self.scaler.save(self.ticker)

        X_train, y_train = map(torch.tensor, self.scaler.transform(X_train, y_train))
        X_train, y_train = X_train.float(), y_train.float()

        # --------------------------
        # ëª¨ë¸ ìƒì„± ë° ì´ˆê¸°í™” (ì•„ì—°ìˆ˜ì •) nn.Moduleì´ë©´ ìê¸° ìì‹  ì‚¬ìš©. ê³¼ê±° ìê¸°ì°¸ì¡° ì„œë¸Œëª¨ë“ˆ ì œê±°.
        # --------------------------
        if isinstance(self, nn.Module):
          model = self
          self._modules.pop("model", None)
        else:
          if getattr(self, "model", None) is None:
              if hasattr(self, "_build_model"):
                  self.model = self._build_model()
                  print(f"â–  {self.agent_id} ëª¨ë¸ ìƒˆë¡œ ìƒì„±ë¨.")
              else:
                raise RuntimeError(f"{self.agent_id}ì— _build_model()ì´ ì •ì˜ë˜ì§€ ì•ŠìŒ")
          model = self.model


        # --------------------------
        # í•™ìŠµ
        # --------------------------
        model.train()

        optimizer = torch.optim.Adam(model.parameters(), lr=lr)
        # ê¸°ì¡´: MSE Loss ì‚¬ìš©
        # loss_fn = torch.nn.MSELoss()
        # ìˆ˜ì •: Huber Loss ì‚¬ìš© - ì´ìƒì¹˜ì— ëœ ë¯¼ê°í•˜ê³  ë” ì•ˆì •ì ì¸ í•™ìŠµ
        # delta=1.0ìœ¼ë¡œ ì¡°ì • (íƒ€ê²Ÿ ìŠ¤ì¼€ì¼ë§ í›„ ì ì ˆí•œ ê°’)
        loss_fn = torch.nn.HuberLoss(delta=1.0)

        # ì•„ì—°ìˆ˜ì •
        train_loader = DataLoader(TensorDataset(X_train, y_train.view(-1, 1)),
                                  batch_size=batch_size, shuffle=True)

        # --------------------------
        # í•™ìŠµ ë£¨í”„
        # --------------------------
        for epoch in range(epochs):
            total_loss = 0.0
            for Xb, yb in train_loader:
                y_pred = model(Xb)
                loss = loss_fn(y_pred, yb)
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                total_loss += loss.item()

            if (epoch + 1) % 5 == 0:
                print(f"  Epoch {epoch+1:03d} | Loss: {total_loss/len(train_loader):.6f}")

        # --------------------------
        # ëª¨ë¸ ì €ì¥ ë° ì—°ê²°
        # --------------------------
        os.makedirs(self.model_dir, exist_ok=True)
        model_path = os.path.join(self.model_dir, f"{self.ticker}_{self.agent_id}.pt")
        torch.save({"model_state_dict": model.state_dict()}, model_path)

        # (ì•„ì—°ìˆ˜ì •) nn.Module ìê¸° ìì‹ ì´ë©´ self.modelì— ë“±ë¡í•˜ì§€ ì•ŠìŒ
        if model is not self:
          self.model = model

        print(f" {self.agent_id} ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ: {model_path}")   


    # -----------------------------------------------------------
    # ì˜ˆì¸¡
    # -----------------------------------------------------------
    def predict(self, X, n_samples: int = 30, current_price: float = None, X_last: np.ndarray = None):
        """
        Monte Carlo Dropout ê¸°ë°˜ ì˜ˆì¸¡ + ë¶ˆí™•ì‹¤ì„±(Ïƒ) ë° confidence ê³„ì‚° (ì•ˆì •í˜•)
        """
        # -----------------------------
        # ëª¨ë¸ ì¤€ë¹„ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ (ì•„ì—°ìˆ˜ì •)
        # -----------------------------
        # 0) ê³¼ê±° ìê¸°ì°¸ì¡°(child) ì •ë¦¬ â”€ RecursionError ë°©ì§€
        if isinstance(self, nn.Module):
            # self._modules ì•ˆì— self ìì‹ ì´ ë“¤ì–´ìˆìœ¼ë©´ ì œê±°
            for name, child in list(getattr(self, "_modules", {}).items()):
                if child is self:
                    del self._modules[name]
            if getattr(self, "model", None) is self:
                self.model = None


        # A) ì´ ì—ì´ì „íŠ¸ê°€ nn.Moduleì´ë©´ ê·¸ ìì²´ ì‚¬ìš©
        if isinstance(self, nn.Module) and hasattr(self, "forward"):
            model = self
        else:
            # B) ê¸°ì¡´ ë¡œì§ ê·¸ëŒ€ë¡œ
            if self.model is None or not hasattr(self.model, "parameters"):
                model_path = os.path.join(self.model_dir, f"{self.ticker}_{self.agent_id}.pt")
                if os.path.exists(model_path):
                    print(f"â–  {self.agent_id} ëª¨ë¸ ìë™ ë¡œë“œ ì‹œë„...")
                    self.load_model(model_path)
                else:
                    print(f"â–  {self.agent_id} ëª¨ë¸ ì—†ìŒ â†’ pretrain ìˆ˜í–‰...")
                    self.pretrain()
            if self.model is None:
                raise RuntimeError(f"{self.agent_id} ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            model = self.model

        self.scaler.load(self.ticker)


        # -----------------------------
        # ì…ë ¥ ë³€í™˜
        # -----------------------------
        # ì›ë³¸ ë³´ì¡´ â†’ ì„¤ëª… ë‹¨ê³„ì—ì„œ ë‹¨ í•œ ë²ˆë§Œ ìŠ¤ì¼€ì¼
        if isinstance(X, np.ndarray):
            X_raw_np = X.copy()
            X_scaled, _ = self.scaler.transform(X_raw_np)
            X_tensor = torch.tensor(X_scaled, dtype=torch.float32)
        elif isinstance(X, torch.Tensor): # ì•„ì—°ìˆ˜ì •
            X_raw_np = X.detach().cpu().numpy().copy()
            X_scaled, _ = self.scaler.transform(X_raw_np)
            X_tensor = torch.tensor(X_scaled, dtype=torch.float32)
        else:
            raise TypeError(f"Unsupported input type: {type(X)}")

        #model = self.model (ì•„ì—°ìˆ˜ì •)
        device = next(model.parameters()).device
        X_tensor = X_tensor.to(device)

        # -----------------------------
        # Monte Carlo Dropout ì¶”ë¡ 
        # -----------------------------
        model.train()
        preds = []
        with torch.no_grad():
            for _ in range(n_samples):
                y_pred = model(X_tensor).cpu().numpy().flatten()
                preds.append(y_pred)

        preds = np.stack(preds)  # (samples, seq)
        mean_pred = preds.mean(axis=0)
        std_pred = np.abs(preds.std(axis=0))  # í•­ìƒ ì–‘ìˆ˜

        # -----------------------------
        # Ïƒ ê¸°ë°˜ confidence ê³„ì‚°
        # -----------------------------
        sigma = float(std_pred[-1])
        sigma = max(sigma, 1e-6)

        # ì‹ ë¢°ë„: ë¶ˆí™•ì‹¤ì„± ì‘ì„ìˆ˜ë¡ 1ì— ê°€ê¹Œì›€
        confidence = 1 / (1 + np.log1p(sigma))

        # -----------------------------
        # ì—­ë³€í™˜ ë° ê°€ê²© ê³„ì‚°
        # -----------------------------
        if hasattr(self.scaler, 'y_scaler') and self.scaler.y_scaler is not None:
            mean_pred = self.scaler.inverse_y(mean_pred)
            std_pred = self.scaler.inverse_y(std_pred)

        if current_price is None:
            current_price = getattr(self.stockdata, 'last_price', 100.0)

        # âœ… í˜„ì¬ ëª¨ë¸ì€ "ë‹¤ìŒë‚  ìˆ˜ìµë¥ (return)"ì„ ì˜ˆì¸¡í•˜ë¯€ë¡œ, ì¢…ê°€ë¡œ ë³€í™˜ ì‹œ (1 + return)
        predicted_return = float(mean_pred[-1]) / 100.0  # ì˜ˆì¸¡ëœ ìƒìŠ¹ë¥  (%) (ì•„ì—°ìˆ˜)
        predicted_price = current_price * (1 + predicted_return)

        # -----------------------------
        # Target ìƒì„± ë° ë°˜í™˜
        # -----------------------------
        target = Target(
            next_close=float(predicted_price),
            uncertainty=sigma,
            confidence=float(confidence),
            idea = None, #ì¼ë‹¨ Noneìœ¼ë¡œ ì‹œì‘ # ì•„ì—°ìˆ˜ì •
        )

        # ì„¤ëª…ì€ "ìŠ¤ì¼€ì¼ ì „" ì…ë ¥ì„ ì‚¬ìš©í•´ ë‚´ë¶€ì—ì„œ 1íšŒ ìŠ¤ì¼€ì¼
        X_last_raw = torch.tensor(X_raw_np, dtype=torch.float32)
        T = X_last_raw.shape[1]
        dates_all = getattr(self.stockdata, f"{self.agent_id}_dates", [])
        dates = dates_all[-T:] if dates_all else [f"t-{T-1-i}" for i in range(T)]

        exp = self.explain_last(X_last_raw, dates, top_k=5)  # ì„¤ëª… ê³„ì‚°

        target.idea = {
            "per_time": exp["per_time"],
            "per_feature": exp["per_feature"],
            "evidence": exp["evidence"],
            "meta": {"ticker": self.ticker, "window_size": self.window_size},
        }

        return target



    # -----------------------------
    # ë©”ì¸ ì›Œí¬í”Œë¡œ
    # -----------------------------
    def reviewer_draft(self, stock_data: StockData = None, target: Target = None) -> Opinion:
        """(1) searcher â†’ (2) predicter â†’ (3) LLM(JSON Schema)ë¡œ reason ìƒì„± â†’ Opinion ë°˜í™˜"""

        # 1) ë°ì´í„° ìˆ˜ì§‘
        if stock_data is None:
            stock_data = getattr(self.stockdata, self.agent_id)

        # 2) ì˜ˆì¸¡ê°’ ìƒì„± (ì•„ì—°ìˆ˜ì •)
        if target is None:
            X_input = self.searcher(self.ticker)              # (1,T,F)
            target = self.predict(X_input)

        # 3) LLM í˜¸ì¶œ(reason ìƒì„±) - ì „ë‹¬ë°›ì€ stock_data ì‚¬ìš©
        sys_text, user_text = self._build_messages_opinion(self.stockdata, target)

        parsed = self._ask_with_fallback(
            self._msg("system", sys_text),
            self._msg("user", user_text),
            {"type": "object", "properties": {"reason": {"type": "string"}}, "required": ["reason"], "additionalProperties": False}
        )

        reason = parsed.get("reason", "(ì‚¬ìœ  ìƒì„± ì‹¤íŒ¨)")

        # 4) Opinion ê¸°ë¡/ë°˜í™˜ (í•­ìƒ ìµœì‹  ê°’ append)
        self.opinions.append(Opinion(agent_id=self.agent_id, target=target, reason=reason))

        # ìµœì‹  ì˜¤í”¼ë‹ˆì–¸ ë°˜í™˜
        return self.opinions[-1]

    def reviewer_rebut(self, my_opinion: Opinion, other_opinion: Opinion, round: int) -> Rebuttal:
        """LLMì„ í†µí•´ ìƒëŒ€ ì˜ê²¬ì— ëŒ€í•œ ë°˜ë°•/ì§€ì§€ ìƒì„±"""

        # ë©”ì‹œì§€ ìƒì„± (context êµ¬ì„±ì€ ë³„ë„ í—¬í¼ì—ì„œ)
        sys_text, user_text = self._build_messages_rebuttal(
            my_opinion=my_opinion,
            target_opinion=other_opinion,
            stock_data=self.stockdata
        )

        # LLM í˜¸ì¶œ
        parsed = self._ask_with_fallback(
            self._msg("system", sys_text),
            self._msg("user", user_text),
            {
                "type": "object",
                "properties": {
                    "stance": {"type": "string", "enum": ["REBUT", "SUPPORT"]},
                    "message": {"type": "string"}
                },
                "required": ["stance", "message"],
                "additionalProperties": False
            }
        )

        # ê²°ê³¼ ì •ë¦¬ ë° ê¸°ë¡
        result = Rebuttal(
            from_agent_id=my_opinion.agent_id,
            to_agent_id=other_opinion.agent_id,
            stance=parsed.get("stance", "REBUT"),
            message=parsed.get("message", "(ë°˜ë°•/ì§€ì§€ ì‚¬ìœ  ìƒì„± ì‹¤íŒ¨)")
        )

        # ì €ì¥
        self.rebuttals[round].append(result)

        # ë””ë²„ê¹… ë¡œê·¸
        if self.verbose:
            print(
                f"[{self.agent_id}] rebuttal ìƒì„± â†’ {result.stance} "
                f"({my_opinion.agent_id} â†’ {other_opinion.agent_id})"
            )

        return result

    def reviewer_revise(
        self,
        my_opinion: Opinion,
        others: List[Opinion],
        rebuttals: List[Rebuttal],
        stock_data: StockData,
        fine_tune: bool = True,
        lr: float = 1e-4,
        epochs: int = 20,
    ):
        """
        Revision ë‹¨ê³„
        - Ïƒ ê¸°ë°˜ Î²-weighted ì‹ ë¢°ë„ ê³„ì‚°
        - Î³ ìˆ˜ë ´ìœ¨ë¡œ ì˜ˆì¸¡ê°’ ë³´ì •
        - fine-tuning (ìˆ˜ìµë¥  ë‹¨ìœ„)
        - reasoning ìƒì„±
        """
        gamma = getattr(self, "gamma", 0.3)               # ìˆ˜ë ´ìœ¨ (0~1)
        delta_limit = getattr(self, "delta_limit", 0.05)  # fine-tuning ë³´ì • í•œê³„

        try:
            # ===================================
            # â‘  Î² ê³„ì‚° (ë¶ˆí™•ì‹¤ì„± ì‘ì„ìˆ˜ë¡ ì‹ ë¢° ë†’ìŒ)
            # ===================================
            my_price = my_opinion.target.next_close
            my_sigma = abs(my_opinion.target.uncertainty or 1e-6)

            other_prices = np.array([o.target.next_close for o in others])
            other_sigmas = np.array([abs(o.target.uncertainty or 1e-6) for o in others])

            all_sigmas = np.concatenate([[my_sigma], other_sigmas])
            all_prices = np.concatenate([[my_price], other_prices])

            inv_sigmas = 1 / (all_sigmas + 1e-6)
            betas = inv_sigmas / inv_sigmas.sum()

            # ===================================
            # â‘¡ ë…¼ë¬¸ì‹ ìˆ˜ë ´ ì—…ë°ì´íŠ¸
            #     y_i_rev = y_i + Î³ Î£ Î²_j (y_j - y_i)
            # ===================================
            delta = np.sum(betas[1:] * (other_prices - my_price))
            revised_price = my_price + gamma * delta

        except Exception as e:
            print(f"[{self.agent_id}] revised_target ê³„ì‚° ì‹¤íŒ¨: {e}")
            revised_price = my_opinion.target.next_close
            current_price = getattr(self.stockdata, "last_price", 100.0)
            price_uplimit = current_price * (1 + delta_limit)
            price_downlimit = current_price * (1 - delta_limit)
            revised_price = min(max(revised_price, price_downlimit), price_uplimit)

        # ===================================
        # â‘¢ Fine-tuning (return ë‹¨ìœ„)
        # ===================================
        loss_value = None
        if fine_tune and hasattr(self, "model"):
            try:
                current_price = getattr(self.stockdata, "last_price", 100.0)
                revised_return = (revised_price / current_price) - 1  # ğŸ”¹ìˆ˜ìµë¥  ë³€í™˜

                X_input = self.searcher(self.ticker)
                device = next(self.model.parameters()).device
                X_tensor = torch.tensor(X_input, dtype=torch.float32).to(device)
                y_tensor = torch.tensor([[revised_return]], dtype=torch.float32).to(device)

                self.model.train()
                optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)
                criterion = torch.nn.MSELoss()

                for _ in range(epochs):
                    optimizer.zero_grad()
                    pred = self.model(X_tensor)
                    loss = criterion(pred, y_tensor) # ì•„ì—°ìˆ˜ì •
                    loss.backward()
                    optimizer.step()

                loss_value = float(loss.item())
                print(f"[{self.agent_id}] fine-tuning ì™„ë£Œ: loss={loss_value:.6f}")

            except Exception as e:
                print(f"[{self.agent_id}] fine-tuning ì‹¤íŒ¨: {e}")

        # ===================================
        # â‘£ fine-tuning ì´í›„ ìƒˆ ì˜ˆì¸¡ ìƒì„±
        # ===================================
        try:
            X_latest = self.searcher(self.ticker)
            new_target = self.predict(X_latest)
        except Exception as e:
            print(f"[{self.agent_id}] predict ì‹¤íŒ¨: {e}")
            new_target = my_opinion.target

        # ===================================
        # â‘¤ reasoning ìƒì„±
        # ===================================
        try:
            sys_text, user_text = self._build_messages_revision(
                my_opinion=my_opinion,
                others=others,
                rebuttals=rebuttals,
                stock_data=stock_data,
            )
        except Exception as e:
            print(f"[{self.agent_id}] _build_messages_revision ì‹¤íŒ¨: {e}")
            sys_text, user_text = (
                "ë„ˆëŠ” ê¸ˆìœµ ë¶„ì„ê°€ë‹¤. ê°„ë‹¨íˆ reasonë§Œ ìƒì„±í•˜ë¼.",
                json.dumps({"reason": "ê¸°ë³¸ ë©”ì‹œì§€ ìƒì„± ì‹¤íŒ¨"}),
            )

        parsed = self._ask_with_fallback(
            self._msg("system", sys_text),
            self._msg("user", user_text),
            {
                "type": "object",
                "properties": {"reason": {"type": "string"}},
                "required": ["reason"],
                "additionalProperties": False,
            },
        )

        revised_reason = parsed.get("reason", "(ìˆ˜ì • ì‚¬ìœ  ìƒì„± ì‹¤íŒ¨)")
        revised_opinion = Opinion(
            agent_id=self.agent_id,
            target=new_target,
            reason=revised_reason,
        )

        self.opinions.append(revised_opinion)
        print(f"[{self.agent_id}] revise ì™„ë£Œ â†’ new_close={new_target.next_close:.2f}, loss={loss_value}")
        return self.opinions[-1]



    def _build_messages_opinion(self, stock_data: StockData, target: Target) -> Tuple[str, str]:
        """LLM(system/user) ë©”ì‹œì§€ ìƒì„±(êµ¬í˜„ í•„ìš”)"""
        raise NotImplementedError(f"{self.__class__.__name__} must implement _build_messages_opinion method")

    def _build_messages_rebuttal(self, *args, **kwargs) -> Tuple[str, str]:
        """LLM(system/user) ë©”ì‹œì§€ ìƒì„±(êµ¬í˜„ í•„ìš”)"""
        raise NotImplementedError(f"{self.__class__.__name__} must implement _build_messages_rebuttal method")

    def load_model(self, model_path: Optional[str] = None): # ì•„ì—°ìˆ˜ì •
        """ì €ì¥ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ (ê°ì²´/ë”•ì…”ë„ˆë¦¬/state_dict ìë™ ì¸ì‹ + model ìë™ ìƒì„±)"""
        if model_path is None:
            model_path = os.path.join(self.model_dir, f"{self.ticker}_{self.agent_id}.pt")

        if not os.path.exists(model_path):
            print(f"â–  ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
            return False

        try:
            checkpoint = torch.load(model_path, map_location=torch.device("cpu"))

            # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ì„ íƒ: nn.Moduleì´ë©´ ìê¸° ìì‹  ì‚¬ìš©. ì•„ë‹ˆë©´ _build_model ì‚¬ìš©.
            if isinstance(self, nn.Module):
                model = self
                # ê³¼ê±°ì— ì˜ëª» ë“±ë¡ëì„ ìˆ˜ ìˆëŠ” ì„œë¸Œëª¨ë“ˆ ì œê±°
                self._modules.pop("model", None)
            elif getattr(self, "model", None) is None:
                if hasattr(self, "_build_model"):
                    self.model = self._build_model()
                    model = self.model
                    print(f"â–  {self.agent_id} ëª¨ë¸ ìƒˆë¡œ ìƒì„±ë¨ (ë¡œë“œ ì „ ì´ˆê¸°í™”).")
                else:
                    raise RuntimeError(f"{self.agent_id}ì— _build_model()ì´ ì •ì˜ë˜ì–´ ìˆì§€ ì•ŠìŒ")
            else:
                model = self.model

            # ë‹¤ì–‘í•œ ì €ì¥ í¬ë§· ì²˜ë¦¬
            if isinstance(checkpoint, torch.nn.Module):
                state_dict = checkpoint.state_dict()
            elif isinstance(checkpoint, dict):
                state_dict = (
                    checkpoint.get("model_state_dict")
                    or checkpoint.get("state_dict")
                    or checkpoint
                )
            else:
                print(f" ì•Œ ìˆ˜ ì—†ëŠ” ì²´í¬í¬ë§·: {type(checkpoint)}")
                return False

            model.load_state_dict(state_dict)
            model.eval()

            # nn.Module ìê¸° ìì‹ ì´ë©´ self.modelì— selfë¥¼ ë„£ì§€ ì•ŠìŒ
            if model is not self:
                self.model = model

            return True

        except Exception as e:
            print(f"â–  ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {model_path}")
            print(f"ì˜¤ë¥˜ ë‚´ìš©: {e}")
            return False


       

    # ì•„ì—°ìˆ˜ì •
    def _p(self, msg: str):
        if getattr(self, "verbose", False):
            print(f"[{self.agent_id}] {msg}")

    # OpenAI API í˜¸ì¶œ
    def _ask_with_fallback(self, msg_sys: dict, msg_user: dict, schema_obj: dict) -> dict:
        """ëª¨ë¸ í´ë°± í¬í•¨ OpenAI Responses API í˜¸ì¶œ"""
        payload_base = {
            "input": [msg_sys, msg_user],
            "text": {
                "format": {
                    "type": "json_schema",
                    "name": "Response",
                    "strict": True,
                    "schema": schema_obj,
                }
            },
            "temperature": self.temperature,
        }
        last_err = None
        for model in self.preferred_models:
            payload = dict(payload_base, model=model)
            try:
                r = requests.post(self.OPENAI_URL, headers=self.headers, json=payload, timeout=120)
                if r.ok:
                    data = r.json()
                    # 1) output_text ìš°ì„  ì‚¬ìš©
                    if isinstance(data.get("output_text"), str) and data["output_text"].strip():
                        try:
                            return json.loads(data["output_text"])
                        except Exception:
                            return {"reason": data["output_text"]}  # JSON ì‹¤íŒ¨ ì‹œ ì›ë¬¸ í…ìŠ¤íŠ¸ ë³´ì¡´
                    # 2) output ë°°ì—´ì—ì„œ í…ìŠ¤íŠ¸ ëª¨ìœ¼ê¸°
                    out = data.get("output")
                    if isinstance(out, list) and out:
                        texts = []
                        for blk in out:
                            for c in blk.get("content", []):
                                if "text" in c:
                                    texts.append(c["text"])
                        joined = "\n".join(t for t in texts if t)
                        if joined.strip():
                            try:
                                return json.loads(joined)
                            except Exception:
                                return {"reason": joined}
                    # ë¹„ì •ìƒ ì‘ë‹µ
                    return {}
                # 400/404ëŠ” ë‹¤ìŒ ëª¨ë¸ë¡œ í´ë°±
                if r.status_code in (400, 404, 503, 401):
                    last_err = (r.status_code, r.text)
                    continue
                # ê¸°íƒ€ ì—ëŸ¬ëŠ” ì¦‰ì‹œ ì˜ˆì™¸
                r.raise_for_status()
            except Exception as e:
                self._p(f"â–  ëª¨ë¸ {model} ì‹¤íŒ¨: {e}")
                last_err = str(e)
                continue
        raise RuntimeError(f"ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨. ë§ˆì§€ë§‰ ì˜¤ë¥˜: {last_err}")

    # ì¶”ê°€: Monte Carlo Dropout ê¸°ë°˜ ë¶ˆí™•ì‹± ì¶”ì •
    def evaluate(self, ticker: str = None):
        """ê²€ì¦ ë°ì´í„°ë¡œ ì„±ëŠ¥ í‰ê°€"""
        if ticker is None:
            ticker = self.ticker

        # ë°ì´í„° ë¡œë“œ (ì•„ì—°ìˆ˜ì •)
        X, y, feature_cols, _ = load_dataset(ticker, agent_id=self.agent_id, save_dir=self.data_dir)

        # ì‹œê³„ì—´ ë¶„í•  (80% í›ˆë ¨, 20% ê²€ì¦)
        split_idx = int(len(X) * 0.8)
        X_val = X[split_idx:]
        y_val = y[split_idx:]

        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        self.scaler.load(ticker)

        # ê²€ì¦ ë°ì´í„° ì˜ˆì¸¡
        predictions = []
        actual_returns = []

        for i in range(len(X_val)):
            X_input = X_val[i:i+1]
            X_tensor = torch.tensor(X_input, dtype=torch.float32)

            # ì˜ˆì¸¡
            with torch.no_grad():
                pred_return = self(X_tensor).item()
                predictions.append(pred_return)
                actual_returns.append(y_val[i, 0])

        predictions = np.array(predictions)
        actual_returns = np.array(actual_returns)

        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        mae = np.mean(np.abs(predictions - actual_returns))
        rmse = np.sqrt(np.mean((predictions - actual_returns) ** 2))
        correlation = np.corrcoef(predictions, actual_returns)[0, 1]

        # ë°©í–¥ ì •í™•ë„
        pred_direction = np.sign(predictions)
        actual_direction = np.sign(actual_returns)
        direction_accuracy = np.mean(pred_direction == actual_direction) * 100

        return {
            'mae': mae,
            'rmse': rmse,
            'correlation': correlation,
            'direction_accuracy': direction_accuracy,
            'n_samples': len(predictions)
        }

    def _msg(self, role: str, content: str) -> dict:
        """OpenAI ChatCompletionìš© ë©”ì‹œì§€ êµ¬ì¡° ìƒì„±"""
        if not isinstance(role, str) or not isinstance(content, str):
            raise ValueError(f"_msg() ì¸ì ì˜¤ë¥˜: role={role}, content={type(content)}")
        return {"role": role, "content": content}


class DataScaler:
    """í•™ìŠµ/ì¶”ë¡ ìš© ì •ê·œí™” ìœ í‹¸ë¦¬í‹° (BaseAgent ë‚´ë¶€ìš©)"""
    def __init__(self, agent_id):
        self.agent_id = agent_id
        self.save_dir = dir_info["scaler_dir"]
        self.x_scaler = agents_info[self.agent_id]["x_scaler"]
        self.y_scaler = agents_info[self.agent_id]["y_scaler"]

    def fit_scalers(self, X_train, y_train):
        ScalerMap = {
            "StandardScaler": StandardScaler,
            "MinMaxScaler": MinMaxScaler,
            "RobustScaler": RobustScaler,
            "None": None,
        }
        # ë¬¸ìì—´ì´ë©´ í´ë˜ìŠ¤ ë§¤í•‘, ì¸ìŠ¤í„´ìŠ¤ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        Sx = ScalerMap[self.x_scaler] if isinstance(self.x_scaler, str) else self.x_scaler
        Sy = ScalerMap[self.y_scaler] if isinstance(self.y_scaler, str) else self.y_scaler

        # 3D ì…ë ¥ (samples, seq_len, features) â†’ 2Dë¡œ ë³€í™˜
        n_samples, seq_len, n_feats = X_train.shape
        X_2d = X_train.reshape(-1, n_feats)
        self.x_scaler = (Sx().fit(X_2d) if isinstance(Sx, type) else Sx.fit(X_2d)) if Sx else None
        self.y_scaler = (Sy().fit(y_train.reshape(-1,1)) if isinstance(Sy, type) else Sy.fit(y_train.reshape(-1,1))) if Sy else None

    def transform(self, X, y=None):
        # 3D ì…ë ¥ (samples, seq_len, features) â†’ 2Dë¡œ ë³€í™˜
        if X.ndim == 3:
            n_samples, seq_len, n_feats = X.shape
            X_2d = X.reshape(-1, n_feats)
            X_t = self.x_scaler.transform(X_2d).reshape(n_samples, seq_len, n_feats)
        else:
            X_t = self.x_scaler.transform(X) if self.x_scaler else X

        y_t = (
            self.y_scaler.transform(y.reshape(-1, 1)).flatten()
            if (self.y_scaler and y is not None)
            else y
        )
        return X_t, y_t


    def inverse_y(self, y_pred):
        # ì‹¤ì œ ìŠ¤ì¼€ì¼ëŸ¬ ê°ì²´ì¸ì§€ í™•ì¸
        if self.y_scaler and self.y_scaler != "None" and hasattr(self.y_scaler, 'inverse_transform'):
            # numpy ë°°ì—´ë¡œ ë³€í™˜
            if isinstance(y_pred, (list, tuple)):
                y_pred = np.array(y_pred)
            return self.y_scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()
        return y_pred

    def convert_return_to_price(self, return_rate, current_price):
        """ìƒìŠ¹/í•˜ë½ìœ¨ì„ ì‹¤ì œ ê°€ê²©ìœ¼ë¡œ ë³€í™˜"""
        return current_price * (1 + return_rate)

    def evaluate(self, ticker: str = None):
        """ê²€ì¦ ë°ì´í„°ë¡œ ì„±ëŠ¥ í‰ê°€"""
        if ticker is None:
            ticker = self.ticker

        # ë°ì´í„° ë¡œë“œ
        X, y, feature_cols = load_dataset(ticker, agent_id=self.agent_id, save_dir=self.data_dir)

        # ì‹œê³„ì—´ ë¶„í•  (80% í›ˆë ¨, 20% ê²€ì¦)
        split_idx = int(len(X) * 0.8)
        X_val = X[split_idx:]
        y_val = y[split_idx:]

        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        self.scaler.load(ticker)

        # ê²€ì¦ ë°ì´í„° ì˜ˆì¸¡
        predictions = []
        actual_returns = []

        for i in range(len(X_val)):
            X_input = X_val[i:i+1]
            X_tensor = torch.tensor(X_input, dtype=torch.float32)

            # ì˜ˆì¸¡
            with torch.no_grad():
                pred_return = self(X_tensor).item()
                predictions.append(pred_return)
                actual_returns.append(y_val[i, 0])

        predictions = np.array(predictions)
        actual_returns = np.array(actual_returns)

        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        mae = np.mean(np.abs(predictions - actual_returns))
        rmse = np.sqrt(np.mean((predictions - actual_returns) ** 2))
        correlation = np.corrcoef(predictions, actual_returns)[0, 1]

        # ë°©í–¥ ì •í™•ë„
        pred_direction = np.sign(predictions)
        actual_direction = np.sign(actual_returns)
        direction_accuracy = np.mean(pred_direction == actual_direction) * 100

        return {
            'mae': mae,
            'rmse': rmse,
            'correlation': correlation,
            'direction_accuracy': direction_accuracy,
            'n_samples': len(predictions)
        }

    def save(self, ticker):
        os.makedirs(self.save_dir, exist_ok=True)
        if self.x_scaler:
            joblib.dump(
                self.x_scaler,
                os.path.join(self.save_dir, f"{ticker}_{self.agent_id}_xscaler.pkl"),
            )
        if self.y_scaler:
            joblib.dump(
                self.y_scaler,
                os.path.join(self.save_dir, f"{ticker}_{self.agent_id}_yscaler.pkl"),
            )

    def load(self, ticker):
        x_path = os.path.join(self.save_dir, f"{ticker}_{self.agent_id}_xscaler.pkl")
        y_path = os.path.join(self.save_dir, f"{ticker}_{self.agent_id}_yscaler.pkl")
        if os.path.exists(x_path):
            self.x_scaler = joblib.load(x_path)
        if os.path.exists(y_path):
            self.y_scaler = joblib.load(y_path)

# ì„¤ëª… ì €ì¥/ë¡œë“œ ìœ í‹¸ë¦¬í‹° (ì•„ì—°ìˆ˜ì •)
def save_explain_json(ticker, agent_id, target, path_dir="models/explain"):
    """Target.idea ë“±ì„ í¬í•¨í•œ ì„¤ëª… ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥"""
    os.makedirs(path_dir, exist_ok=True)
    path = os.path.join(path_dir, f"{ticker}_{agent_id}_explain.json")
    with open(path, "w", encoding="utf-8") as f:
        json.dump({"target": target.__dict__}, f, ensure_ascii=False, indent=2)
    return path

def load_explain_json(ticker, agent_id, path_dir="models/explain"):
    """ì €ì¥ëœ ì„¤ëª… JSONì„ ë¶ˆëŸ¬ì˜¤ê¸°"""
    path = os.path.join(path_dir, f"{ticker}_{agent_id}_explain.json")
    if not os.path.exists(path):
        print(f"â–  ì„¤ëª… JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.:{path}")
        return None
    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)
    print(f"â–  ì„¤ëª… JSON íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {path}")
    return data




