# test_sentimental_lstm.py

import pandas as pd
import numpy as np
import torch
import joblib

from core.sentimental_classes.train_sentimental import (
    LSTMModel,
    FEATURE_COLS,
    WINDOW_SIZE,
    HIDDEN_DIM,
    NUM_LAYERS,
    DROPOUT,
)

TICKER = "NVDA"

data_csv = f"data/datasets/{TICKER}_sentimental_dataset.csv"
scaler_path = f"models/scalers/{TICKER}_SentimentalAgent.pkl"
model_path = f"models/{TICKER}_SentimentalAgent.pt"

# 1) ë°ì´í„° ë¡œë“œ
df = pd.read_csv(data_csv)
print("df shape:", df.shape)

# 2) ë§ˆì§€ë§‰ ìœˆë„ìš° í•˜ë‚˜ ë§Œë“¤ê¸°
values = df[FEATURE_COLS].values
last_seq = values[-WINDOW_SIZE:]           # (40, 5)

# 3) ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ + ìŠ¤ì¼€ì¼ë§
meta = joblib.load(scaler_path)
scaler = meta["scaler"]

last_seq_scaled = scaler.transform(last_seq)          # (40, 5)
X = last_seq_scaled.reshape(1, WINDOW_SIZE, len(FEATURE_COLS))  # (1, 40, 5)

# 4) ëª¨ë¸ ë¡œë“œ
model = LSTMModel(
    input_dim=len(FEATURE_COLS),
    hidden_dim=HIDDEN_DIM,
    num_layers=NUM_LAYERS,
    dropout=DROPOUT,
)
state = torch.load(model_path, map_location="cpu")
model.load_state_dict(state)
model.eval()

with torch.no_grad():
    out = model(torch.tensor(X, dtype=torch.float32))
    next_return = float(out[0, 0])

print(f"ğŸ“ˆ {TICKER} ì˜ˆì¸¡ next-day return â‰ˆ {next_return:.4f}")
