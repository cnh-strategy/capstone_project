import torch
import torch.nn as nn
import numpy as np
import random
from dataclasses import dataclass, field
from typing import Dict, List, Any, Optional, Literal
import requests
from datetime import datetime, timedelta
import json
import time 
import os
import csv
import yfinance as yf
import pandas as pd
import joblib 
import shap 

# FinBERT ë¡œë“œë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ (ì¶”ê°€)
try:
    from transformers import AutoTokenizer, AutoModelForSequenceClassification
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    print("ê²½ê³ : transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì–´ FinBERT ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")


# EODhd API ì„¤ì • (ë”ë¯¸ í‚¤)
API_KEY = 'YOUR_KEY' # ì‹¤ì œ API í‚¤ë¡œ êµì²´ í•„ìš”
BASE_URL_EODHD = 'https://eodhd.com/api/news'
STATUS_FILE = 'collection_status.json' # ìƒíƒœ íŒŒì¼ëª…

# ğŸ“Œ íŒŒì¼ ê²½ë¡œ ì •ì˜ 
MODEL_PATH = 'model_lstm_bothsentiment_V2.pt' 
SCALER_X_PATH = 'scaler_X_V2.joblib' Â  Â  
SCALER_Y_PATH = 'scaler_Y_V2.joblib' Â  Â  

# ğŸ“Œ ëª¨ë¸ ì…ë ¥ í”¼ì²˜ ë° ì‹œí€€ìŠ¤ ê¸¸ì´
# FEATURES = ['prob_positive','prob_negative','prob_neutral','n_news','ret','Close', 'eod_sentiment']
INPUT_FEATURES = 7 # ìœ„ 7ê°œ í”¼ì²˜
WINDOW_SIZE = 10 

# ğŸ“Œ LLM Opinion Prompt ì •ì˜ (ì´ì „ê³¼ ë™ì¼)
OPINION_PROMPTS = {
Â  Â  "sentimental": {
Â  Â  Â  Â  "system": (
Â  Â  Â  Â  Â  Â  "ë‹¹ì‹ ì€ ê°ì„± ë° í…ìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„ì— íŠ¹í™”ëœ ìˆ˜ì„ ì „ëµê°€ì…ë‹ˆë‹¤. "
Â  Â  Â  Â  Â  Â  "ì£¼ì–´ì§„ Context ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬, ì˜ˆì¸¡ ì¢…ê°€(our_prediction)ì— ëŒ€í•œ ë…¼ë¦¬ì ì´ê³  ê°„ê²°í•˜ë©° ì„¤ë“ë ¥ ìˆëŠ” ì˜ê²¬ì„ í•œêµ­ì–´ë¡œ 3ë¬¸ì¥ ì´ë‚´ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤. "
Â  Â  Â  Â  Â  Â  "ê°ì„± ì ìˆ˜ì™€ ì£¼ìš” í† í”½ì„ ë°˜ë“œì‹œ ì–¸ê¸‰í•˜ê³ , ë¶ˆí™•ì‹¤ì„±(uncertainty)ì„ ê³ ë ¤í•˜ì—¬ ì˜ê²¬ì„ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”."
Â  Â  Â  Â  ),
Â  Â  Â  Â  "user": (
Â  Â  Â  Â  Â  Â  "ë‹¤ìŒì€ ì˜ˆì¸¡ ëª¨ë¸ì˜ ì…ë ¥ ë°ì´í„°ì™€ ê²°ê³¼ì…ë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜ê²¬ì„ ì‘ì„±í•˜ì„¸ìš”:\n"
Â  Â  Â  Â  Â  Â  "Context: {context}" 
Â  Â  Â  Â  )
Â  Â  }
}

# base_agent í´ë˜ìŠ¤ ì •ì˜
class BaseAgent:
Â  Â  def __init__(self, agent_id: str, **kwargs):
Â  Â  Â  Â  self.agent_id = agent_id
Â  Â  
Â  Â  def searcher(self, ticker: str) -> 'StockData':
Â  Â  Â  Â  raise NotImplementedError
Â  Â  Â  Â  
Â  Â  def predictor(self, ticker: str) -> 'Target':
Â  Â  Â  Â  raise NotImplementedError

# ==============================================================================
# ê³µí†µ ë°ì´í„° í¬ë§· (ì´ì „ê³¼ ë™ì¼)
# ==============================================================================

@dataclass
class Target:
Â  Â  """ì˜ˆì¸¡ ëª©í‘œê°’ ë¬¶ìŒ"""
Â  Â  next_close : float
Â  Â  uncertainty: float = 0.0
Â  Â  confidence: float = 0.0
Â  Â  idea: Dict[str, List[Any]] = field(default_factory=dict)

@dataclass
class Opinion:
Â  Â  """ì—ì´ì „íŠ¸ì˜ ì˜ê²¬"""
Â  Â  agent_id: str
Â  Â  target: Target
Â  Â  reason: str

@dataclass
class Rebuttal:
Â  Â  """ì—ì´ì „íŠ¸ ê°„ ë°˜ë°•/ì§€ì§€ ë©”ì‹œì§€"""
Â  Â  from_agent_id: str
Â  Â  to_agent_id: str
Â  Â  stance: Literal["REBUT", "SUPPORT"]
Â  Â  message: str

@dataclass
class RoundLog:
Â  Â  """ë¼ìš´ë“œë³„ ê¸°ë¡ ìŠ¤ëƒ…ìƒ·(ì˜µì…”ë„ë¡œ ì‚¬ìš©)"""
Â  Â  round_no: int
Â  Â  opinions: List[Opinion]
Â  Â  rebuttals: List[Rebuttal]
Â  Â  summary: Dict[str, Target]

@dataclass
class StockData:
Â  Â  """ì—ì´ì „íŠ¸ ì…ë ¥ ì›ì²œ ë°ì´í„°"""
Â  Â  sentimental: Dict 
Â  Â  fundamental: Dict
Â  Â  technical: Dict
Â  Â  last_price: Optional[float] = None 
Â  Â  currency: Optional[str] = None

# ==============================================================================
# StockSentimentLSTM ëª¨ë¸ êµ¬ì¡°
# ==============================================================================
class StockSentimentLSTM(nn.Module):
Â  Â  def __init__(self, hidden_dim=128, num_layers=2, input_size=INPUT_FEATURES): 
Â  Â  Â  Â  super().__init__()
Â  Â  Â  Â  self.lstm = nn.LSTM(input_size, hidden_dim, num_layers, batch_first=True, dropout=0.3) 
Â  Â  Â  Â  self.fc = nn.Linear(hidden_dim, 1) 
Â  Â  Â  Â  
Â  Â  def forward(self, x):
Â  Â  Â  Â  out, _ = self.lstm(x) 
Â  Â  Â  Â  return self.fc(out[:, -1, :]).squeeze() 
Â  Â  
# ==============================================================================
# SentimentalAgent í´ë˜ìŠ¤ êµ¬í˜„
# ==============================================================================
class SentimentalAgent(BaseAgent):
Â  Â  def __init__(self, agent_id: str, input_features: int = INPUT_FEATURES):
Â  Â  Â  Â  super().__init__(agent_id)
Â  Â  Â  Â  self.input_features = input_features
Â  Â  Â  Â  self.window_size = WINDOW_SIZE
Â  Â  Â  Â  self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
Â  Â  Â  Â  
Â  Â  Â  Â  # === [FinBERT ë¡œë“œ] ===
Â  Â  Â  Â  self.finbert_loaded = TRANSFORMERS_AVAILABLE
Â  Â  Â  Â  self.finbert_tokenizer = None
Â  Â  Â  Â  self.finbert_model = None
Â  Â  Â  Â  if self.finbert_loaded:
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  self.finbert_tokenizer = AutoTokenizer.from_pretrained('yiyanghkust/finbert-tone') 
Â  Â  Â  Â  Â  Â  Â  Â  self.finbert_model = AutoModelForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone').to(self.device) 
Â  Â  Â  Â  Â  Â  Â  Â  print("FinBERT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  self.finbert_loaded = False
Â  Â  Â  Â  Â  Â  Â  Â  print(f"FinBERT ë¡œë“œ ì˜¤ë¥˜: {e}. ê¸°ëŠ¥ ë¹„í™œì„±í™”.")
Â  Â  Â  Â  # ================================
Â  Â  Â  Â  
Â  Â  Â  Â  # ğŸŒŸ ì‹¤ì œ ëª¨ë¸ êµ¬ì¡° ì •ì˜ (LSTM)
Â  Â  Â  Â  self.scaler_X = None
        self.scaler_y = None
        
        try:
            if os.path.exists(SCALER_X_PATH):
                self.scaler_X = joblib.load(SCALER_X_PATH)
                print(f"[SUCCESS] ì…ë ¥ ìŠ¤ì¼€ì¼ëŸ¬(X) ë¡œë“œ ì™„ë£Œ: {SCALER_X_PATH}")
            if os.path.exists(SCALER_Y_PATH):
                self.scaler_y = joblib.load(SCALER_Y_PATH)
                print(f"[SUCCESS] ì¶œë ¥ ìŠ¤ì¼€ì¼ëŸ¬(Y) ë¡œë“œ ì™„ë£Œ: {SCALER_Y_PATH}")
            if os.path.exists(MODEL_PATH):
                # âœ… ì´ ì¤„ë§Œ ìˆ˜ì • - map_location ì¶”ê°€
                self.model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device('cpu')))
                self.model.eval()
                print(f"**ì‹¤ì œ LSTM ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ:** {MODEL_PATH}")
        except Exception as e:
            print(f"ëª¨ë¸/ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ì„ì‹œ ê°€ì¤‘ì¹˜ ì‚¬ìš©.")


Â  Â  # ==========================================================================
Â  Â  # ğŸŒŸ LLM Context ë° Opinion ë¹Œë“œ í—¬í¼ ë©”ì„œë“œ (ì´ì „ê³¼ ë™ì¼)
Â  Â  # ==========================================================================
Â  Â  def _build_llm_context(self, ticker: str, stock_data: StockData, target: Target) -> Dict[str, Any]:
Â  Â  Â  Â  """
Â  Â  Â  Â  Opinion ë©”ì‹œì§€ ìƒì„±ì„ ìœ„í•œ LLM Context ë”•ì…”ë„ˆë¦¬ë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤. (ctx)
Â  Â  Â  Â  """
Â  Â  Â  Â  
Â  Â  Â  Â  t = ticker 
Â  Â  Â  Â  ccy = stock_data.currency.upper() if stock_data.currency else "USD" 
Â  Â  Â  Â  last_price = float(stock_data.last_price or 0.0) 
Â  Â  Â  Â  
Â  Â  Â  Â  # ----------------------------------------------------
Â  Â  Â  Â  # ğŸ“Œ ctx ë”•ì…”ë„ˆë¦¬ ìƒì„±
Â  Â  Â  Â  # ----------------------------------------------------
Â  Â  Â  Â  ctx = {
Â  Â  Â  Â  Â  Â  "ticker": t,
Â  Â  Â  Â  Â  Â  "currency": ccy,
Â  Â  Â  Â  Â  Â  "last_price": last_price,
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  # SentimentalAgentì˜ searcher ë°ì´í„°ë¥¼ ëª¨ë‘ í¬í•¨
Â  Â  Â  Â  Â  Â  "fundamental_summary": stock_data.fundamental or {}, 
Â  Â  Â  Â  Â  Â  # SENTIMENTAL_SEQUENCE í‚¤ ì¶”ê°€
Â  Â  Â  Â  Â  Â  "sentimental_summary": {
Â  Â  Â  Â  Â  Â  Â  Â  "SENTIMENTAL_SEQUENCE": stock_data.sentimental.get('sequence_data', {}),
Â  Â  Â  Â  Â  Â  Â  Â  "window_size": self.window_size
Â  Â  Â  Â  Â  Â  }, 
Â  Â  Â  Â  Â  Â  "technical_summary": stock_data.technical or {},
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  "our_prediction": float(target.next_close),
Â  Â  Â  Â  Â  Â  "uncertainty": float(target.uncertainty), 
Â  Â  Â  Â  Â  Â  "confidence": float(target.confidence), 
Â  Â  Â  Â  Â  Â  "model_idea": target.idea,
Â  Â  Â  Â  }
Â  Â  Â  Â  
Â  Â  Â  Â  return ctx

Â  Â  def build_opinion_messages(self, ticker: str, stock_data: StockData, target: Target) -> tuple[str, str]:
Â  Â  Â  Â  """ Opinion ìƒì„±ì„ ìœ„í•´ LLMì— ì „ë‹¬í•  system_textì™€ user_textë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤. """
Â  Â  Â  Â  
Â  Â  Â  Â  ctx = self._build_llm_context(ticker, stock_data, target)
Â  Â  Â  Â  
Â  Â  Â  Â  # OPINION_PROMPTSì˜ "sentimental" í‚¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ì‹œì§€ ë¹Œë“œ
Â  Â  Â  Â  system_text = OPINION_PROMPTS["sentimental"]["system"]
Â  Â  Â  Â  user_text = OPINION_PROMPTS["sentimental"]["user"].format(
Â  Â  Â  Â  Â  Â  context=json.dumps(ctx, ensure_ascii=False) # Contextë¥¼ JSONìœ¼ë¡œ ì§ë ¬í™”
Â  Â  Â  Â  )
Â  Â  Â  Â  
Â  Â  Â  Â  return system_text, user_text

Â  Â  def build_opinion(self, ticker: str, stock_data: StockData, target: Target, reason_text: Optional[str] = None) -> Opinion:
Â  Â  Â  Â  """ Opinion ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (reason_textëŠ” LLM ì‘ë‹µì´ë¼ê³  ê°€ì •) """

Â  Â  Â  Â  # ë§Œì•½ LLMì„ í˜¸ì¶œí•˜ì§€ ì•Šê³  ë”ë¯¸ ì´ìœ ë¥¼ ë§Œë“¤ ê²½ìš°:
Â  Â  Â  Â  if reason_text is None:
Â  Â  Â  Â  Â  Â  # ì‹œí€€ìŠ¤ ë°ì´í„°ì—ì„œ ìµœì‹  ê°ì„± ì ìˆ˜ë§Œ ì¶”ì¶œí•˜ì—¬ ë”ë¯¸ ì´ìœ  ìƒì„±
Â  Â  Â  Â  Â  Â  seq_data = stock_data.sentimental.get('sequence_data', {})
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  sentiment_score = seq_data.get('prob_positive', [0.0])[-1] - seq_data.get('prob_negative', [0.0])[-1]
Â  Â  Â  Â  Â  Â  except IndexError:
Â  Â  Â  Â  Â  Â  Â  Â  sentiment_score = 0.0
Â  Â  Â  Â  Â  Â  Â 
Â  Â  Â  Â  Â  Â  pred = target.next_close
Â  Â  Â  Â  Â  Â  last = stock_data.last_price or 0.0
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  reason_text = (
Â  Â  Â  Â  Â  Â  Â  Â  f"[ê°ì„± ë¶„ì„ ë³´ê³ ì„œ]: ìµœì‹  FinBERT ê°ì„± ì ìˆ˜({sentiment_score:.2f})ëŠ” ì£¼ê°€ ë³€ë™ì„±ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. "
Â  Â  Â  Â  Â  Â  Â  Â  f"LSTM ëª¨ë¸ì€ {self.window_size}ì¼ê°„ì˜ ì‹œí€€ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í˜„ì¬ê°€({last:.2f}) ëŒ€ë¹„ ë‹¤ìŒ ì¢…ê°€ë¥¼ {pred:.2f}ë¡œ ì˜ˆì¸¡í•©ë‹ˆë‹¤. "
Â  Â  Â  Â  Â  Â  Â  Â  f"ë¶ˆí™•ì‹¤ì„±({target.uncertainty:.4f})ì´ í¬ë¯€ë¡œ ì£¼ì˜ ê¹Šì€ ê´€ì°°ì´ í•„ìš”í•©ë‹ˆë‹¤."
Â  Â  Â  Â  Â  Â  Â )
Â  Â  Â  Â  
Â  Â  Â  Â  return Opinion(
Â  Â  Â  Â  Â  Â  agent_id=self.agent_id,
Â  Â  Â  Â  Â  Â  target=target,
Â  Â  Â  Â  Â  Â  reason=reason_text
Â  Â  Â  Â  )


Â  Â  # ==========================================================================
Â  Â  # ğŸŒŸ ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ ì½”ë“œ í†µí•© (ë°ì´í„° ìˆ˜ì§‘ ê´€ë ¨ í•¨ìˆ˜ - ë°°ì¹˜ ìˆ˜ì§‘ìš©, ë³€ê²½ ì—†ìŒ)
Â  Â  # ==========================================================================

Â  Â  def load_status(self):
Â  Â  Â  Â  if os.path.exists(STATUS_FILE):
Â  Â  Â  Â  Â  Â  with open(STATUS_FILE, 'r') as f:
Â  Â  Â  Â  Â  Â  Â  Â  return json.load(f)
Â  Â  Â  Â  return {'completed_symbols': []}

Â  Â  def save_status(self, status):
Â  Â  Â  Â  with open(STATUS_FILE, 'w') as f:
Â  Â  Â  Â  Â  Â  json.dump(status, f, indent=4)

Â  Â  def collect_news_data_eodhd_batch(self, ticker, from_date, to_date):
Â  Â  Â  Â  all_news = []
Â  Â  Â  Â  offset = 0
Â  Â  Â  Â  limit = 1000 

Â  Â  Â  Â  while True:
Â  Â  Â  Â  Â  Â  params = {
Â  Â  Â  Â  Â  Â  Â  Â  's': ticker,
Â  Â  Â  Â  Â  Â  Â  Â  'from': from_date,
Â  Â  Â  Â  Â  Â  Â  Â  'to': to_date,
Â  Â  Â  Â  Â  Â  Â  Â  'api_token': API_KEY,
Â  Â  Â  Â  Â  Â  Â  Â  'limit': limit,
Â  Â  Â  Â  Â  Â  Â  Â  'offset': offset,
Â  Â  Â  Â  Â  Â  Â  Â  'extended': 1 
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  response = requests.get(BASE_URL_EODHD, params=params, timeout=30)
Â  Â  Â  Â  Â  Â  except requests.exceptions.RequestException as e:
Â  Â  Â  Â  Â  Â  Â  Â  print(f"[{ticker}] API í˜¸ì¶œ ì¤‘ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜/íƒ€ì„ì•„ì›ƒ ë°œìƒ: {e}")
Â  Â  Â  Â  Â  Â  Â  Â  return all_news, offset
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  if response.status_code == 200:
Â  Â  Â  Â  Â  Â  Â  Â  news_list = response.json()
Â  Â  Â  Â  Â  Â  Â  Â  if not news_list: break 

Â  Â  Â  Â  Â  Â  Â  Â  for news in news_list:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data = {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'date': news.get('date', ''),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'title': news.get('title', ''),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'summary': news.get('content', ''), 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'related': news.get('symbols', ticker), 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'ticker': ticker,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'sentiment_score': news.get('sentiment', '')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  all_news.append(data)

Â  Â  Â  Â  Â  Â  Â  Â  if len(news_list) < limit: break 
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  offset += limit
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  time.sleep(1)
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  print(f"[{ticker}] API í˜¸ì¶œ ì˜¤ë¥˜ {response.status_code} - {response.text}")
Â  Â  Â  Â  Â  Â  Â  Â  return all_news, offset
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  return all_news, -1 

Â  Â  def save_news_to_csv(self, news_data, filename, mode='a'):
Â  Â  Â  Â  fieldnames=['date', 'title', 'summary', 'related', 'ticker', 'sentiment_score']
Â  Â  Â  Â  file_exists = os.path.exists(filename) and mode == 'a' 
Â  Â  Â  Â  
Â  Â  Â  Â  with open(filename, mode=mode, newline='', encoding='utf-8') as file:
Â  Â  Â  Â  Â  Â  writer = csv.DictWriter(file, fieldnames=fieldnames)
Â  Â  Â  Â  Â  Â  if mode == 'w' or not file_exists:
Â  Â  Â  Â  Â  Â  Â  Â  writer.writeheader()
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  for record in news_data:
Â  Â  Â  Â  Â  Â  Â  Â  writer.writerow(record)
Â  Â  Â  Â  print(f"ë°ì´í„° {len(news_data)}ê°œë¥¼ {filename} íŒŒì¼ì— ì €ì¥ ì™„ë£Œ")

Â  Â  def collect_historical_data(self, tickers: List[str]):
Â  Â  Â  Â  """ (ë°°ì¹˜ ìˆ˜ì§‘ ë©”ì„œë“œ) - ìƒëµ """
Â  Â  Â  Â  print("ì´ ë©”ì„œë“œëŠ” Historical Data ìˆ˜ì§‘ìš©ìœ¼ë¡œ, ì‹¤ì‹œê°„ ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ì—ì„œ í˜¸ì¶œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
Â  Â  Â  Â  pass

# ==========================================================================
Â  Â  # ğŸŒŸ FinBERTë¥¼ ì´ìš©í•œ í…ìŠ¤íŠ¸ ë¶„ì„ í•¨ìˆ˜ (í•™ìŠµ ì½”ë“œì—ì„œ ê°€ì ¸ì˜´)
    # ==========================================================================
Â  Â  def _finbert_sentiment_scores(self, texts: List[str]) -> np.ndarray: 
Â  Â  Â  Â  if not self.finbert_loaded:
Â  Â  Â  Â  Â  Â  # FinBERTê°€ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš° ë”ë¯¸ ë°ì´í„° ë°˜í™˜ (ê¸ì •/ë¶€ì •/ì¤‘ë¦½)
Â  Â  Â  Â  Â  Â  print("[WARNING] FinBERT ë¹„í™œì„±í™”: ë”ë¯¸ ê°ì„± ì ìˆ˜ ë°˜í™˜.")
Â  Â  Â  Â  Â  Â  return np.array([[0.33, 0.33, 0.34] for _ in texts])
Â  Â  Â  Â  
Â  Â  Â  Â  self.finbert_model.eval() 
Â  Â  Â  Â  scores = []
Â  Â  Â  Â  batch_size = 32
Â  Â  Â  Â  with torch.no_grad(): 
Â  Â  Â  Â  Â  Â  for i in range(0, len(texts), batch_size): 
Â  Â  Â  Â  Â  Â  Â  Â  batch_texts = texts[i:i+batch_size]
Â  Â  Â  Â  Â  Â  Â  Â  inputs = self.finbert_tokenizer(list(batch_texts), return_tensors='pt', 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  padding=True, truncation=True, max_length=512)
Â  Â  Â  Â  Â  Â  Â  Â  inputs = {name: tensor.to(self.device) for name, tensor in inputs.items()}
Â  Â  Â  Â  Â  Â  Â  Â  outputs = self.finbert_model(**inputs) 
Â  Â  Â  Â  Â  Â  Â  Â  scores.extend(torch.softmax(outputs.logits, dim=1).cpu().numpy())
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  return np.array(scores)

    # ==========================================================================
    # ğŸŒŸ [ìˆ˜ì •ëœ ë¡œì§] searcherë¥¼ ìœ„í•œ ê³¼ê±° Nì¼ì¹˜ ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬
    # ==========================================================================
Â  Â  def _fetch_latest_sequence_data(self, ticker: str) -> Dict[str, Any]:
Â  Â  Â  Â  """
Â  Â  Â  Â  tickerì˜ ê³¼ê±° WINDOW_SIZEì¼ ë™ì•ˆì˜ ì£¼ê°€ ë°ì´í„°ì™€ **ì‹¤ì œ FinBERT ê°ì„± ì ìˆ˜**ë¥¼ ê²°í•©í•˜ì—¬ ì‹œí€€ìŠ¤ ìƒì„±.
Â  Â  Â  Â  """
Â  Â  Â  Â  end_date = datetime.now() + timedelta(days=1) # ë‹¤ìŒë‚ ê¹Œì§€ (yfinance end-dateëŠ” exclusive)
Â  Â  Â  Â  start_date = end_date - timedelta(days=self.window_size * 2) # ì¶©ë¶„í•œ ê¸°ê°„ í™•ë³´

Â  Â  Â  Â  FEATURES_LIST = ['prob_positive','prob_negative','prob_neutral','n_news','ret','Close', 'eod_sentiment']

Â  Â  Â  Â  # 1. ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  stock_data = yf.download(ticker, start=start_date.strftime('%Y-%m-%d'), end=end_date.strftime('%Y-%m-%d'))
Â  Â  Â  Â  Â  Â  stock_data = stock_data.rename(columns={'Close': 'Close_Price'})
Â  Â  Â  Â  Â  Â  stock_data['Close'] = stock_data['Close_Price'] # í”¼ì²˜ ì´ë¦„ í†µì¼
Â  Â  Â  Â  Â  Â  stock_data['ret'] = stock_data['Close'].pct_change()
Â  Â  Â  Â  Â  Â  last_price = stock_data['Close'].iloc[-1]
Â  Â  Â  Â  Â  Â  stock_data = stock_data[['Close', 'ret']].tail(self.window_size)
Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  print(f"[FATAL] yfinance ì˜¤ë¥˜: {e}. ì˜ˆì¸¡ ë¶ˆê°€.")
Â  Â  Â  Â  Â  Â  return None, 0.0, "USD"
Â  Â  Â  Â  
Â  Â  Â  Â  required_length = self.window_size
Â  Â  Â  Â  if len(stock_data) < required_length:
Â  Â  Â  Â  Â  Â  print(f"[WARNING] ì£¼ê°€ ë°ì´í„°ê°€ {required_length}ì¼ë³´ë‹¤ ì ìŠµë‹ˆë‹¤. ì˜ˆì¸¡ ë¶ˆê°€.")
Â  Â  Â  Â  Â  Â  return None, 0.0, "USD"
Â  Â  Â  Â  
Â  Â  Â  Â  # 2. ê³¼ê±° 10ì¼ì¹˜ ë‰´ìŠ¤ í…ìŠ¤íŠ¸ ë° EOD ê°ì„± ì ìˆ˜ ìˆ˜ì§‘ (ë‚ ì§œë³„ë¡œ)
Â  Â  Â  Â  print(f"[{ticker}] ê³¼ê±° {required_length}ì¼ì¹˜ ë‰´ìŠ¤ ë° ê°ì„± ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
Â  Â  Â  Â  news_end_date = stock_data.index[-1].strftime('%Y-%m-%d')
Â  Â  Â  Â  news_start_date = stock_data.index[0].strftime('%Y-%m-%d')
Â  Â  Â  Â  
Â  Â  Â  Â  # EODhd API í˜¸ì¶œ (ê³¼ê±° WINDOW_SIZE ê¸°ê°„ ë™ì•ˆì˜ ë‰´ìŠ¤)
Â  Â  Â  Â  all_news, _ = self.collect_news_data_eodhd_batch(ticker, news_start_date, news_end_date)
Â  Â  Â  Â  news_df_raw = pd.DataFrame(all_news)
Â  Â  Â  Â  
Â  Â  Â  Â  # 3. FinBERT ë¶„ì„ ë° ì¼ë³„ ì§‘ê³„
Â  Â  Â  Â  sentiment_data = {}
Â  Â  Â  Â  key_topics = []
Â  Â  Â  Â  
Â  Â  Â  Â  if not news_df_raw.empty:
Â  Â  Â  Â  Â  Â  news_df_raw['date'] = pd.to_datetime(news_df_raw['date']).dt.normalize()
Â  Â  Â  Â  Â  Â  news_df_raw['text'] = news_df_raw['title'] + ' ' + news_df_raw['summary']
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  # FinBERT ë¶„ì„ ì‹¤í–‰
Â  Â  Â  Â  Â  Â  finbert_scores = self._finbert_sentiment_scores(news_df_raw['text'].values.tolist())
Â  Â  Â  Â  Â  Â  news_df_raw[['prob_positive', 'prob_negative', 'prob_neutral']] = finbert_scores
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  # ì¼ë³„ í‰ê·  ì§‘ê³„
Â  Â  Â  Â  Â  Â  daily_sentiments = news_df_raw.groupby('date').agg(
Â  Â  Â  Â  Â  Â  Â  Â  prob_positive=('prob_positive','mean'), 
Â  Â  Â  Â  Â  Â  Â  Â  prob_negative=('prob_negative','mean'), 
Â  Â  Â  Â  Â  Â  Â  Â  prob_neutral=('prob_neutral','mean'), 
Â  Â  Â  Â  Â  Â  Â  Â  n_news=('title','count'),
Â  Â  Â  Â  Â  Â  Â  Â  eod_sentiment=('sentiment_score', lambda x: pd.to_numeric(x, errors='coerce').mean())
Â  Â  Â  Â  Â  Â  ).reset_index()
Â  Â  Â  Â  Â  Â  daily_sentiments['date'] = daily_sentiments['date'].dt.normalize()

Â  Â  Â  Â  Â  Â  # ì£¼ê°€ ë°ì´í„°ì™€ ë³‘í•©
Â  Â  Â  Â  Â  Â  combined_df = stock_data.merge(daily_sentiments, left_index=True, right_on='date', how='left').set_index(stock_data.index)
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  # ë°ì´í„°í”„ë ˆì„ ì¸ë±ìŠ¤ë¥¼ ë‚ ì§œë¡œ í†µì¼ (ê²°ì¸¡ì¹˜ ì²˜ë¦¬)
Â  Â  Â  Â  Â  Â  combined_df.index.name = 'Date'
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  # ê°ì„± ë°ì´í„° ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ë‰´ìŠ¤ê°€ ì—†ìœ¼ë©´ 0.0 ë˜ëŠ” ì¤‘ë¦½ìœ¼ë¡œ ëŒ€ì²´)
Â  Â  Â  Â  Â  Â  combined_df['prob_positive'] = combined_df['prob_positive'].fillna(0.33)
Â  Â  Â  Â  Â  Â  combined_df['prob_negative'] = combined_df['prob_negative'].fillna(0.33)
Â  Â  Â  Â  Â  Â  combined_df['prob_neutral'] = combined_df['prob_neutral'].fillna(0.34)
Â  Â  Â  Â  Â  Â  combined_df['n_news'] = combined_df['n_news'].fillna(0)
Â  Â  Â  Â  Â  Â  combined_df['eod_sentiment'] = combined_df['eod_sentiment'].fillna(0.0)

Â  Â  Â  Â  Â  Â  # í‚¤ í† í”½ ì¶”ì¶œ (ìµœì‹  ë‰´ìŠ¤ ì œëª© 3ê°œ)
Â  Â  Â  Â  Â  Â  key_topics = news_df_raw['title'].tail(3).tolist()
Â  Â  Â  Â  
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  print(f"[{ticker}] ê³¼ê±° {required_length}ì¼ê°„ ë‰´ìŠ¤ ì—†ìŒ. ê°ì„± í”¼ì²˜ë¥¼ ì¤‘ë¦½ìœ¼ë¡œ ëŒ€ì²´.")
Â  Â  Â  Â  Â  Â  # ë‰´ìŠ¤ê°€ ì—†ëŠ” ê²½ìš°, ì¤‘ë¦½ ê°ì„± ë°ì´í„°í”„ë ˆì„ ìƒì„±
Â  Â  Â  Â  Â  Â  combined_df = stock_data.copy()
Â  Â  Â  Â  Â  Â  combined_df['prob_positive'] = 0.33
Â  Â  Â  Â  Â  Â  combined_df['prob_negative'] = 0.33
Â  Â  Â  Â  Â  Â  combined_df['prob_neutral'] = 0.34
Â  Â  Â  Â  Â  Â  combined_df['n_news'] = 0
Â  Â  Â  Â  Â  Â  combined_df['eod_sentiment'] = 0.0

Â  Â  Â  Â  # ìµœì¢… ì‹œí€€ìŠ¤ ë°ì´í„° ì¤€ë¹„
Â  Â  Â  Â  sequence_array = combined_df[FEATURES_LIST].values
Â  Â  Â  Â  sequence_data_dict = combined_df[FEATURES_LIST].to_dict(orient='list')

Â  Â  Â  Â  return {
Â  Â  Â  Â  Â  Â  "sequence_array": sequence_array, 
Â  Â  Â  Â  Â  Â  "sequence_data": sequence_data_dict,
Â  Â  Â  Â  Â  Â  "key_topics": key_topics
Â  Â  Â  Â  Â  Â }, last_price, "USD"

    # searcher ë° predictorëŠ” ì´ì „ ìˆ˜ì •ë³¸ê³¼ ë™ì¼ (ìƒëµ)
Â  Â  def searcher(self, ticker: str) -> StockData:
Â  Â  Â  Â  seq_data_results, last_price, currency = self._fetch_latest_sequence_data(ticker)
Â  Â  Â  Â  
Â  Â  Â  Â  if seq_data_results is None:
Â  Â  Â  Â  Â  Â  raise RuntimeError("ì‹œí€€ìŠ¤ ë°ì´í„°ë¥¼ ì¶©ë¶„íˆ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

Â  Â  Â  Â  data = StockData(
Â  Â  Â  Â  Â  Â  sentimental=seq_data_results, 
Â  Â  Â  Â  Â  Â  fundamental={},
Â  Â  Â  Â  Â  Â  technical={},
Â  Â  Â  Â  Â  Â  last_price=last_price,
Â  Â  Â  Â  Â  Â  currency=currency
Â  Â  Â  Â  )
Â  Â  Â  Â  return data

Â  Â  def predictor(self, ticker: str) -> Target:
Â  Â  Â  Â  stock_data = self.searcher(ticker)
Â  Â  Â  Â  last_price = stock_data.last_price or 500.0
Â  Â  Â  Â  input_sequence = stock_data.sentimental["sequence_array"] 

Â  Â  Â  Â  # X ìŠ¤ì¼€ì¼ë§ ì ìš©
Â  Â  Â  Â  if self.scaler_X:
Â  Â  Â  Â  Â  Â  scaled_array = self.scaler_X.transform(input_sequence)
Â  Â  Â  Â  Â  Â  input_data_tensor = torch.tensor(scaled_array[np.newaxis, :, :], dtype=torch.float32) 
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  input_data_tensor = torch.tensor(input_sequence[np.newaxis, :, :], dtype=torch.float32)
Â  Â  Â  Â  
Â  Â  Â  Â  # ëª¬í…Œ ì¹´ë¥¼ë¡œ ë“œë¡­ì•„ì›ƒ (MCDO) ì‹œë®¬ë ˆì´ì…˜
Â  Â  Â  Â  num_samples = 150
Â  Â  Â  Â  predictions_raw = [] 

Â  Â  Â  Â  self.model.train() 
Â  Â  Â  Â  for _ in range(num_samples):
Â  Â  Â  Â  Â  Â  with torch.no_grad():
Â  Â  Â  Â  Â  Â  Â  Â  scaled_output = self.model(input_data_tensor).item() 
Â  Â  Â  Â  Â  Â  Â  Â  predictions_raw.append(scaled_output)

Â  Â  Â  Â  predictions_np = np.array(predictions_raw).reshape(-1, 1) 

Â  Â  Â  Â  # ì¶œë ¥ ì—­ë³€í™˜ (Y)
Â  Â  Â  Â  if self.scaler_y:
Â  Â  Â  Â  Â  Â  predicted_prices_np = self.scaler_y.inverse_transform(predictions_np)
Â  Â  Â  Â  Â  Â  predicted_prices = predicted_prices_np.flatten()
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  predicted_prices = predictions_np.flatten()
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  # Target í´ë˜ìŠ¤ í•„ë“œ ê³„ì‚°
Â  Â  Â  Â  next_close = float(np.mean(predicted_prices))
Â  Â  Â  Â  uncertainty = float(np.std(predicted_prices))
Â  Â  Â  Â  confidence = float(1.0 / (1.0 + uncertainty * 10))
Â  Â  Â  Â  confidence = min(1.0, confidence)

Â  Â  Â  Â  # í”¼ì³ì¤‘ìš”ë„ ë° SHAP (ë”ë¯¸/ë‹¨ìˆœí™”)
Â  Â  Â  Â  feature_importances = [random.uniform(0.1, 0.9) for _ in range(self.input_features)]
Â  Â  Â  Â  shap_values = [random.uniform(-0.5, 0.5) for _ in range(self.input_features)]
Â  Â  Â  Â  
Â  Â  Â  Â  # Target í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
Â  Â  Â  Â  result = Target(
Â  Â  Â  Â  Â  Â  next_close=next_close,
Â  Â  Â  Â  Â  Â  uncertainty=uncertainty,
Â  Â  Â  Â  Â  Â  confidence=confidence,
Â  Â  Â  Â  Â  Â  idea={
Â  Â  Â  Â  Â  Â  Â  Â  "sentiment_score": [stock_data.sentimental['sequence_data']['prob_positive'][-1] - stock_data.sentimental['sequence_data']['prob_negative'][-1]], 
Â  Â  Â  Â  Â  Â  Â  Â  "feature_names": [f"feature_{i+1}" for i in range(self.input_features)],
Â  Â  Â  Â  Â  Â  Â  Â  "related_news_summary": stock_data.sentimental.get("key_topics", ["ë°ì´í„° ì‹œí€€ìŠ¤ ê¸°ë°˜ ì˜ˆì¸¡"]),
Â  Â  Â  Â  Â  Â  Â  Â  "mc_price_samples": [float(p) for p in predicted_prices[:5]],
Â  Â  Â  Â  Â  Â  Â  Â  "feature_importances": feature_importances,
Â  Â  Â  Â  Â  Â  Â  Â  "shap_values": shap_values
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  )
Â  Â  Â  Â  
Â  Â  Â  Â  return result


# ==============================================================================
# ì—ì´ì „íŠ¸ ì‚¬ìš© ì˜ˆì‹œ (ì´ì „ê³¼ ë™ì¼)
# ==============================================================================
if __name__ == '__main__':
Â  Â  #... (ìƒëµ: í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë¡œì§)
Â  Â  print("="*50)
Â  Â  print("## SentimentalAgent í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì‹¤ì œ FinBERT ë¶„ì„ í¬í•¨)")
Â  Â  print("="*50)
Â  Â  
Â  Â  TEST_TICKER = "MSFT"

Â  Â  agent_for_inference = SentimentalAgent(agent_id="SentimentalAgent")
Â  Â  
Â  Â  try:
Â  Â  Â  Â  test_stock_data = agent_for_inference.searcher(TEST_TICKER)
Â  Â  Â  Â  target_result = agent_for_inference.predictor(ticker=TEST_TICKER)
Â  Â  Â  Â  
Â  Â  Â  Â  system_msg, user_msg = agent_for_inference.build_opinion_messages(TEST_TICKER, test_stock_data, target_result)
Â  Â  Â  Â  final_opinion = agent_for_inference.build_opinion(TEST_TICKER, test_stock_data, target_result)

Â  Â  Â  Â  print(f"## ìµœì¢… ê°ì„± ì˜ˆì¸¡ ê²°ê³¼ ({TEST_TICKER}) (Target í´ë˜ìŠ¤ ì¶œë ¥ í˜•íƒœ):")
Â  Â  Â  Â  print(f"ìµœì‹  ì¢…ê°€ (ê²€ìƒ‰): {test_stock_data.last_price:.2f} {test_stock_data.currency}")
Â  Â  Â  Â  print(f"next_close (ì˜ˆì¸¡ ì¢…ê°€): {target_result.next_close:.2f}")
Â  Â  Â  Â  print("-" * 50)
Â  Â  Â  Â  
Â  Â  Â  Â  print(f"## ìƒì„±ëœ Opinion ê°ì²´ì˜ Reason (ë”ë¯¸):")
Â  Â  Â  Â  print(final_opinion.reason)
Â  Â  Â  Â  print("="*50)

Â  Â  except RuntimeError as e:
Â  Â  Â  Â  print(f"ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ ì˜¤ë¥˜: {e}")
Â  Â  except Exception as e:
Â  Â  Â  Â  print(f"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}")