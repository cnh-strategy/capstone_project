# ===============================================================
# BaseAgent: LLM ê¸°ë°˜ ê³µí†µ ì¸í„°í˜ì´ìŠ¤
# ===============================================================
from __future__ import annotations
from dataclasses import dataclass
from typing import Dict, List, Optional, Literal, Tuple
from collections import defaultdict
import os, json, requests
from datetime import datetime
from dotenv import load_dotenv

from agents.macro_agent import MacroPredictor
from agents.macro_agent_with_shap_llm import FundamentalForecastAgent
from debate_ver3_tmp.agents.prompts import OPINION_PROMPTS, REBUTTAL_PROMPTS, REVISION_PROMPTS
from debate_ver3_tmp.config.agents import agents_info, dir_info
from debate_ver3_tmp.core.data_set import build_dataset, load_dataset
import torch
import numpy as np
from torch.utils.data import DataLoader, TensorDataset
from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler
import joblib

# -----------------------------
# ë°ì´í„° êµ¬ì¡° ì •ì˜
# -----------------------------
@dataclass
class Target:
    """ì˜ˆì¸¡ ëª©í‘œê°’ + ë¶ˆí™•ì‹¤ì„± ì •ë³´ í¬í•¨
    - next_close: ë‹¤ìŒ ê±°ë˜ì¼ ì¢…ê°€ ì˜ˆì¸¡ì¹˜
    - uncertainty: Monte Carlo Dropout ê¸°ë°˜ ì˜ˆì¸¡ í‘œì¤€í¸ì°¨(Ïƒ)
    - confidence: ëª¨ë¸ ì‹ ë¢°ë„ Î² (ì •ê·œí™”ëœ ì‹ ë¢°ë„; ì„ íƒì )
    """
    next_close: float
    uncertainty: Optional[float] = None
    confidence: Optional[float] = None
    feature_cols: Optional[List[str]] = None
    importances: Optional[List[float]] = None

@dataclass
class Opinion:
    agent_id: str
    target: Target
    reason: str

@dataclass
class Rebuttal:
    from_agent_id: str
    to_agent_id: str
    stance: Literal["REBUT", "SUPPORT"]
    message: str

@dataclass
class RoundLog:
    round_no: int
    opinions: List[Opinion]
    rebuttals: List[Rebuttal]
    summary: Dict[str, Target]

@dataclass
class StockData:
    agent_id: str = ""
    ticker: str = ""
    X: Optional[np.ndarray] = None
    y: Optional[np.ndarray] = None
    feature_cols: Optional[List[str]] = None
    last_price: Optional[float] = None
    technical: Optional[Dict] = None
    
    def __post_init__(self):
        if self.last_price is None:
            self.last_price = 100.0

# ===============================================================
# BaseAgent í´ë˜ìŠ¤
# ===============================================================
class BaseAgent:
    """LLM ê¸°ë°˜ Multi-Agent Debate ê³µí†µ í´ë˜ìŠ¤"""

    OPENAI_URL = "https://api.openai.com/v1/responses"

    def __init__(
        self,
        agent_id: str,
        model: Optional[str] = None,
        preferred_models: Optional[List[str]] = None,
        temperature: float = 0.2,
        verbose: bool = False,
        need_training: bool = True,
        data_dir: str = dir_info["data_dir"],
        model_dir: str = dir_info["model_dir"],
        ticker: str = "TSLA",

    ):

        load_dotenv()
        self.agent_id = agent_id # ì—ì´ì „íŠ¸ ì‹ë³„ì
        self.model = model # ëª¨ë¸ ì´ë¦„
        self.temperature = temperature # Temperature ì„¤ì • 
        self.verbose = verbose            # ë””ë²„ê¹… ëª¨ë“œ
        self.need_training = need_training # ëª¨ë¸ í•™ìŠµ í•„ìš” ì—¬ë¶€
        self.data_dir = data_dir
        self.model_dir = model_dir
        self.ticker = ticker
        self.scaler = DataScaler(agent_id)
        # ëª¨ë¸ í´ë°± ìš°ì„ ìˆœìœ„
        self.preferred_models = preferred_models or ["gpt-5-mini", "gpt-4.1-mini"]
        if model:
            self.preferred_models = [model] + [
                m for m in self.preferred_models if m != model
            ]

        # API í‚¤ ë¡œë“œ
        self.api_key = os.getenv("CAPSTONE_OPENAI_API")
        if not self.api_key:
            raise RuntimeError("í™˜ê²½ë³€ìˆ˜ CAPSTONE_OPENAI_APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # ê³µí†µ í—¤ë”
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }

        # ìƒíƒœê°’
        self.stockdata: Optional[StockData] = None
        self.opinions: List[Opinion] = []
        self.rebuttals: Dict[int, List[Rebuttal]] = defaultdict(list)

        # JSON Schema
        self.schema_obj_opinion = {
            "type": "object",
            "properties": {
                "next_close": {"type": "number"},
                "reason": {"type": "string"},
            },
            "required": ["next_close", "reason"],
            "additionalProperties": False,
        }
        self.schema_obj_rebuttal = {
            "type": "object",
            "properties": {
                "stance": {"type": "string", "enum": ["REBUT", "SUPPORT"]},
                "message": {"type": "string"},
            },
            "required": ["stance", "message"],
            "additionalProperties": False,
        }

    def searcher(self, ticker: Optional[str] = None, rebuild: bool = False):
        """
        preprocessing.py ê¸°ë°˜ ë°ì´í„° ê²€ìƒ‰ê¸°
        - CSVê°€ ì—†ì„ ê²½ìš° build_dataset()ìœ¼ë¡œ ìë™ ìƒì„±
        - ë§ˆì§€ë§‰ window ì‹œí€€ìŠ¤ë¥¼ torch.tensorë¡œ ë°˜í™˜
        """

        if ticker is None:
            ticker = self.ticker
            
        dataset_path = os.path.join(self.data_dir, f"{ticker}_{self.agent_id}_dataset.csv")

        # ë°ì´í„°ì…‹ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
        if not os.path.exists(dataset_path) or rebuild:
            print(f"âš™ï¸ {ticker} {self.agent_id} dataset not found. Building new dataset...")
            build_dataset(ticker=ticker, save_dir=self.data_dir)

        # CSVì—ì„œ ë°ì´í„°ì…‹ ë¡œë“œ
        X, y, feature_cols = load_dataset(ticker, agent_id=self.agent_id, save_dir=self.data_dir)

        # StockData ì¸ìŠ¤í„´ìŠ¤ ìƒì„±í•´ì„œ self.stockdataì— ì €ì¥ (Load_csv_dataset ê²°ê³¼ ë°˜ì˜)
        self.stockdata = StockData()
        self.stockdata.agent_id = self.agent_id
        self.stockdata.ticker = ticker
        self.stockdata.X = X
        self.stockdata.y = y
        self.stockdata.feature_cols = feature_cols
        
        # ê°€ì¥ ìµœê·¼ window ë°ì´í„°ë§Œ ì‚¬ìš©
        X_latest = X[-1:]  # shape: (1, window_size, n_features)
        X_tensor = torch.tensor(X_latest, dtype=torch.float32)
        
        # ì‹¤ì œ í˜„ì¬ ê°€ê²© ì €ì¥ (yfinanceë¡œ ìµœì‹  Close ê°€ê²© ê°€ì ¸ì˜¤ê¸°)
        import yfinance as yf
        try:
            data = yf.download(ticker, period="1d", interval="1d")
            self.stockdata.last_price = float(data['Close'].iloc[-1])
        except:
            self.stockdata.last_price = 100.0  # ê¸°ë³¸ê°’

        return X_tensor

    def predict(self, X, n_samples: int = 30, current_price: float = None):
        """
        Monte Carlo Dropout ê¸°ë°˜ ì˜ˆì¸¡ + ë¶ˆí™•ì‹¤ì„± ê³„ì‚° (ê³µí†µ)
        ëª¨ë“  Agentì—ì„œ ì‚¬ìš© ê°€ëŠ¥
        """

        if self.agent_id == 'MacroAgent':
            macro_predictor = MacroPredictor(
                base_date=datetime.today(),
                window=40,
                ticker = self.ticker  # âœ… ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë‹¨ì¼ í‹°ì»¤ ì§€ì •
            )
            pred_prices, target, _ = macro_predictor.run_prediction()
            return target

        # 1. ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        self.scaler.load(self.ticker)

        # 2. ì…ë ¥ í…ì„œ ë³€í™˜
        if isinstance(X, np.ndarray):
            # transform()ì€ (X_t, y_t) í˜•íƒœë¡œ ë°˜í™˜ â†’ X_të§Œ ì‚¬ìš©
            X_scaled, _ = self.scaler.transform(X)
            X_tensor = torch.tensor(X_scaled, dtype=torch.float32)
        elif isinstance(X, torch.Tensor):
            X_tensor = X.float()
        else:
            raise TypeError(f"Unsupported input type: {type(X)}")

        # 3. ëª¨ë¸ ì„ íƒ (self.model ë˜ëŠ” self)
        model = getattr(self, "model", None)
        if model is None:
            model = self

        if not hasattr(model, "parameters"):
            raise AttributeError(f"{model} has no parameters()")

        # 4. ë””ë°”ì´ìŠ¤ ì„¤ì •
        try:
            device = next(model.parameters()).device
        except StopIteration:
            device = torch.device("cpu")

        X_tensor = X_tensor.to(device)

        # 5. Dropout í™œì„±í™” (Monte Carlo Dropout)
        model.train()

        preds = []
        with torch.no_grad():
            for _ in range(n_samples):
                y_pred = model(X_tensor).cpu().numpy().flatten()
                preds.append(y_pred)

        preds = np.stack(preds)
        mean_pred = preds.mean(axis=0)
        std_pred = preds.std(axis=0)

        # 6. ì •ê·œí™” ë³µì› (ìƒìŠ¹/í•˜ë½ìœ¨ ë³µì›)
        if hasattr(self.scaler, 'y_scaler') and self.scaler.y_scaler is not None:
            mean_pred = self.scaler.inverse_y(mean_pred)
            std_pred = self.scaler.inverse_y(std_pred)
        else:
            # ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì—†ìœ¼ë©´ ì›ë³¸ ê°’ ì‚¬ìš©
            pass

        # 7. ìƒìŠ¹/í•˜ë½ìœ¨ì„ ì‹¤ì œ ê°€ê²©ìœ¼ë¡œ ë³€í™˜
        if current_price is None:
            # self.stockdataì—ì„œ ì‹¤ì œ í˜„ì¬ ê°€ê²© ê°€ì ¸ì˜¤ê¸°
            current_price = getattr(self.stockdata, 'last_price', 100.0)
        
        # ê¸°ì¡´: ì ˆëŒ€ ì¢…ê°€ ì˜ˆì¸¡
        # return Target(
        #     next_close=float(mean_pred[-1]),
        #     uncertainty=float(std_pred[-1]),
        #     confidence=float(confidence[-1])
        # )
        
        # ìƒˆë¡œìš´: ìƒìŠ¹/í•˜ë½ìœ¨ ì˜ˆì¸¡
        return_rate = float(mean_pred[-1])
        predicted_price = self.scaler.convert_return_to_price(return_rate, current_price) if hasattr(self.scaler, 'convert_return_to_price') else current_price * (1 + return_rate)
        
        # confidence ê³„ì‚°
        confidence = 1 / (std_pred + 1e-8)

        return Target(
            next_close=float(predicted_price),
            uncertainty=float(std_pred[-1]),
            confidence=float(confidence[-1])
        )



    # -----------------------------
    # ë©”ì¸ ì›Œí¬í”Œë¡œ
    # -----------------------------
    def reviewer_draft(self, stock_data, target: Target) -> Opinion:
        """(1) searcher â†’ (2) predicter â†’ (3) LLM(JSON Schema)ë¡œ reason ìƒì„± â†’ Opinion ë°˜í™˜"""

        # 1) ë°ì´í„° ìˆ˜ì§‘
        X = self.searcher(self.ticker)

        # 2) ì˜ˆì¸¡ê°’ ìƒì„±
        target = self.predict(X)

        # 3) LLM í˜¸ì¶œ(reason ìƒì„±)
        if self.agent_id == 'MacroAgent':
            m_agent = FundamentalForecastAgent(agent_id = 'MacroAgent', ticker=self.ticker)
            total_json, opinions = m_agent.run()
            return opinions

        else:
            sys_text, user_text = self._build_messages_opinion(self.stockdata, target)
            msg_sys = self._msg("system", sys_text)
            msg_user = self._msg("user",   user_text)

            parsed = self._ask_with_fallback(msg_sys, msg_user, self.schema_obj_opinion)
            reason = parsed.get("reason") or "(ì‚¬ìœ  ìƒì„± ì‹¤íŒ¨: ë¯¸ì…ë ¥)"

            prompt_set = OPINION_PROMPTS.get(self.agent_id, OPINION_PROMPTS[self.agent_id])

            #ctx
            context = json.dumps({
                "agent_id": self.agent_id,
                "predicted_next_close": round(target.next_close, 3),
                "uncertainty_sigma": round(target.uncertainty or 0.0, 4),
                "confidence_beta": round(target.confidence or 0.0, 4),
                "latest_data": str(stock_data)
            }, ensure_ascii=False, indent=2)

            sys_text = prompt_set["system"]
            user_text = prompt_set["user"].format(context=context)

            parsed = self._ask_with_fallback(
                self._msg("system", sys_text),
                self._msg("user", user_text),
                {"type": "object", "properties": {"reason": {"type": "string"}}, "required": ["reason"]}
            )

            reason = parsed.get("reason", "(ì‚¬ìœ  ìƒì„± ì‹¤íŒ¨)")

            # 4) Opinion ê¸°ë¡/ë°˜í™˜ (í•­ìƒ ìµœì‹  ê°’ append)
            self.opinions.append(Opinion(agent_id=self.agent_id, target=target, reason=reason))

            # ìµœì‹  ì˜¤í”¼ë‹ˆì–¸ ë°˜í™˜
            return self.opinions[-1]

    def reviewer_rebut(self, my_opinion: Opinion, other_opinion: Opinion) -> Rebuttal:
        """LLMì„ í†µí•´ ìƒëŒ€ ì˜ê²¬ì— ëŒ€í•œ ë°˜ë°•/ì§€ì§€ ìƒì„±"""
        prompt_set = REBUTTAL_PROMPTS.get(self.agent_id)

        context = json.dumps({
            "self_agent": my_opinion.agent_id,
            "self_next_close": my_opinion.target.next_close,
            "self_confidence": my_opinion.target.confidence,
            "self_uncertainty": my_opinion.target.uncertainty,
            "self_reason": my_opinion.reason,
            "other_agent": other_opinion.agent_id,
            "other_next_close": other_opinion.target.next_close,
            "other_confidence": other_opinion.target.confidence,
            "other_uncertainty": other_opinion.target.uncertainty,
            "other_reason": other_opinion.reason
        }, ensure_ascii=False, indent=2)

        sys_text = prompt_set["system"]
        user_text = prompt_set["user"].format(context=context)

        parsed = self._ask_with_fallback(
            self._msg("system", sys_text),
            self._msg("user", user_text),
            {
                "type": "object",
                "properties": {
                    "stance": {"type": "string", "enum": ["REBUT", "SUPPORT"]},
                    "message": {"type": "string"}
                },
                "required": ["stance", "message"]
            }
        )

        self.rebuttals.append(Rebuttal(
            from_agent_id=my_opinion.agent_id,
            to_agent_id=other_opinion.agent_id,
            stance=parsed.get("stance", "REBUT"),
            message=parsed.get("message", "(ë°˜ë°•/ì§€ì§€ ì‚¬ìœ  ìƒì„± ì‹¤íŒ¨)")
        ))

        return self.rebuttals[-1]

    def reviewer_revise(
        self,
        revised_target: Target,
        old_opinion: Opinion,
        rebuttals: list,
        others: list,
        X_input=None,
        fine_tune: bool = True,
        lr: float = 1e-4,
        epochs: int = 3,
    ):
        """
        Monte Carlo ê¸°ë°˜ Î²-weighted revised_targetì„ ë°›ì•„
        - ëª¨ë¸ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸(fine-tuning)
        - ìˆ˜ì •ëœ ìˆ˜ì¹˜ì— ëŒ€í•œ LLM reasoning ìƒì„±
        - Opinion ì—…ë°ì´íŠ¸ê¹Œì§€ í•œ ë²ˆì— ìˆ˜í–‰
        """

        # --------------------------------------------
        # 1ï¸âƒ£ Fine-tuning ë‹¨ê³„ (ëª¨ë¸ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸)
        # --------------------------------------------
        if fine_tune and hasattr(self, "model") and X_input is not None:
            try:
                device = next(self.model.parameters()).device
                X_tensor = torch.tensor(X_input, dtype=torch.float32).to(device)
                y_tensor = torch.tensor([[revised_target.next_close]], dtype=torch.float32).to(device)

                self.model.train()
                optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)
                criterion = torch.nn.MSELoss()

                for _ in range(epochs):
                    optimizer.zero_grad()
                    pred = self.model(X_tensor)
                    loss = criterion(pred, y_tensor)
                    loss.backward()
                    optimizer.step()

                loss_value = float(loss.item())
            except Exception as e:
                loss_value = None
                print(f"[{self.agent_id}] fine-tuning ì‹¤íŒ¨: {e}")
        else:
            loss_value = None

        # --------------------------------------------
        # 2ï¸âƒ£ LLM Reasoning ìƒì„± ë‹¨ê³„
        # --------------------------------------------
        prompt_set = REVISION_PROMPTS.get(self.agent_id, REVISION_PROMPTS.get("default"))

        context = json.dumps({
            "agent_id": self.agent_id,
            "new_next_close": revised_target.next_close,
            "my_reason": old_opinion.reason if old_opinion else "(ì´ì „ ì˜ê²¬ ì—†ìŒ)",
            "my_confidence": getattr(old_opinion.target, "confidence", None) if old_opinion else None,
            "my_uncertainty": getattr(old_opinion.target, "uncertainty", None) if old_opinion else None,
            "others": [
                {
                    "agent": o.agent_id,
                    "reason": o.reason,
                    "confidence": getattr(o.target, "confidence", None),
                    "uncertainty": getattr(o.target, "uncertainty", None),
                }
                for o in others
            ],
            "rebuttals": [
                {"from": r.from_agent_id, "stance": r.stance, "message": r.message}
                for r in rebuttals
            ],
            "fine_tune_loss": loss_value,
        }, ensure_ascii=False, indent=2)

        sys_text = prompt_set["system"]
        user_text = prompt_set["user"].format(context=context)

        parsed = self._ask_with_fallback(
            self._msg("system", sys_text),
            self._msg("user", user_text),
            {
                "type": "object",
                "properties": {"reason": {"type": "string"}},
                "required": ["reason"],
                "additionalProperties": False
            },
        )

        # --------------------------------------------
        # 3ï¸âƒ£ ìˆ˜ì •ëœ Opinion ê¸°ë¡
        # --------------------------------------------
        revised_reason = parsed.get("reason", "(ìˆ˜ì • ì‚¬ìœ  ìƒì„± ì‹¤íŒ¨)")
        revised_opinion = Opinion(
            agent_id=self.agent_id,
            target=revised_target,
            reason=revised_reason,
        )
        self.opinions.append(revised_opinion)

        # --------------------------------------------
        # 4ï¸âƒ£ ë””ë²„ê¹… / ë¡œê¹…ìš© ì¶œë ¥
        # --------------------------------------------
        if self.verbose:
            print(
                f"[{self.agent_id}] revise ì™„ë£Œ â†’ "
                f"new_target={revised_target.next_close:.4f}, "
                f"Ïƒ={getattr(revised_target, 'uncertainty', None)}, "
                f"Î²={getattr(revised_target, 'confidence', None)}, "
                f"loss={loss_value:.6f if loss_value else 'N/A'}"
            )

        return self.opinions[-1]

    # -----------------------------
    # ê³µí†µ ìœ í‹¸
    # -----------------------------
    def _p(self, msg: str):
        if self.verbose:
            print(f"[{self.agent_id}] {msg}")

    @staticmethod
    def _msg(role: str, text: str) -> dict:
        return {"role": role, "content": [{"type": "input_text", "text": text}]}

    # -----------------------------
    # êµ¬í˜„ í•„ìš” í•¨ìˆ˜ (ì¶”ìƒ)
    # -----------------------------

    def _build_messages_opinion(self, stock_data: StockData, target: Target) -> Tuple[str, str]:
        """LLM(system/user) ë©”ì‹œì§€ ìƒì„±(êµ¬í˜„ í•„ìš”)"""
        raise NotImplementedError(f"{self.__class__.__name__} must implement _build_messages_opinion method")
    
    def _build_messages_rebuttal(self, *args, **kwargs) -> Tuple[str, str]:
        """LLM(system/user) ë©”ì‹œì§€ ìƒì„±(êµ¬í˜„ í•„ìš”)"""
        raise NotImplementedError(f"{self.__class__.__name__} must implement _build_messages_rebuttal method")
    
    def load_model(self, model_path: Optional[str] = None):
        """ì €ì¥ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ"""

        if model_path is None:
            model_path = os.path.join(self.model_dir, f"{self.ticker}_{self.agent_id}.pt")
        
        if not os.path.exists(model_path):
            print(f"âš ï¸ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
            return False

        checkpoint = torch.load(model_path, map_location=torch.device("cpu"))
        self.load_state_dict(checkpoint["model_state_dict"])
        print(f"âœ… {self.agent_id} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({model_path})")

    def pretrain(self):
        epochs = agents_info[self.agent_id]["epochs"]
        lr = agents_info[self.agent_id]["learning_rate"]
        batch_size = agents_info[self.agent_id]["batch_size"]

        X, y, cols = load_dataset(self.ticker, self.agent_id, save_dir=self.data_dir)
        print(f"[{datetime.now().strftime('%H:%M:%S')}] Pretraining {self.agent_id}")

        split_idx = int(len(X) * 0.8)
        X_train, X_val = X[:split_idx], X[split_idx:]
        y_train, y_val = y[:split_idx], y[split_idx:]

        self.scaler.fit_scalers(X_train, y_train)
        self.scaler.save(self.ticker)

        X_train, y_train = map(torch.tensor, self.scaler.transform(X_train, y_train))
        X_train, y_train = X_train.float(), y_train.float()

        model = self if hasattr(self, 'forward') else self.model
        model.train()
        optimizer = torch.optim.Adam(model.parameters(), lr=lr)
        loss_fn = torch.nn.MSELoss()
        train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)

        for epoch in range(epochs):
            total_loss = 0
            for Xb, yb in train_loader:
                y_pred = model(Xb)
                loss = loss_fn(y_pred, yb)
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                total_loss += loss.item()
            if (epoch + 1) % 5 == 0:
                print(f"  Epoch {epoch+1:03d} | Loss: {total_loss/len(train_loader):.6f}")

        os.makedirs(self.model_dir, exist_ok=True)
        model_path = os.path.join(self.model_dir, f"{self.ticker}_{self.agent_id}.pt")
        torch.save(model.state_dict(), model_path)
        print(f"âœ… {self.agent_id} model saved.\nâœ… pretraining finished.\n")

    # -----------------------------
    # OpenAI API í˜¸ì¶œ
    # -----------------------------
    def _ask_with_fallback(self, msg_sys: dict, msg_user: dict, schema_obj: dict) -> dict:
        """ëª¨ë¸ í´ë°± í¬í•¨ OpenAI Responses API í˜¸ì¶œ"""
        payload_base = {
            "input": [msg_sys, msg_user],
            "text": {
                "format": {
                    "type": "json_schema",
                    "name": "Response",
                    "strict": True,
                    "schema": schema_obj,
                }
            },
            "temperature": self.temperature,
        }
        last_err = None
        for model in self.preferred_models:
            payload = dict(payload_base, model=model)
            try:
                r = requests.post(self.OPENAI_URL, headers=self.headers, json=payload, timeout=120)
                if r.ok:
                    data = r.json()
                    # 1) output_text ìš°ì„  ì‚¬ìš©
                    if isinstance(data.get("output_text"), str) and data["output_text"].strip():
                        try:
                            return json.loads(data["output_text"])
                        except Exception:
                            return {"reason": data["output_text"]}  # JSON ì‹¤íŒ¨ ì‹œ ì›ë¬¸ í…ìŠ¤íŠ¸ ë³´ì¡´
                    # 2) output ë°°ì—´ì—ì„œ í…ìŠ¤íŠ¸ ëª¨ìœ¼ê¸°
                    out = data.get("output")
                    if isinstance(out, list) and out:
                        texts = []
                        for blk in out:
                            for c in blk.get("content", []):
                                if "text" in c:
                                    texts.append(c["text"])
                        joined = "\n".join(t for t in texts if t)
                        if joined.strip():
                            try:
                                return json.loads(joined)
                            except Exception:
                                return {"reason": joined}
                    # ë¹„ì •ìƒ ì‘ë‹µ
                    return {}
                # 400/404ëŠ” ë‹¤ìŒ ëª¨ë¸ë¡œ í´ë°±
                if r.status_code in (400, 404):
                    last_err = (r.status_code, r.text)
                    continue
                # ê¸°íƒ€ ì—ëŸ¬ëŠ” ì¦‰ì‹œ ì˜ˆì™¸
                r.raise_for_status()
            except Exception as e:
                self._p(f"âš ï¸ ëª¨ë¸ {model} ì‹¤íŒ¨: {e}")
                last_err = str(e)
                continue
        raise RuntimeError(f"ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨. ë§ˆì§€ë§‰ ì˜¤ë¥˜: {last_err}")
    # -----------------------------------------
    # ğŸ”¹ ì¶”ê°€: Monte Carlo Dropout ê¸°ë°˜ ë¶ˆí™•ì‹¤ì„± ì¶”ì •
    # -----------------------------------------
    def evaluate(self, ticker: str = None):
        """ê²€ì¦ ë°ì´í„°ë¡œ ì„±ëŠ¥ í‰ê°€"""
        if ticker is None:
            ticker = self.ticker
            
        # ë°ì´í„° ë¡œë“œ
        X, y, feature_cols = load_dataset(ticker, agent_id=self.agent_id, save_dir=self.data_dir)
        
        # ì‹œê³„ì—´ ë¶„í•  (80% í›ˆë ¨, 20% ê²€ì¦)
        split_idx = int(len(X) * 0.8)
        X_val = X[split_idx:]
        y_val = y[split_idx:]
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        self.scaler.load(ticker)
        
        # ê²€ì¦ ë°ì´í„° ì˜ˆì¸¡
        predictions = []
        actual_returns = []
        
        for i in range(len(X_val)):
            X_input = X_val[i:i+1]
            X_tensor = torch.tensor(X_input, dtype=torch.float32)
            
            # ì˜ˆì¸¡
            with torch.no_grad():
                pred_return = self(X_tensor).item()
                predictions.append(pred_return)
                actual_returns.append(y_val[i, 0])
        
        predictions = np.array(predictions)
        actual_returns = np.array(actual_returns)
        
        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        mae = np.mean(np.abs(predictions - actual_returns))
        rmse = np.sqrt(np.mean((predictions - actual_returns) ** 2))
        correlation = np.corrcoef(predictions, actual_returns)[0, 1]
        
        # ë°©í–¥ ì •í™•ë„
        pred_direction = np.sign(predictions)
        actual_direction = np.sign(actual_returns)
        direction_accuracy = np.mean(pred_direction == actual_direction) * 100
        
        return {
            'mae': mae,
            'rmse': rmse,
            'correlation': correlation,
            'direction_accuracy': direction_accuracy,
            'n_samples': len(predictions)
        }

class DataScaler:
    """í•™ìŠµ/ì¶”ë¡ ìš© ì •ê·œí™” ìœ í‹¸ë¦¬í‹° (BaseAgent ë‚´ë¶€ìš©)"""
    def __init__(self, agent_id):
        self.agent_id = agent_id
        self.save_dir = dir_info["scaler_dir"]
        self.x_scaler = agents_info[self.agent_id]["x_scaler"]
        self.y_scaler = agents_info[self.agent_id]["y_scaler"]

    def fit_scalers(self, X_train, y_train):
        ScalerMap = {
            "StandardScaler": StandardScaler,
            "MinMaxScaler": MinMaxScaler,
            "RobustScaler": RobustScaler,
            "None": None,
        }
        Sx = ScalerMap[self.x_scaler]
        Sy = ScalerMap[self.y_scaler]

        # âœ… 3D ì…ë ¥ (samples, seq_len, features) â†’ 2Dë¡œ ë³€í™˜
        n_samples, seq_len, n_feats = X_train.shape
        X_2d = X_train.reshape(-1, n_feats)
        self.x_scaler = Sx().fit(X_2d) if Sx else None
        self.y_scaler = Sy().fit(y_train.reshape(-1, 1)) if Sy else None

    def transform(self, X, y=None):
        # âœ… 3D ì…ë ¥ (samples, seq_len, features) â†’ 2Dë¡œ ë³€í™˜
        if X.ndim == 3:
            n_samples, seq_len, n_feats = X.shape
            X_2d = X.reshape(-1, n_feats)
            X_t = self.x_scaler.transform(X_2d).reshape(n_samples, seq_len, n_feats)
        else:
            X_t = self.x_scaler.transform(X) if self.x_scaler else X

        y_t = (
            self.y_scaler.transform(y.reshape(-1, 1)).flatten()
            if (self.y_scaler and y is not None)
            else y
        )
        return X_t, y_t


    def inverse_y(self, y_pred):
        if self.y_scaler:
            # numpy ë°°ì—´ë¡œ ë³€í™˜
            if isinstance(y_pred, (list, tuple)):
                y_pred = np.array(y_pred)
            return self.y_scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()
        return y_pred
    
    def convert_return_to_price(self, return_rate, current_price):
        """ìƒìŠ¹/í•˜ë½ìœ¨ì„ ì‹¤ì œ ê°€ê²©ìœ¼ë¡œ ë³€í™˜"""
        return current_price * (1 + return_rate)
    
    def evaluate(self, ticker: str = None):
        """ê²€ì¦ ë°ì´í„°ë¡œ ì„±ëŠ¥ í‰ê°€"""
        if ticker is None:
            ticker = self.ticker
            
        # ë°ì´í„° ë¡œë“œ
        X, y, feature_cols = load_dataset(ticker, agent_id=self.agent_id, save_dir=self.data_dir)
        
        # ì‹œê³„ì—´ ë¶„í•  (80% í›ˆë ¨, 20% ê²€ì¦)
        split_idx = int(len(X) * 0.8)
        X_val = X[split_idx:]
        y_val = y[split_idx:]
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        self.scaler.load(ticker)
        
        # ê²€ì¦ ë°ì´í„° ì˜ˆì¸¡
        predictions = []
        actual_returns = []
        
        for i in range(len(X_val)):
            X_input = X_val[i:i+1]
            X_tensor = torch.tensor(X_input, dtype=torch.float32)
            
            # ì˜ˆì¸¡
            with torch.no_grad():
                pred_return = self(X_tensor).item()
                predictions.append(pred_return)
                actual_returns.append(y_val[i, 0])
        
        predictions = np.array(predictions)
        actual_returns = np.array(actual_returns)
        
        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        mae = np.mean(np.abs(predictions - actual_returns))
        rmse = np.sqrt(np.mean((predictions - actual_returns) ** 2))
        correlation = np.corrcoef(predictions, actual_returns)[0, 1]
        
        # ë°©í–¥ ì •í™•ë„
        pred_direction = np.sign(predictions)
        actual_direction = np.sign(actual_returns)
        direction_accuracy = np.mean(pred_direction == actual_direction) * 100
        
        return {
            'mae': mae,
            'rmse': rmse,
            'correlation': correlation,
            'direction_accuracy': direction_accuracy,
            'n_samples': len(predictions)
        }

    def save(self, ticker):
        os.makedirs(self.save_dir, exist_ok=True)
        if self.x_scaler:
            joblib.dump(
                self.x_scaler,
                os.path.join(self.save_dir, f"{ticker}_{self.agent_id}_xscaler.pkl"),
            )
        if self.y_scaler:
            joblib.dump(
                self.y_scaler,
                os.path.join(self.save_dir, f"{ticker}_{self.agent_id}_yscaler.pkl"),
            )

    def load(self, ticker):
        x_path = os.path.join(self.save_dir, f"{ticker}_{self.agent_id}_xscaler.pkl")
        y_path = os.path.join(self.save_dir, f"{ticker}_{self.agent_id}_yscaler.pkl")
        if os.path.exists(x_path):
            self.x_scaler = joblib.load(x_path)
        if os.path.exists(y_path):
            self.y_scaler = joblib.load(y_path)
