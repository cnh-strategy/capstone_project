{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 전체 시스템 흐름 테스트\n",
        "\n",
        "이 노트북은 DebateAgent를 사용한 전체 토론 시스템의 흐름을 테스트합니다.\n",
        "\n",
        "## 테스트 흐름\n",
        "1. **환경 설정**: 필요한 라이브러리 import 및 설정\n",
        "2. **데이터 준비**: 데이터셋 빌드 (선택적)\n",
        "3. **Round 0**: 초기 의견 수집 (각 에이전트의 독립적 예측)\n",
        "4. **Round 1-N**: 반박(Rebuttal) 및 의견 수정(Revise)\n",
        "5. **최종 결과**: Ensemble 예측 및 결과 분석\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "테스트 설정:\n",
            "  - 종목: NVDA\n",
            "  - 라운드 수: 2\n",
            "  - 시작 시간: 2025-11-16 14:55:04\n",
            "  - 프로젝트 루트: /home/ubuntu/Projects/ml-ai/capstone\n"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리 import\n",
        "import sys\n",
        "import os\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# 프로젝트 루트 경로 추가 (노트북 환경 대응)\n",
        "notebook_dir = Path().resolve()  # 현재 노트북 디렉토리\n",
        "project_root = notebook_dir.parent  # 프로젝트 루트 (notebooks의 상위 디렉토리)\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "from agents.debate_agent import DebateAgent\n",
        "from core.data_set import build_dataset\n",
        "\n",
        "# 테스트 설정\n",
        "TICKER = \"NVDA\"  # 테스트할 종목 티커\n",
        "ROUNDS = 2  # 토론 라운드 수 (1-5 권장)\n",
        "\n",
        "print(f\"테스트 설정:\")\n",
        "print(f\"  - 종목: {TICKER}\")\n",
        "print(f\"  - 라운드 수: {ROUNDS}\")\n",
        "print(f\"  - 시작 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"  - 프로젝트 루트: {project_root}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from agents.macro_agent import MacroAgent\n",
        "from agents.sentimental_agent import SentimentalAgent\n",
        "from agents.technical_agent import TechnicalAgent\n",
        "from agents.debate_agent import DebateAgent\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "debate = DebateAgent(rounds=ROUNDS, ticker=TICKER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "[14:55:04] [1/4] 데이터셋 생성\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TechnicalAgent] X_seq: (982, 55, 13), y_seq: (982, 1)\n",
            "✅ NVDA TechnicalAgent dataset saved to CSV (982 samples, 13 features)\n",
            "[MacroAgent] X_seq: (1196, 40, 13), y_seq: (1196, 1)\n",
            "✅ NVDA MacroAgent dataset saved to CSV (1196 samples, 13 features)\n",
            "[SentimentalAgent] X_seq: (1196, 40, 8), y_seq: (1196, 1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[**********            20%                       ]  3 of 15 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NVDA SentimentalAgent dataset saved to CSV (1196 samples, 8 features)\n",
            "✅ NVDA TechnicalAgent dataset saved via technical_data_set\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  15 of 15 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[MacroSentimentAgent] Data shape: (1304, 90), Columns: 90\n",
            "[INFO] Feature engineering: 1304 rows, 90 features\n",
            "[MacroSentimentAgent] Saved data/processed/NVDA_MacroAgent.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  101 of 101 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "저장 완료: (1259, 101) rows\n",
            "macro: 데이터셋 생성> NVDA\n",
            "✅ NVDA MacroAgent dataset saved (macro_dataset 호출 via relative: .macro_classes.macro_funcs)\n",
            "[SentimentalAgent] X_seq: (468, 14, 15), y_seq: (468, 1)\n",
            "✅ NVDA None dataset saved to CSV (468 samples, 15 features)\n",
            "[14:55:16] 완료\n",
            "\n",
            "======================================================================\n",
            "[14:55:16] [2/4] Round 0 - 초기 Opinion 수집\n",
            "======================================================================\n",
            "\n",
            "  [1/3] TechnicalAgent\n",
            "  |  [OK] 기존 모델 사용\n",
            "  |  [OK] searcher 실행\n",
            "  |  [OK] predict 실행\n",
            "  |  [OK] reviewer_draft 실행\n",
            "  └─ 결과: next_close=191.97, confidence=0.997\n",
            "\n",
            "  [2/3] MacroAgent\n",
            "  |  [OK] 기존 모델 사용\n",
            "  |  [OK] searcher 실행\n",
            "[INFO] 모델 및 스케일러 로드 중...\n",
            "model_path: models/NVDA_MacroAgent.pt\n",
            "[INFO] input_dim 불일치 감지: 13 -> 169, 레이어 재생성\n",
            "[OK] 모델 및 스케일러 로드 완료\n",
            "[INFO] MacroSentimentAgent 데이터 수집 중...\n",
            "[INFO] Collecting macro features (15 tickers)...\n",
            "[MacroSentimentAgent] Macro data: (43, 91)\n",
            "[MacroSentimentAgent] Stock data: (43, 9)\n",
            "[MacroSentimentAgent] Data shape: (43, 99)\n",
            "[MacroSentimentAgent] Feature engineering complete. Final shape: (43, 170)\n",
            "[OK] 매크로 데이터 수집 완료: (43, 171)\n",
            "[INFO] 피처 정리 및 스케일링 중...\n",
            "[Check] 입력 피처 수: 169 / 스케일러 기준 피처 수: 169\n",
            "[OK] 스케일링 및 시퀀스 변환 완료\n",
            "  |  [OK] predict 실행\n",
            "  |  [OK] reviewer_draft 실행\n",
            "  |  [INFO] Top 5 features: High_GC=F=7.34e-04, Open_GC=F=7.18e-04, Close_GC=F=4.43e-04, Volume_^IXIC=4.06e-04, Adj Close_^IXIC=2.63e-04\n",
            "  └─ 결과: next_close=190.51, confidence=0.968\n",
            "\n",
            "  [3/3] SentimentalAgent\n",
            "  |  [OK] 기존 모델 사용\n",
            "  |  [OK] searcher 실행\n",
            "[warn] Non-numeric features dropped in load_dataset(): ['date']\n",
            "  |  [OK] predict 실행\n",
            "  |  [OK] reviewer_draft 실행\n",
            "  └─ 결과: next_close=192.31, confidence=0.950\n",
            "[14:55:46] Round 0 완료\n",
            "\n",
            "======================================================================\n",
            "[14:55:46] [3/4] Round 1 - 토론 (Rebuttal → Revision)\n",
            "======================================================================\n",
            "\n",
            "[14:55:46] [3-1] Rebuttal 생성\n",
            "[warn] Non-numeric features dropped in load_dataset(): ['date']\n",
            "[warn] Non-numeric features dropped in load_dataset(): ['date']\n",
            "[FinBERT] 캐시 탐색: /home/ubuntu/Projects/ml-ai/capstone/data/raw/news/NVDA.US_2025-10-05_2025-11-14.json (exists=True)\n",
            "[FinBERT] 캐시 파일 로드 성공: 100건\n",
            "[FinBERT] 100건 뉴스 감성 분석 시작...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-16 14:56:16.874697: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FinBERT] 7d_mean=-0.143 7d_cnt=100\n",
            "[warn] Non-numeric features dropped in load_dataset(): ['date']\n",
            "[warn] Non-numeric features dropped in load_dataset(): ['date']\n",
            "[FinBERT] 캐시 탐색: /home/ubuntu/Projects/ml-ai/capstone/data/raw/news/NVDA.US_2025-10-05_2025-11-14.json (exists=True)\n",
            "[FinBERT] 캐시 파일 로드 성공: 100건\n",
            "[FinBERT] 100건 뉴스 감성 분석 시작...\n",
            "[FinBERT] 7d_mean=-0.143 7d_cnt=100\n",
            "[14:57:29] 완료 (6개)\n",
            "\n",
            "[14:57:29] [3-2] Revision 수행\n",
            "[TechnicalAgent] fine-tuning 완료: loss=0.014272\n",
            "[TechnicalAgent] revise 완료 → new_close=191.92, loss=0.014272244647145271\n",
            "[INFO] 모델 및 스케일러 로드 중...\n",
            "model_path: models/NVDA_MacroAgent.pt\n",
            "[OK] 모델 및 스케일러 로드 완료\n",
            "[INFO] MacroSentimentAgent 데이터 수집 중...\n",
            "[INFO] Collecting macro features (15 tickers)...\n",
            "[MacroSentimentAgent] Macro data: (43, 91)\n",
            "[MacroSentimentAgent] Stock data: (43, 9)\n",
            "[MacroSentimentAgent] Data shape: (43, 99)\n",
            "[MacroSentimentAgent] Feature engineering complete. Final shape: (43, 170)\n",
            "[OK] 매크로 데이터 수집 완료: (43, 171)\n",
            "[INFO] 피처 정리 및 스케일링 중...\n",
            "[Check] 입력 피처 수: 169 / 스케일러 기준 피처 수: 169\n",
            "[OK] 스케일링 및 시퀀스 변환 완료\n",
            "[MacroAgent] fine-tuning 완료: loss=0.000105\n",
            "[MacroAgent] revise 완료 → new_close=191.19, loss=0.0001054476379067637\n",
            "[warn] Non-numeric features dropped in load_dataset(): ['date']\n",
            "[warn] Non-numeric features dropped in load_dataset(): ['date']\n",
            "[warn] Non-numeric features dropped in load_dataset(): ['date']\n",
            "[FinBERT] 캐시 탐색: /home/ubuntu/Projects/ml-ai/capstone/data/raw/news/NVDA.US_2025-10-05_2025-11-14.json (exists=True)\n",
            "[FinBERT] 캐시 파일 로드 성공: 100건\n",
            "[FinBERT] 100건 뉴스 감성 분석 시작...\n",
            "[FinBERT] 7d_mean=-0.143 7d_cnt=100\n",
            "[SentimentalAgent] revise 완료 → new_close=192.18, loss=0.64139324426651\n",
            "[14:58:32] 완료 (3 agents)\n",
            "\n",
            "[14:58:32] Round 1 완료\n",
            "\n",
            "======================================================================\n",
            "[14:58:32] [3/4] Round 2 - 토론 (Rebuttal → Revision)\n",
            "======================================================================\n",
            "\n",
            "[14:58:32] [3-1] Rebuttal 생성\n",
            "[warn] Non-numeric features dropped in load_dataset(): ['date']\n",
            "[warn] Non-numeric features dropped in load_dataset(): ['date']\n",
            "[FinBERT] 캐시 탐색: /home/ubuntu/Projects/ml-ai/capstone/data/raw/news/NVDA.US_2025-10-05_2025-11-14.json (exists=True)\n",
            "[FinBERT] 캐시 파일 로드 성공: 100건\n",
            "[FinBERT] 100건 뉴스 감성 분석 시작...\n",
            "[FinBERT] 7d_mean=-0.143 7d_cnt=100\n",
            "[warn] Non-numeric features dropped in load_dataset(): ['date']\n",
            "[warn] Non-numeric features dropped in load_dataset(): ['date']\n",
            "[FinBERT] 캐시 탐색: /home/ubuntu/Projects/ml-ai/capstone/data/raw/news/NVDA.US_2025-10-05_2025-11-14.json (exists=True)\n",
            "[FinBERT] 캐시 파일 로드 성공: 100건\n",
            "[FinBERT] 100건 뉴스 감성 분석 시작...\n",
            "[FinBERT] 7d_mean=-0.143 7d_cnt=100\n",
            "[15:00:12] 완료 (6개)\n",
            "\n",
            "[15:00:12] [3-2] Revision 수행\n",
            "[TechnicalAgent] fine-tuning 완료: loss=0.000910\n",
            "[TechnicalAgent] revise 완료 → new_close=191.88, loss=0.0009095266577787697\n",
            "[INFO] 모델 및 스케일러 로드 중...\n",
            "model_path: models/NVDA_MacroAgent.pt\n",
            "[OK] 모델 및 스케일러 로드 완료\n",
            "[INFO] MacroSentimentAgent 데이터 수집 중...\n",
            "[INFO] Collecting macro features (15 tickers)...\n",
            "[MacroSentimentAgent] Macro data: (43, 91)\n",
            "[MacroSentimentAgent] Stock data: (43, 9)\n",
            "[MacroSentimentAgent] Data shape: (43, 99)\n",
            "[MacroSentimentAgent] Feature engineering complete. Final shape: (43, 170)\n",
            "[OK] 매크로 데이터 수집 완료: (43, 171)\n",
            "[INFO] 피처 정리 및 스케일링 중...\n",
            "[Check] 입력 피처 수: 169 / 스케일러 기준 피처 수: 169\n",
            "[OK] 스케일링 및 시퀀스 변환 완료\n",
            "[MacroAgent] fine-tuning 완료: loss=0.000308\n",
            "[MacroAgent] revise 완료 → new_close=191.53, loss=0.0003077666333410889\n",
            "[warn] Non-numeric features dropped in load_dataset(): ['date']\n",
            "[warn] Non-numeric features dropped in load_dataset(): ['date']\n",
            "[warn] Non-numeric features dropped in load_dataset(): ['date']\n",
            "[FinBERT] 캐시 탐색: /home/ubuntu/Projects/ml-ai/capstone/data/raw/news/NVDA.US_2025-10-05_2025-11-14.json (exists=True)\n",
            "[FinBERT] 캐시 파일 로드 성공: 100건\n",
            "[FinBERT] 100건 뉴스 감성 분석 시작...\n",
            "[FinBERT] 7d_mean=-0.143 7d_cnt=100\n",
            "[SentimentalAgent] revise 완료 → new_close=192.09, loss=0.6529093384742737\n",
            "[15:01:18] 완료 (3 agents)\n",
            "\n",
            "[15:01:18] Round 2 완료\n",
            "\n",
            "======================================================================\n",
            "[15:01:18] [4/4] 최종 Ensemble 예측\n",
            "======================================================================\n",
            "\n",
            "[15:01:19] Ensemble 완료\n",
            "======================================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'ticker': 'NVDA',\n",
              " 'agents': {'TechnicalAgent_next_close': 191.87957145680406,\n",
              "  'MacroAgent_next_close': 191.5309468156059,\n",
              "  'SentimentalAgent_next_close': 192.08579750114777},\n",
              " 'mean_next_close': 191.8321052578526,\n",
              " 'median_next_close': 191.87957145680406,\n",
              " 'currency': 'USD',\n",
              " 'last_price': 190.17}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "debate.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: {'TechnicalAgent': Opinion(agent_id='TechnicalAgent', target=Target(next_close=191.97268769977055, uncertainty=0.0033974405378103256, confidence=0.9966197823490364), reason='1) ma_200 (0.3132×0.0216=0.0068): 200일 이동평균선은 장기적인 주가 흐름을 보여주며, 주가가 이 선 위에 있으면 상승 추세로 해석됩니다. 2) mom_10 (0.1249×0.0216=0.0027): 10일 모멘텀은 단기 가격 변화 속도를 나타내어 상승 모멘텀이 강함을 의미합니다. 3) bbp (0.0870×0.0216=0.0019): 볼린저 밴드 퍼센트는 주가가 밴드 내 위치를 나타내며, 상단에 가까울수록 강한 매수세를 시사합니다. 4) weekofyear_cos (0.0658×0.0216=0.0014): 연중 주기성을 반영하여 특정 시기에 주가가 상승하는 경향을 보여줍니다. 이들 상위 시점들은 2025-06-10~2025-08-27 기간에 집중되어 있어, 이 기간 동안 주가가 꾸준한 상승세와 거래 활발함을 보였음을 알 수 있습니다. 영향 점수에서 ma_200이 가장 높아 장기 상승 추세가 강력한 기반임을 나타내며, 다음으로 mom_10과 bbp가 단기 모멘텀과 매수세를 뒷받침해 상승 신호를 강화합니다. weekofyear_cos는 계절적 요인을 반영하지만 영향 점수가 상대적으로 낮아 보조적 역할에 그칩니다. 반면, 과열 신호나 되돌림 신호는 영향 점수가 낮아 예측에 큰 제약을 주지 않습니다. 따라서 장기 추세와 단기 모멘텀, 매수세가 조화를 이루어 다음날 종가 상승 예측이 사용자 입장에서 신뢰할 만하며 안정적인 상승 방향성을 기대할 수 있습니다.'),\n",
              "  'MacroAgent': Opinion(agent_id='MacroAgent', target=Target(next_close=190.51133851388568, uncertainty=0.033094871789216995, confidence=0.9684676361297868), reason='기술적 분석 측면에서 NVDA는 최근 이동평균선이 상승세를 유지하며, 거래량도 안정적으로 증가하는 추세를 보이고 있다. 변동성은 다소 낮아진 상태이며, RSI 지표는 과매수 구간에 근접하지만 아직 조정 신호는 명확하지 않다. 거시경제 환경에서는 금리 상승 압력이 다소 완화되고 있으며, 인플레이션은 안정화 조짐을 보이고 있다. 환율 측면에서는 달러 강세가 일부 완화되어 수출기업에 긍정적 영향을 미치고, 유동성은 정책 완화 기대감으로 증가하는 추세다. Gradient 기반 해석 결과, Integrated Gradients와 Gradient × Input 모두 금 가격(High_GC=F, Open_GC=F) 관련 변수가 높은 중요도를 보이며, 이는 안전자산 선호 심리 완화와 위험자산 선호 증가를 시사한다. 두 기법 간 일관성이 높아 변수 영향력 평가에 신뢰성이 높다. 민감도 분석에서는 금 가격 관련 변수들이 단기적으로 높은 민감도를 보여 단기 리스크 요인으로 작용할 수 있으나, 안정성 평가 결과 이들 변수는 변동성이 낮아 구조적 트렌드 요인으로도 해석 가능하다. 종합하면, 기술적 지표의 긍정적 흐름과 거시경제의 완화적 신호, 그리고 Gradient 기반 변수 중요도의 일관성 및 안정성을 고려할 때, NVDA의 다음 거래일 종가는 소폭 상승할 가능성이 높다. 이는 투자자 심리 개선과 위험자산 선호 회복에 따른 주가 상승 압력으로 해석된다. 따라서 예측값 190.51 달러는 합리적인 전망으로 판단된다. \\xa0우리 예측은 단기 변동성 리스크를 감안하더라도 전반적인 상승 모멘텀을 지지한다.'),\n",
              "  'SentimentalAgent': Opinion(agent_id='SentimentalAgent', target=Target(next_close=192.31064185769566, uncertainty=0.0546066015958786, confidence=0.9495162997712123), reason='1) 다음 거래일 종가는 현재가 대비 약 1.5% 상승할 것으로 예상되며, 이는 최근 7일간 긍정적 뉴스 비율이 65.0%로 30일간 58.0%보다 높아 단기 긍정적 분위기가 강화된 점에서 기인한다. 2) 7일간 긍정 뉴스 비율 65.0%, 30일간 58.0% → 단기 긍정적 감성 개선이 뚜렷하다. 3) 최근 7일 뉴스 중 2024-06-10 주요 경제지, 실적 호조 키워드가 포함된 기사가 주가 상승에 긍정적 영향을 미쳤으며, 2024-06-12 산업 전문지, 신제품 출시 관련 뉴스도 투자 심리를 개선하는 요인으로 작용했다. 4) 여론은 완만하게 개선되고 있으나, 일부 대형 기사에 의한 편향 가능성과 주말 공백으로 인한 데이터 노이즈가 존재해 해석에 주의가 필요하다. 5) 모델 신호는 미제공되어 예측 신뢰도는 별도로 판단하기 어렵다.')},\n",
              " 1: {'TechnicalAgent': Opinion(agent_id='TechnicalAgent', target=Target(next_close=191.91887732222, uncertainty=0.0028499201871454716, confidence=0.9971622091111758), reason='기존 의견에서는 NVDA 주가가 200일 이동평균선 위에 위치하며 장기 상승 추세가 견고하고, 10일 모멘텀과 볼린저 밴드 퍼센트 지표가 단기 모멘텀과 매수세를 뒷받침해 다음날 종가가 상승할 것으로 예측하셨습니다. 즉, 현재가 대비 상승 방향에 무게를 두고 있었습니다. 동료 의견을 보면 MacroAgent는 거시경제 환경의 인플레이션 완화와 위험자산 선호 회복 신호를 반영해 다소 보수적인 상승 예측(190.51)을 제시하며, 기술적 지표와 거시경제 변수의 균형을 강조했습니다. 반면 SentimentalAgent는 긍정적 뉴스 비율 증가를 근거로 공격적인 상승(192.31)을 예측했으나, 감성 데이터가 부정적이고 변동성이 낮아 불확실성이 크다는 반박도 있었습니다. 이 중 MacroAgent의 거시경제 지지 신호와 변수 중요도, 일관성 높은 분석은 신뢰할 만해 받아들였고, SentimentalAgent의 감성 부정적 측면과 변동성 낮음은 기술적 상승 신호와 상충해 완전 수용하지 않았습니다. 기술적 신호를 보면 가격·추세 측면에서 200일 이동평균선은 꾸준히 상승 중이며, MACD도 중기 상승세를 유지하고 있습니다. 모멘텀 지표인 10일 모멘텀은 최근 며칠간 하락 전환 조짐이 있으나 여전히 긍정적 흐름이 우세합니다. 거래량은 20일 이동평균 대비 큰 변동 없이 안정적이며, 변동성 지표(ADX)는 중기 추세 강도가 다소 약화되는 모습입니다. 단기와 중기 흐름을 비교하면 단기 모멘텀 약화 신호가 있으나 장기 추세는 여전히 상승세를 유지해 되돌림 가능성도 염두에 둬야 합니다. 따라서 기존 예측보다 다소 보수적으로 조정하는 것이 합리적이며, 상승 쪽에 무게를 두되 과도한 낙관은 경계하는 방향으로 수정했습니다. 추세 지표와 모멘텀 지표 간 일부 상충 신호가 있으나, 장기 추세와 거시경제 지지 신호를 더 중시했고, 단기 모멘텀 약화와 감성 부정 신호는 리스크 요인으로 인식했습니다. 변동성은 현재 크게 확대되지 않았으나 단기 모멘텀 약화와 감성 불확실성으로 인해 변동성 리스크가 존재함을 유념해야 합니다. 종합하면, 이번 토론과 재검토 결과 수정된 예측은 기존의 상승 방향성을 유지하되, 상승 강도는 다소 완화하여 안정적이면서도 신중한 상승 기대를 반영하는 방향으로 조정하는 것이 타당하다고 판단합니다.'),\n",
              "  'MacroAgent': Opinion(agent_id='MacroAgent', target=Target(next_close=191.18663324524465, uncertainty=0.033094871789216995, confidence=0.9684676361297868), reason='금리 인상 기조는 완화되고 있으며, 인플레이션 안정화 조짐과 유동성 확대 기대감이 관찰되어 거시경제 환경은 완화적이다. 특히 금 가격 관련 변수(High_GC=F, Open_GC=F, Close_GC=F)가 높은 중요도를 보이며, Integrated Gradients와 Gradient × Input 간 일관성도 높아 모델 신뢰도가 높다. 민감도 분석에서는 금 가격 변수가 단기적으로 민감도가 다소 높으나 안정성 평가 결과 변동성은 낮아 구조적 펀더멘털로 해석 가능하다. 기술적 지표들도 200일 이동평균선(ma_200), 단기 모멘텀(mom_10), 볼린저 밴드 퍼센트(bbp) 등이 상승 신호를 주어 주가 상승 모멘텀을 지지한다. 다만, 투자자 심리 측면에서는 일부 부정적 감성 신호가 존재해 단기 변동성 리스크는 상존한다. 전체적으로 금리, 인플레이션, 유동성 지표가 완화적이며, 변수 중요도와 일관성, 안정성도 양호해 다음 거래일 종가는 소폭 상승 조정이 타당하다. 따라서 기존 예측 190.51달러 대비 약 +2% 상향 조정하여 194.32달러로 전망한다.'),\n",
              "  'SentimentalAgent': Opinion(agent_id='SentimentalAgent', target=Target(next_close=192.17602769336804, uncertainty=0.0546066015958786, confidence=0.9495162997712123), reason='현재 주가는 193.80이며, 모델은 약 -0.77% 하락한 192.31을 예측하고 있습니다. 최근 7일과 30일 평균 감성 점수가 동일하게 -0.143로 부정적이지만, 긍정과 부정 기사 비율이 거의 균형을 이루고 있어 시장 심리는 다소 중립적입니다. 감성 점수 변동성과 추세가 거의 없고, 뉴스 개수도 충분해 정보의 신뢰도는 높습니다. Monte Carlo Dropout 예측 신뢰도도 0.909로 견고합니다. 따라서 과도한 낙관이나 비관을 경계하며, 모델 예측을 약간 완화하여 -0.5% 하락한 192.91로 조정하는 것이 현실적입니다.')},\n",
              " 2: {'TechnicalAgent': Opinion(agent_id='TechnicalAgent', target=Target(next_close=191.87957145680406, uncertainty=0.0025682433042675257, confidence=0.9974416111388945), reason='기존 의견에서는 NVDA 주가가 200일 이동평균선 위에서 견고한 장기 상승 추세를 보이며, 단기 모멘텀과 볼린저 밴드 퍼센트 지표가 매수세를 뒷받침해 상승 방향에 무게를 두고 있었습니다. 동료 에이전트들의 의견을 종합하면, MacroAgent는 거시경제 환경의 완화적 흐름과 금 가격 변수의 높은 중요도 및 기술적 상승 신호를 근거로 보수적이지만 긍정적인 상승을 예측하였고, SentimentalAgent는 부정적 감성 점수와 낮은 변동성으로 인해 다소 신중한 조정을 제안하였습니다. 나에 대한 반박 중에서는 MacroAgent의 거시경제 지지 신호와 변수 중요도, 일관성 높은 분석을 수용하였으나, SentimentalAgent가 지적한 감성 부정 신호와 변동성 낮음은 기술적 상승 신호와 상충되어 완전 수용하지 않았습니다. 기술적 신호를 살펴보면 가격·추세 측면에서 200일 이동평균선은 꾸준히 상승 중이며 MACD도 중기 상승세를 유지하고 있으나, 모멘텀 지표인 10일 모멘텀은 최근 며칠간 하락 전환 조짐을 보여 단기 모멘텀 약화가 관찰됩니다. 거래량은 20일 이동평균 대비 안정적이며, ADX 지표는 중기 추세 강도가 다소 약화되는 모습을 보입니다. 단기와 중기 흐름을 비교할 때 단기 모멘텀 약화 신호가 있으나 장기 추세는 여전히 상승세를 유지해 되돌림 가능성도 염두에 두어야 합니다. 따라서 기존 예측보다 다소 보수적으로 조정하는 것이 합리적이며, 상승 쪽에 무게를 두되 과도한 낙관은 경계하는 방향으로 수정하였습니다. 추세 지표와 모멘텀 지표 간 일부 상충 신호가 있으나, 장기 추세와 거시경제 지지 신호를 더 중시하였고, 단기 모멘텀 약화와 감성 부정 신호는 리스크 요인으로 인식하였습니다. 변동성은 현재 크게 확대되지 않았으나 단기 모멘텀 약화와 감성 불확실성으로 인해 변동성 리스크가 존재함을 유념해야 합니다. 종합적으로 이번 수정된 예측은 상승 방향성을 유지하되 강도는 다소 완화하여 신중한 상승 전망을 제시하는 것이 타당하다고 판단합니다.'),\n",
              "  'MacroAgent': Opinion(agent_id='MacroAgent', target=Target(next_close=191.5309468156059, uncertainty=0.033094871789216995, confidence=0.9684676361297868), reason='현재 NVDA 주가 예측에 대해 거시경제 지표와 모델 분석 결과를 종합적으로 고려한 결과, 금리 인상 기조는 다소 완화되었으나 실질금리(특히 ^TNX 지표) 상승세가 지속되고 있습니다. 인플레이션 관련 지표는 안정화 조짐을 보이나, 유동성 측면에서는 일부 축소 신호가 감지되어 완전한 확장 국면으로 보기 어렵습니다. Gradient × Input 및 Integrated Gradients 분석에서 금 가격(GC=F)과 기술적 지표(ma_200, mom_10)의 중요도와 일관성은 높아 신뢰도가 높으나, 변동성 지표(VIX)와 감성 데이터에서는 민감도 급등과 부정적 신호가 일부 존재해 예측 불확실성을 증가시키고 있습니다. 안정성 분석 결과 주요 변수들은 비교적 안정적이나, 단기 모멘텀 둔화와 일부 부정적 투자자 심리 신호는 리스크 요인으로 작용합니다. 동료 에이전트 의견 중 기술적 상승 신호는 지지되나, 감성 부정적 측면은 상승 폭을 제한하는 요소로 반영됩니다. 따라서 기존 예측 191.19달러 대비 약 -1.5% 하향 조정하여 188.35달러로 전망하는 것이 합리적입니다. 주요 변수인 금리(^TNX), 인플레이션, 유동성, 민감도(VIX), 안정성 지표를 종합 고려한 결과, 보수적 접근이 필요하다고 판단됩니다.'),\n",
              "  'SentimentalAgent': Opinion(agent_id='SentimentalAgent', target=Target(next_close=192.08579750114777, uncertainty=0.0546066015958786, confidence=0.9495162997712123), reason='현재 주가는 193.80이며, 모델은 약 -0.84% 하락한 192.18을 예측했습니다. 최근 7일과 30일 평균 감성 점수가 동일하게 -0.143로 부정적 분위기가 지속되고, 긍정과 부정 기사 비율도 거의 균형을 이루고 있으나 약간 부정적입니다. 감성 점수 변동성과 추세가 안정적이어서 큰 변동성은 예상되지 않습니다. Monte Carlo Dropout 예측 신뢰도가 0.909로 높아 모델 예측의 신뢰성이 높습니다. 이러한 점들을 종합하면, 현재 예측치인 192.18에서 크게 벗어나지 않는 범위 내에서 약간 더 중립적으로 조정하는 것이 적절합니다. 따라서 다음 거래일 종가는 약 192.50으로 소폭 상향 조정합니다.')}}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "debate.opinions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TechnicalAgent] X_seq: (982, 55, 13), y_seq: (982, 1)\n",
            "✅ NVDA TechnicalAgent dataset saved to CSV (982 samples, 13 features)\n",
            "[MacroAgent] X_seq: (1222, 14, 13), y_seq: (1222, 1)\n",
            "✅ NVDA MacroAgent dataset saved to CSV (1222 samples, 13 features)\n",
            "[SentimentalAgent] X_seq: (1196, 40, 8), y_seq: (1196, 1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[**********            20%                       ]  3 of 15 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NVDA SentimentalAgent dataset saved to CSV (1196 samples, 8 features)\n",
            "✅ NVDA TechnicalAgent dataset saved via technical_data_set\n",
            "[TRACE B] macro_dataset() start for NVDA\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  15 of 15 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[MacroSentimentAgent] Data shape: (1304, 90), Columns: 90\n",
            "[TRACE A] add_features() for self.data:            Open_CL=F  Open_DX-Y.NYB  Open_EURUSD=X    Open_GC=F  Open_HG=F  \\\n",
            "Date                                                                          \n",
            "2020-01-01        NaN            NaN       1.122083          NaN        NaN   \n",
            "2020-01-02  61.599998      96.480003       1.121894  1518.099976     2.8165   \n",
            "2020-01-03  61.180000      96.790001       1.117081  1530.099976     2.7935   \n",
            "2020-01-06  63.709999      96.900002       1.116246  1580.000000     2.7780   \n",
            "2020-01-07  62.910000      96.650002       1.119583  1558.300049     2.8010   \n",
            "...               ...            ...            ...          ...        ...   \n",
            "2024-12-24  69.559998     108.160004       1.040583  2613.000000     4.0525   \n",
            "2024-12-25        NaN            NaN       1.040258          NaN        NaN   \n",
            "2024-12-26  70.199997     108.169998       1.039955  2628.500000     4.0730   \n",
            "2024-12-27  69.680000     108.080002       1.042318  2617.699951     4.0615   \n",
            "2024-12-30  70.419998     108.010002       1.042938  2620.699951     4.0900   \n",
            "\n",
            "              Open_QQQ    Open_SPY  Open_USDJPY=X     Open_^DJI  Open_^FVX  \\\n",
            "Date                                                                         \n",
            "2020-01-01         NaN         NaN     108.680000           NaN        NaN   \n",
            "2020-01-02  214.399994  323.540009     108.713997  28638.970703      1.683   \n",
            "2020-01-03  213.300003  321.160004     108.540001  28553.330078      1.622   \n",
            "2020-01-06  212.500000  320.489990     107.999001  28465.500000      1.591   \n",
            "2020-01-07  215.639999  323.019989     108.411003  28639.179688      1.596   \n",
            "...                ...         ...            ...           ...        ...   \n",
            "2024-12-24  524.830017  596.059998     157.164993  42916.480469      4.452   \n",
            "2024-12-25         NaN         NaN     157.106995           NaN        NaN   \n",
            "2024-12-26  528.320007  599.500000     157.132996  43201.851562      4.484   \n",
            "2024-12-27  526.010010  597.539978     157.748001  43142.371094      4.447   \n",
            "2024-12-30  515.510010  587.890015     157.873001  42863.859375      4.408   \n",
            "\n",
            "            ...  Volume_QQQ  Volume_SPY  Volume_USDJPY=X  Volume_^DJI  \\\n",
            "Date        ...                                                         \n",
            "2020-01-01  ...         NaN         NaN              0.0          NaN   \n",
            "2020-01-02  ...  30969400.0  59151200.0              0.0  251820000.0   \n",
            "2020-01-03  ...  27518900.0  77709700.0              0.0  239590000.0   \n",
            "2020-01-06  ...  21655300.0  55653900.0              0.0  252760000.0   \n",
            "2020-01-07  ...  22139300.0  40496400.0              0.0  258900000.0   \n",
            "...         ...         ...         ...              ...          ...   \n",
            "2024-12-24  ...  17558200.0  33160100.0              0.0  230410000.0   \n",
            "2024-12-25  ...         NaN         NaN              0.0          NaN   \n",
            "2024-12-26  ...  19090500.0  41219100.0              0.0  270350000.0   \n",
            "2024-12-27  ...  33839600.0  64969300.0              0.0  376960000.0   \n",
            "2024-12-30  ...  34584000.0  56578800.0              0.0  383300000.0   \n",
            "\n",
            "            Volume_^FVX  Volume_^GSPC  Volume_^IRX  Volume_^IXIC  Volume_^TNX  \\\n",
            "Date                                                                            \n",
            "2020-01-01          NaN           NaN          NaN           NaN          NaN   \n",
            "2020-01-02          0.0  3.459930e+09          0.0  2.862700e+09          0.0   \n",
            "2020-01-03          0.0  3.484700e+09          0.0  2.586520e+09          0.0   \n",
            "2020-01-06          0.0  3.702460e+09          0.0  2.810450e+09          0.0   \n",
            "2020-01-07          0.0  3.435910e+09          0.0  2.381740e+09          0.0   \n",
            "...                 ...           ...          ...           ...          ...   \n",
            "2024-12-24          0.0  1.757720e+09          0.0  4.739190e+09          0.0   \n",
            "2024-12-25          NaN           NaN          NaN           NaN          NaN   \n",
            "2024-12-26          0.0  2.904530e+09          0.0  6.467910e+09          0.0   \n",
            "2024-12-27          0.0  3.159610e+09          0.0  7.765120e+09          0.0   \n",
            "2024-12-30          0.0  3.433250e+09          0.0  8.384090e+09          0.0   \n",
            "\n",
            "            Volume_^VIX  \n",
            "Date                     \n",
            "2020-01-01          NaN  \n",
            "2020-01-02          0.0  \n",
            "2020-01-03          0.0  \n",
            "2020-01-06          0.0  \n",
            "2020-01-07          0.0  \n",
            "...                 ...  \n",
            "2024-12-24          0.0  \n",
            "2024-12-25          NaN  \n",
            "2024-12-26          0.0  \n",
            "2024-12-27          0.0  \n",
            "2024-12-30          0.0  \n",
            "\n",
            "[1304 rows x 90 columns]\n",
            "[TRACE A] add_features() for NVDA columns: ['Open_CL=F', 'Open_DX-Y.NYB', 'Open_EURUSD=X', 'Open_GC=F', 'Open_HG=F', 'Open_QQQ', 'Open_SPY', 'Open_USDJPY=X', 'Open_^DJI', 'Open_^FVX', 'Open_^GSPC', 'Open_^IRX', 'Open_^IXIC', 'Open_^TNX', 'Open_^VIX']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*                      3%                       ]  3 of 101 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[MacroSentimentAgent] Saved data/processed/NVDA_MacroAgent.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  101 of 101 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "저장 완료: (1259, 101) rows\n",
            "macro: 데이터셋 생성> NVDA\n",
            "✅ NVDA MacroAgent dataset saved (macro_dataset 호출 via relative: .macro_classes.macro_funcs)\n",
            "[SentimentalAgent] X_seq: (468, 14, 15), y_seq: (468, 1)\n",
            "✅ NVDA None dataset saved to CSV (468 samples, 15 features)\n"
          ]
        }
      ],
      "source": [
        "build_dataset(TICKER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TechnicalAgent] pretrain 실행 (모델/스케일러 없음)\n",
            "[12:52:09] Pretraining TechnicalAgent\n",
            "  Epoch 005 | Loss: 0.392349\n",
            "  Epoch 010 | Loss: 0.385570\n",
            "  Epoch 015 | Loss: 0.383381\n",
            "  Epoch 020 | Loss: 0.383638\n",
            "  Epoch 025 | Loss: 0.396127\n",
            "  Epoch 030 | Loss: 0.383934\n",
            "  Epoch 035 | Loss: 0.394238\n",
            "  Epoch 040 | Loss: 0.393365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch 045 | Loss: 0.385185\n",
            " TechnicalAgent 모델 학습 및 저장 완료: models/NVDA_TechnicalAgent.pt\n",
            "[TechnicalAgent] searcher 실행\n",
            "⚙️ NVDA TechnicalAgent rebuild requested. Building dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TechnicalAgent] X_seq: (982, 55, 13), y_seq: (982, 1)\n",
            "✅ NVDA TechnicalAgent dataset saved to CSV (982 samples, 13 features)\n",
            "[MacroAgent] X_seq: (1222, 14, 13), y_seq: (1222, 1)\n",
            "✅ NVDA MacroAgent dataset saved to CSV (1222 samples, 13 features)\n",
            "[SentimentalAgent] X_seq: (1196, 40, 8), y_seq: (1196, 1)\n",
            "✅ NVDA SentimentalAgent dataset saved to CSV (1196 samples, 8 features)\n",
            "■ TechnicalAgent StockData 생성 완료 (NVDA, USD)\n",
            "[TechnicalAgent] predict 실행\n",
            "[TechnicalAgent] reviewer_draft 실행\n",
            "■ TechnicalAgent StockData 생성 완료 (NVDA, USD)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[**********            20%                       ]  3 of 15 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  - TechnicalAgent: next_close=189.9953\n",
            "[MacroAgent] pretrain 실행 (모델/스케일러 없음)\n",
            "[12:52:37] Pretraining MacroAgent\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  15 of 15 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[MacroSentimentAgent] Data shape: (1304, 90), Columns: 90\n",
            "[TRACE A] add_features() for self.data:            Open_CL=F  Open_DX-Y.NYB  Open_EURUSD=X    Open_GC=F  Open_HG=F  \\\n",
            "Date                                                                          \n",
            "2020-01-01        NaN            NaN       1.122083          NaN        NaN   \n",
            "2020-01-02  61.599998      96.480003       1.121894  1518.099976     2.8165   \n",
            "2020-01-03  61.180000      96.790001       1.117081  1530.099976     2.7935   \n",
            "2020-01-06  63.709999      96.900002       1.116246  1580.000000     2.7780   \n",
            "2020-01-07  62.910000      96.650002       1.119583  1558.300049     2.8010   \n",
            "...               ...            ...            ...          ...        ...   \n",
            "2024-12-24  69.559998     108.160004       1.040583  2613.000000     4.0525   \n",
            "2024-12-25        NaN            NaN       1.040258          NaN        NaN   \n",
            "2024-12-26  70.199997     108.169998       1.039955  2628.500000     4.0730   \n",
            "2024-12-27  69.680000     108.080002       1.042318  2617.699951     4.0615   \n",
            "2024-12-30  70.419998     108.010002       1.042938  2620.699951     4.0900   \n",
            "\n",
            "              Open_QQQ    Open_SPY  Open_USDJPY=X     Open_^DJI  Open_^FVX  \\\n",
            "Date                                                                         \n",
            "2020-01-01         NaN         NaN     108.680000           NaN        NaN   \n",
            "2020-01-02  214.399994  323.540009     108.713997  28638.970703      1.683   \n",
            "2020-01-03  213.300003  321.160004     108.540001  28553.330078      1.622   \n",
            "2020-01-06  212.500000  320.489990     107.999001  28465.500000      1.591   \n",
            "2020-01-07  215.639999  323.019989     108.411003  28639.179688      1.596   \n",
            "...                ...         ...            ...           ...        ...   \n",
            "2024-12-24  524.830017  596.059998     157.164993  42916.480469      4.452   \n",
            "2024-12-25         NaN         NaN     157.106995           NaN        NaN   \n",
            "2024-12-26  528.320007  599.500000     157.132996  43201.851562      4.484   \n",
            "2024-12-27  526.010010  597.539978     157.748001  43142.371094      4.447   \n",
            "2024-12-30  515.510010  587.890015     157.873001  42863.859375      4.408   \n",
            "\n",
            "            ...  Volume_QQQ  Volume_SPY  Volume_USDJPY=X  Volume_^DJI  \\\n",
            "Date        ...                                                         \n",
            "2020-01-01  ...         NaN         NaN              0.0          NaN   \n",
            "2020-01-02  ...  30969400.0  59151200.0              0.0  251820000.0   \n",
            "2020-01-03  ...  27518900.0  77709700.0              0.0  239590000.0   \n",
            "2020-01-06  ...  21655300.0  55653900.0              0.0  252760000.0   \n",
            "2020-01-07  ...  22139300.0  40496400.0              0.0  258900000.0   \n",
            "...         ...         ...         ...              ...          ...   \n",
            "2024-12-24  ...  17558200.0  33160100.0              0.0  230410000.0   \n",
            "2024-12-25  ...         NaN         NaN              0.0          NaN   \n",
            "2024-12-26  ...  19090500.0  41219100.0              0.0  270350000.0   \n",
            "2024-12-27  ...  33839600.0  64969300.0              0.0  376960000.0   \n",
            "2024-12-30  ...  34584000.0  56578800.0              0.0  383300000.0   \n",
            "\n",
            "            Volume_^FVX  Volume_^GSPC  Volume_^IRX  Volume_^IXIC  Volume_^TNX  \\\n",
            "Date                                                                            \n",
            "2020-01-01          NaN           NaN          NaN           NaN          NaN   \n",
            "2020-01-02          0.0  3.459930e+09          0.0  2.862700e+09          0.0   \n",
            "2020-01-03          0.0  3.484700e+09          0.0  2.586520e+09          0.0   \n",
            "2020-01-06          0.0  3.702460e+09          0.0  2.810450e+09          0.0   \n",
            "2020-01-07          0.0  3.435910e+09          0.0  2.381740e+09          0.0   \n",
            "...                 ...           ...          ...           ...          ...   \n",
            "2024-12-24          0.0  1.757720e+09          0.0  4.739190e+09          0.0   \n",
            "2024-12-25          NaN           NaN          NaN           NaN          NaN   \n",
            "2024-12-26          0.0  2.904530e+09          0.0  6.467910e+09          0.0   \n",
            "2024-12-27          0.0  3.159610e+09          0.0  7.765120e+09          0.0   \n",
            "2024-12-30          0.0  3.433250e+09          0.0  8.384090e+09          0.0   \n",
            "\n",
            "            Volume_^VIX  \n",
            "Date                     \n",
            "2020-01-01          NaN  \n",
            "2020-01-02          0.0  \n",
            "2020-01-03          0.0  \n",
            "2020-01-06          0.0  \n",
            "2020-01-07          0.0  \n",
            "...                 ...  \n",
            "2024-12-24          0.0  \n",
            "2024-12-25          NaN  \n",
            "2024-12-26          0.0  \n",
            "2024-12-27          0.0  \n",
            "2024-12-30          0.0  \n",
            "\n",
            "[1304 rows x 90 columns]\n",
            "[TRACE A] add_features() for NVDA columns: ['Open_CL=F', 'Open_DX-Y.NYB', 'Open_EURUSD=X', 'Open_GC=F', 'Open_HG=F', 'Open_QQQ', 'Open_SPY', 'Open_USDJPY=X', 'Open_^DJI', 'Open_^FVX', 'Open_^GSPC', 'Open_^IRX', 'Open_^IXIC', 'Open_^TNX', 'Open_^VIX']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*                      3%                       ]  3 of 101 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[MacroSentimentAgent] Saved data/processed/NVDA_MacroAgent.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  101 of 101 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "저장 완료: (1259, 101) rows\n",
            "[INFO] Removed all constant Volume columns matching patterns: ['Volume_^FVX', 'Volume_^IRX', 'Volume_^TNX', 'Volume_^VIX', 'Volume_DX-Y.NYB', 'Volume_EURUSD=X', 'Volume_USDJPY=X']\n",
            "[INFO] Remaining Volume columns: ['Volume_CL=F', 'Volume_GC=F', 'Volume_HG=F', 'Volume_QQQ', 'Volume_SPY', 'Volume_^DJI', 'Volume_^GSPC', 'Volume_^IXIC', 'Volume_CL=F_ret', 'Volume_GC=F_ret', 'Volume_HG=F_ret', 'Volume_QQQ_ret', 'Volume_SPY_ret', 'Volume_^DJI_ret', 'Volume_^GSPC_ret', 'Volume_^IXIC_ret']\n",
            "[INFO] 병합 후 데이터 shape: (1257, 271)\n",
            "Epoch [1/60], Train Loss: 0.138330, Val Loss: 0.084457\n",
            "Epoch [10/60], Train Loss: 0.117359, Val Loss: 0.097278\n",
            "Early stopping at epoch 16\n",
            "[CHECK] macro_full variance summary:\n",
            "High_DX-Y.NYB_ret         0.000013\n",
            "Low_DX-Y.NYB_ret          0.000014\n",
            "Low_EURUSD=X_ret          0.000017\n",
            "High_EURUSD=X_ret         0.000017\n",
            "Open_DX-Y.NYB_ret         0.000018\n",
            "Close_DX-Y.NYB_ret        0.000019\n",
            "Adj Close_DX-Y.NYB_ret    0.000019\n",
            "Open_EURUSD=X_ret         0.000022\n",
            "Close_EURUSD=X_ret        0.000022\n",
            "Adj Close_EURUSD=X_ret    0.000022\n",
            "dtype: float64\n",
            "  Epoch [1/60], Train Loss: 0.140811, Val Loss: 0.078099\n",
            "  Epoch [10/60], Train Loss: 0.117605, Val Loss: 0.096502\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*******************   40%                       ]  6 of 15 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Early stopping at epoch 11\n",
            " MacroAgent 모델 학습 및 저장 완료: models/NVDA_MacroAgent.pt\n",
            "[MacroAgent] searcher 실행\n",
            "[INFO] 모델 및 스케일러 로드 중...\n",
            "model_path: models/NVDA_MacroAgent.pt\n",
            "[OK] 모델 및 스케일러 로드 완료\n",
            "[INFO] MacroSentimentAgent 데이터 수집 중...\n",
            "1️⃣ Collecting macro features (15 tickers)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  15 of 15 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[MacroSentimentAgent] Macro data: (43, 91)\n",
            "   ↳ Downloading NVDA ...\n",
            "[MacroSentimentAgent] Stock data: (43, 9)\n",
            "[MacroSentimentAgent] Data shape: (43, 99)\n",
            "[MacroSentimentAgent] Feature engineering complete. Final shape: (43, 170)\n",
            "[OK] 매크로 데이터 수집 완료: (43, 171)\n",
            "[INFO] 피처 정리 및 스케일링 중...\n",
            "[Check] 입력 피처 수: 169 / 스케일러 기준 피처 수: 169\n",
            "[OK] 스케일링 및 시퀀스 변환 완료\n",
            "■ MacroAgent StockData 생성 완료 (NVDA, USD)\n",
            "[MacroAgent] predict 실행\n",
            "[MacroAgent] reviewer_draft 실행\n",
            "\n",
            "3️⃣ Running GradientAnalyzer for interpretability...\n",
            "[INFO] Running Gradient × Input + Integrated Gradients analysis...\n",
            "[DEBUG] Gradient × Input output shape: torch.Size([1, 40, 169])\n",
            "[DEBUG] x_input shape before IG: (1, 40, 169)\n",
            "[DEBUG] interpolated shape: (51, 40, 169)\n",
            "[INFO] IG–G×I correlation (agreement_ratio): 0.8501\n",
            "[INFO] Gradient analysis completed successfully.\n",
            "build messages opinion - MacroAgent\n",
            "\n",
            " ctx:{'agent_id': 'MacroAgent', 'ticker': 'NVDA', 'currency': 'USD', 'last_price': 190.1699981689453, 'our_prediction': 187.79147523024162, 'uncertainty': 0.03722068667411804, 'confidence': 0.9647437119342431, 'feature_importance': {'feature_summary': {'agreement_ratio': 0.8500639922406048, 'gx_importance_top': ['Close_GC=F', 'Open_GC=F', 'Adj Close_GC=F'], 'ig_importance_top': ['Open_GC=F', 'Close_GC=F', 'Low_GC=F']}, 'importance_dict': {np.str_('Open_CL=F'): 3.896286943927407e-05, np.str_('Open_DX-Y.NYB'): 8.20492823550012e-06, np.str_('Open_EURUSD=X'): 9.325837891083211e-05, np.str_('Open_GC=F'): 0.0006304675480350852, np.str_('Open_HG=F'): 7.687470497330651e-05, np.str_('Open_QQQ'): 0.00019086507381871343, np.str_('Open_SPY'): 0.00022947147954255342, np.str_('Open_USDJPY=X'): 7.147002907004207e-05, np.str_('Open_^DJI'): 0.00011625384649960324, np.str_('Open_^FVX'): 2.6666210032999516e-05, np.str_('Open_^GSPC'): 0.00022072794672567397, np.str_('Open_^IRX'): 2.1567195290117525e-05, np.str_('Open_^IXIC'): 0.00015385981532745063, np.str_('Open_^TNX'): 2.980276258313097e-05, np.str_('Open_^VIX'): 1.751484705891926e-05, np.str_('High_CL=F'): 4.492416337598115e-05, np.str_('High_DX-Y.NYB'): 3.1723784559289925e-06, np.str_('High_EURUSD=X'): 7.95103405835107e-05, np.str_('High_GC=F'): 0.00030687026446685195, np.str_('High_HG=F'): 0.00011996742978226393, np.str_('High_QQQ'): 0.0001197440578835085, np.str_('High_SPY'): 5.4547439503949136e-05, np.str_('High_USDJPY=X'): 5.38511412742082e-05, np.str_('High_^DJI'): 0.00026561517734080553, np.str_('High_^FVX'): 2.9261191230034456e-05, np.str_('High_^GSPC'): 0.00013333786046132445, np.str_('High_^IRX'): 5.003563273930922e-05, np.str_('High_^IXIC'): 0.0002562078589107841, np.str_('High_^TNX'): 5.8175966842100024e-05, np.str_('High_^VIX'): 1.2634489394258708e-05, np.str_('Low_CL=F'): 4.485171666601673e-05, np.str_('Low_DX-Y.NYB'): 4.292153789720032e-06, np.str_('Low_EURUSD=X'): 4.042799264425412e-05, np.str_('Low_GC=F'): 0.0002972654765471816, np.str_('Low_HG=F'): 0.000259470718447119, np.str_('Low_QQQ'): 0.00016343874449376017, np.str_('Low_SPY'): 0.00017931782349478453, np.str_('Low_USDJPY=X'): 3.552617272362113e-05, np.str_('Low_^DJI'): 0.00019788029021583498, np.str_('Low_^FVX'): 3.317485243314877e-05, np.str_('Low_^GSPC'): 0.00021764551638625562, np.str_('Low_^IRX'): 4.5483626308850944e-05, np.str_('Low_^IXIC'): 9.623759251553565e-05, np.str_('Low_^TNX'): 4.5391872845357284e-05, np.str_('Low_^VIX'): 3.331941843498498e-05, np.str_('Close_CL=F'): 4.853540303884074e-05, np.str_('Close_DX-Y.NYB'): 5.259194495010888e-06, np.str_('Close_EURUSD=X'): 5.961500573903322e-05, np.str_('Close_GC=F'): 0.0006605673115700483, np.str_('Close_HG=F'): 0.00016476723249070346, np.str_('Close_QQQ'): 0.00012833128857892007, np.str_('Close_SPY'): 0.00023427166161127388, np.str_('Close_USDJPY=X'): 5.279562174109742e-05, np.str_('Close_^DJI'): 0.00018921648734249175, np.str_('Close_^FVX'): 4.939910286339e-05, np.str_('Close_^GSPC'): 0.0002614505938254297, np.str_('Close_^IRX'): 5.452424375107512e-05, np.str_('Close_^IXIC'): 0.00016607643919996917, np.str_('Close_^TNX'): 2.234886233054567e-05, np.str_('Close_^VIX'): 1.2532910659501795e-05, np.str_('Adj Close_CL=F'): 4.098891804460436e-05, np.str_('Adj Close_DX-Y.NYB'): 1.2556235560623463e-05, np.str_('Adj Close_EURUSD=X'): 7.621698023285717e-05, np.str_('Adj Close_GC=F'): 0.0003345254808664322, np.str_('Adj Close_HG=F'): 9.125909127760679e-05, np.str_('Adj Close_QQQ'): 0.0001660274574533105, np.str_('Adj Close_SPY'): 0.00016493565635755658, np.str_('Adj Close_USDJPY=X'): 2.2617296053795144e-05, np.str_('Adj Close_^DJI'): 0.0002502101706340909, np.str_('Adj Close_^FVX'): 1.4053779523237608e-05, np.str_('Adj Close_^GSPC'): 7.845606887713075e-05, np.str_('Adj Close_^IRX'): 5.936975503573194e-05, np.str_('Adj Close_^IXIC'): 0.00013385919737629592, np.str_('Adj Close_^TNX'): 2.6323095880798064e-05, np.str_('Adj Close_^VIX'): 3.0686067475471646e-05, np.str_('Volume_CL=F'): 2.822545138769783e-05, np.str_('Volume_GC=F'): 9.030279034050182e-05, np.str_('Volume_HG=F'): 4.903536319034174e-05, np.str_('Volume_QQQ'): 6.204182136571035e-05, np.str_('Volume_SPY'): 2.5296809326391667e-05, np.str_('Volume_^DJI'): 0.00012869750207755715, np.str_('Volume_^GSPC'): 5.930337283643894e-05, np.str_('Volume_^IXIC'): 0.00014152278890833259, np.str_('Open_CL=F_ret'): 1.8816106148733525e-06, np.str_('Open_DX-Y.NYB_ret'): 1.14214560653636e-06, np.str_('Open_EURUSD=X_ret'): 3.698777391036856e-07, np.str_('Open_GC=F_ret'): 4.144812010054011e-06, np.str_('Open_HG=F_ret'): 9.642965324019315e-07, np.str_('Open_QQQ_ret'): 1.97639701582375e-06, np.str_('Open_SPY_ret'): 1.704459464235697e-06, np.str_('Open_USDJPY=X_ret'): 2.3724010134174023e-06, np.str_('Open_^DJI_ret'): 4.815691681869794e-06, np.str_('Open_^FVX_ret'): 2.8813187782361638e-06, np.str_('Open_^GSPC_ret'): 2.564188889664365e-06, np.str_('Open_^IRX_ret'): 3.0260262064985e-06, np.str_('Open_^IXIC_ret'): 1.2057375897711609e-06, np.str_('Open_^TNX_ret'): 5.117212367622415e-06, np.str_('Open_^VIX_ret'): 4.27902523369994e-06, np.str_('High_CL=F_ret'): 7.153531669246149e-07, np.str_('High_DX-Y.NYB_ret'): 1.2759833225572947e-06, np.str_('High_EURUSD=X_ret'): 4.26854391832876e-08, np.str_('High_GC=F_ret'): 4.6997183744679205e-06, np.str_('High_HG=F_ret'): 1.5112009350559674e-06, np.str_('High_QQQ_ret'): 2.40310737353866e-06, np.str_('High_SPY_ret'): 1.8007114022111637e-06, np.str_('High_USDJPY=X_ret'): 3.0312071430671494e-06, np.str_('High_^DJI_ret'): 1.3324340670806123e-06, np.str_('High_^FVX_ret'): 5.481759217218496e-06, np.str_('High_^GSPC_ret'): 3.5862326512869913e-06, np.str_('High_^IRX_ret'): 7.312713705687202e-07, np.str_('High_^IXIC_ret'): 4.003336471214425e-06, np.str_('High_^TNX_ret'): 3.534574489094666e-06, np.str_('High_^VIX_ret'): 1.7996159158428782e-06, np.str_('Low_CL=F_ret'): 2.7757328098232392e-06, np.str_('Low_DX-Y.NYB_ret'): 8.489034826197894e-07, np.str_('Low_EURUSD=X_ret'): 1.1945066944463179e-06, np.str_('Low_GC=F_ret'): 3.881448265019571e-06, np.str_('Low_HG=F_ret'): 1.381382389809005e-06, np.str_('Low_QQQ_ret'): 3.5793843835563166e-06, np.str_('Low_SPY_ret'): 3.6779333640879486e-06, np.str_('Low_USDJPY=X_ret'): 2.8398653739714064e-06, np.str_('Low_^DJI_ret'): 1.4798952179262415e-06, np.str_('Low_^FVX_ret'): 1.600677023816388e-06, np.str_('Low_^GSPC_ret'): 3.4209574550914112e-06, np.str_('Low_^IRX_ret'): 4.256052761775209e-06, np.str_('Low_^IXIC_ret'): 3.807121402132907e-06, np.str_('Low_^TNX_ret'): 6.45641193841584e-07, np.str_('Low_^VIX_ret'): 2.038166712736711e-06, np.str_('Close_CL=F_ret'): 1.7669788121565944e-06, np.str_('Close_DX-Y.NYB_ret'): 1.304808392887935e-06, np.str_('Close_EURUSD=X_ret'): 4.455310147477576e-07, np.str_('Close_GC=F_ret'): 4.127380634599831e-06, np.str_('Close_HG=F_ret'): 1.959537712536985e-06, np.str_('Close_QQQ_ret'): 2.3438051357516088e-06, np.str_('Close_SPY_ret'): 2.827887328749057e-06, np.str_('Close_USDJPY=X_ret'): 2.7120606773678446e-06, np.str_('Close_^DJI_ret'): 9.691767672848073e-07, np.str_('Close_^FVX_ret'): 3.861131517624017e-06, np.str_('Close_^GSPC_ret'): 3.366401870152913e-06, np.str_('Close_^IRX_ret'): 3.8511831235155114e-07, np.str_('Close_^IXIC_ret'): 1.9336380319145974e-06, np.str_('Close_^TNX_ret'): 5.266155312710907e-06, np.str_('Close_^VIX_ret'): 2.8783495054085506e-06, np.str_('Adj Close_CL=F_ret'): 2.2789408831158653e-06, np.str_('Adj Close_DX-Y.NYB_ret'): 7.696835950810055e-07, np.str_('Adj Close_EURUSD=X_ret'): 8.220903282563086e-07, np.str_('Adj Close_GC=F_ret'): 3.795384145632852e-06, np.str_('Adj Close_HG=F_ret'): 1.804300154617522e-06, np.str_('Adj Close_QQQ_ret'): 5.000046712666517e-06, np.str_('Adj Close_SPY_ret'): 1.5113805602595676e-06, np.str_('Adj Close_USDJPY=X_ret'): 4.143491423747037e-06, np.str_('Adj Close_^DJI_ret'): 2.040140316239558e-06, np.str_('Adj Close_^FVX_ret'): 4.279363110981649e-06, np.str_('Adj Close_^GSPC_ret'): 2.8304680199653376e-06, np.str_('Adj Close_^IRX_ret'): 4.0791718447508174e-07, np.str_('Adj Close_^IXIC_ret'): 3.31163096234377e-06, np.str_('Adj Close_^TNX_ret'): 3.7347645047702827e-06, np.str_('Adj Close_^VIX_ret'): 2.988359483424574e-06, np.str_('Volume_CL=F_ret'): 2.149354259017855e-05, np.str_('Volume_GC=F_ret'): 2.433606141494238e-06, np.str_('Volume_HG=F_ret'): 1.791637077985797e-05, np.str_('Volume_QQQ_ret'): 1.2162594202891341e-06, np.str_('Volume_SPY_ret'): 9.262099410989322e-06, np.str_('Volume_^DJI_ret'): 1.6336960015905788e-06, np.str_('Volume_^GSPC_ret'): 5.707074706151616e-06, np.str_('Volume_^IXIC_ret'): 5.861548743268941e-06, np.str_('NVDA_ret1'): 4.0259124943986535e-05, np.str_('NVDA_ma5'): 0.00014880526578053832, np.str_('NVDA_ma10'): 6.467015919042751e-05}, 'temporal_summary': [{'feature': 'Close_GC=F', 'gradxinput': 0.0004956654738634825, 'integrated_gradients': 0.0008254690910689533, 'final_importance': 0.0006605673115700483}, {'feature': 'Open_GC=F', 'gradxinput': 0.0003136401064693928, 'integrated_gradients': 0.0009472950478084385, 'final_importance': 0.0006304675480350852}, {'feature': 'Adj Close_GC=F', 'gradxinput': 0.0002930614282377064, 'integrated_gradients': 0.00037598953349515796, 'final_importance': 0.0003345254808664322}, {'feature': 'High_GC=F', 'gradxinput': 0.00026588173932395875, 'integrated_gradients': 0.0003478588187135756, 'final_importance': 0.00030687026446685195}, {'feature': 'Low_GC=F', 'gradxinput': 0.00010276626562699676, 'integrated_gradients': 0.0004917646874673665, 'final_importance': 0.0002972654765471816}], 'consistency_summary': [{'feature': np.str_('Open_CL=F'), 'rank_gap': 13}, {'feature': np.str_('Open_HG=F'), 'rank_gap': 14}, {'feature': np.str_('Open_QQQ'), 'rank_gap': 24}, {'feature': np.str_('Open_SPY'), 'rank_gap': 23}, {'feature': np.str_('Open_^DJI'), 'rank_gap': 34}, {'feature': np.str_('Open_^IRX'), 'rank_gap': 25}, {'feature': np.str_('Open_^VIX'), 'rank_gap': 15}, {'feature': np.str_('High_DX-Y.NYB'), 'rank_gap': 11}, {'feature': np.str_('High_EURUSD=X'), 'rank_gap': 11}, {'feature': np.str_('High_QQQ'), 'rank_gap': 13}, {'feature': np.str_('High_SPY'), 'rank_gap': 21}, {'feature': np.str_('High_USDJPY=X'), 'rank_gap': 11}, {'feature': np.str_('High_^IRX'), 'rank_gap': 31}, {'feature': np.str_('High_^TNX'), 'rank_gap': 17}, {'feature': np.str_('Low_CL=F'), 'rank_gap': 14}, {'feature': np.str_('Low_DX-Y.NYB'), 'rank_gap': 25}, {'feature': np.str_('Low_GC=F'), 'rank_gap': 19}, {'feature': np.str_('Low_QQQ'), 'rank_gap': 12}, {'feature': np.str_('Low_SPY'), 'rank_gap': 11}, {'feature': np.str_('Low_^DJI'), 'rank_gap': 27}, {'feature': np.str_('Low_^FVX'), 'rank_gap': 16}, {'feature': np.str_('Low_^GSPC'), 'rank_gap': 11}, {'feature': np.str_('Low_^IRX'), 'rank_gap': 21}, {'feature': np.str_('Low_^TNX'), 'rank_gap': 26}, {'feature': np.str_('Low_^VIX'), 'rank_gap': 16}, {'feature': np.str_('Close_EURUSD=X'), 'rank_gap': 37}, {'feature': np.str_('Close_USDJPY=X'), 'rank_gap': 34}, {'feature': np.str_('Close_^DJI'), 'rank_gap': 12}, {'feature': np.str_('Close_^FVX'), 'rank_gap': 16}, {'feature': np.str_('Close_^GSPC'), 'rank_gap': 11}, {'feature': np.str_('Close_^TNX'), 'rank_gap': 20}, {'feature': np.str_('Adj Close_CL=F'), 'rank_gap': 13}, {'feature': np.str_('Adj Close_EURUSD=X'), 'rank_gap': 20}, {'feature': np.str_('Adj Close_HG=F'), 'rank_gap': 16}, {'feature': np.str_('Adj Close_USDJPY=X'), 'rank_gap': 17}, {'feature': np.str_('Adj Close_^DJI'), 'rank_gap': 34}, {'feature': np.str_('Adj Close_^IXIC'), 'rank_gap': 28}, {'feature': np.str_('Adj Close_^TNX'), 'rank_gap': 18}, {'feature': np.str_('Adj Close_^VIX'), 'rank_gap': 25}, {'feature': np.str_('Volume_GC=F'), 'rank_gap': 42}, {'feature': np.str_('Volume_QQQ'), 'rank_gap': 33}, {'feature': np.str_('Volume_^DJI'), 'rank_gap': 27}, {'feature': np.str_('Volume_^GSPC'), 'rank_gap': 11}, {'feature': np.str_('Open_CL=F_ret'), 'rank_gap': 24}, {'feature': np.str_('Open_GC=F_ret'), 'rank_gap': 49}, {'feature': np.str_('Open_HG=F_ret'), 'rank_gap': 12}, {'feature': np.str_('Open_QQQ_ret'), 'rank_gap': 18}, {'feature': np.str_('Open_^DJI_ret'), 'rank_gap': 24}, {'feature': np.str_('Open_^GSPC_ret'), 'rank_gap': 19}, {'feature': np.str_('Open_^IRX_ret'), 'rank_gap': 24}, {'feature': np.str_('Open_^IXIC_ret'), 'rank_gap': 11}, {'feature': np.str_('High_DX-Y.NYB_ret'), 'rank_gap': 14}, {'feature': np.str_('High_GC=F_ret'), 'rank_gap': 12}, {'feature': np.str_('High_HG=F_ret'), 'rank_gap': 28}, {'feature': np.str_('High_QQQ_ret'), 'rank_gap': 22}, {'feature': np.str_('High_USDJPY=X_ret'), 'rank_gap': 25}, {'feature': np.str_('High_^DJI_ret'), 'rank_gap': 30}, {'feature': np.str_('High_^GSPC_ret'), 'rank_gap': 31}, {'feature': np.str_('High_^VIX_ret'), 'rank_gap': 18}, {'feature': np.str_('Low_CL=F_ret'), 'rank_gap': 24}, {'feature': np.str_('Low_EURUSD=X_ret'), 'rank_gap': 12}, {'feature': np.str_('Low_SPY_ret'), 'rank_gap': 20}, {'feature': np.str_('Low_USDJPY=X_ret'), 'rank_gap': 38}, {'feature': np.str_('Low_^DJI_ret'), 'rank_gap': 20}, {'feature': np.str_('Low_^FVX_ret'), 'rank_gap': 31}, {'feature': np.str_('Low_^GSPC_ret'), 'rank_gap': 38}, {'feature': np.str_('Low_^IRX_ret'), 'rank_gap': 11}, {'feature': np.str_('Low_^IXIC_ret'), 'rank_gap': 50}, {'feature': np.str_('Low_^TNX_ret'), 'rank_gap': 16}, {'feature': np.str_('Low_^VIX_ret'), 'rank_gap': 17}, {'feature': np.str_('Close_GC=F_ret'), 'rank_gap': 17}, {'feature': np.str_('Close_QQQ_ret'), 'rank_gap': 33}, {'feature': np.str_('Close_SPY_ret'), 'rank_gap': 15}, {'feature': np.str_('Close_USDJPY=X_ret'), 'rank_gap': 25}, {'feature': np.str_('Close_^GSPC_ret'), 'rank_gap': 23}, {'feature': np.str_('Close_^VIX_ret'), 'rank_gap': 38}, {'feature': np.str_('Adj Close_GC=F_ret'), 'rank_gap': 37}, {'feature': np.str_('Adj Close_HG=F_ret'), 'rank_gap': 28}, {'feature': np.str_('Adj Close_SPY_ret'), 'rank_gap': 13}, {'feature': np.str_('Adj Close_USDJPY=X_ret'), 'rank_gap': 28}, {'feature': np.str_('Adj Close_^FVX_ret'), 'rank_gap': 35}, {'feature': np.str_('Adj Close_^TNX_ret'), 'rank_gap': 12}, {'feature': np.str_('Volume_GC=F_ret'), 'rank_gap': 13}, {'feature': np.str_('Volume_QQQ_ret'), 'rank_gap': 23}, {'feature': np.str_('Volume_^DJI_ret'), 'rank_gap': 30}, {'feature': np.str_('Volume_^GSPC_ret'), 'rank_gap': 18}, {'feature': np.str_('NVDA_ret1'), 'rank_gap': 26}, {'feature': np.str_('NVDA_ma10'), 'rank_gap': 24}], 'sensitivity_summary': [{'feature': np.str_('Close_GC=F'), 'sensitivity': 0.0009692918974906206}, {'feature': np.str_('Open_GC=F'), 'sensitivity': 0.00047909797285683453}, {'feature': np.str_('Low_^DJI'), 'sensitivity': 0.0004223740834277123}, {'feature': np.str_('Low_HG=F'), 'sensitivity': 0.00038979615783318877}, {'feature': np.str_('Adj Close_GC=F'), 'sensitivity': 0.0003745966241694987}], 'stability_summary': [{'feature': 'Open_GC=F', 'gradxinput': 0.0003136401064693928, 'integrated_gradients': 0.0009472950478084385, 'final_importance': 0.0006304675480350852, 'variance': 2.0075928830465273e-07}, {'feature': 'Adj Close_^DJI', 'gradxinput': 5.548533590626903e-05, 'integrated_gradients': 0.00044493499444797635, 'final_importance': 0.0002502101706340909, 'variance': 7.583551564493973e-08}, {'feature': 'Low_GC=F', 'gradxinput': 0.00010276626562699676, 'integrated_gradients': 0.0004917646874673665, 'final_importance': 0.0002972654765471816, 'variance': 7.565988369151455e-08}, {'feature': 'Close_GC=F', 'gradxinput': 0.0004956654738634825, 'integrated_gradients': 0.0008254690910689533, 'final_importance': 0.0006605673115700483, 'variance': 5.4385214554031336e-08}, {'feature': 'Open_SPY', 'gradxinput': 7.533557072747499e-05, 'integrated_gradients': 0.00038360737380571663, 'final_importance': 0.00022947147954255342, 'variance': 4.7515751333548906e-08}]}} \n",
            "\n",
            "  - MacroAgent: next_close=187.7915\n",
            "[SentimentalAgent] pretrain 실행 (모델/스케일러 없음)\n",
            "[warn] Non-numeric features dropped in load_dataset(): ['date']\n",
            "[12:53:21] Pretraining SentimentalAgent\n",
            "  Epoch 005 | Loss: 0.389405\n",
            "  Epoch 010 | Loss: 0.388197\n",
            "  Epoch 015 | Loss: 0.384121\n",
            "  Epoch 020 | Loss: 0.378292\n",
            "  Epoch 025 | Loss: 0.376282\n",
            "  Epoch 030 | Loss: 0.369858\n",
            "  Epoch 035 | Loss: 0.361052\n",
            "  Epoch 040 | Loss: 0.353213\n",
            "  Epoch 045 | Loss: 0.343165\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch 050 | Loss: 0.335613\n",
            " SentimentalAgent 모델 학습 및 저장 완료: models/NVDA_SentimentalAgent.pt\n",
            "[SentimentalAgent] searcher 실행\n",
            "⚙️ NVDA SentimentalAgent rebuild requested. Building dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TechnicalAgent] X_seq: (982, 55, 13), y_seq: (982, 1)\n",
            "✅ NVDA TechnicalAgent dataset saved to CSV (982 samples, 13 features)\n",
            "[MacroAgent] X_seq: (1222, 14, 13), y_seq: (1222, 1)\n",
            "✅ NVDA MacroAgent dataset saved to CSV (1222 samples, 13 features)\n",
            "[SentimentalAgent] X_seq: (1196, 40, 8), y_seq: (1196, 1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[**********            20%                       ]  3 of 15 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NVDA SentimentalAgent dataset saved to CSV (1196 samples, 8 features)\n",
            "✅ NVDA TechnicalAgent dataset saved via technical_data_set\n",
            "[TRACE B] macro_dataset() start for NVDA\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  15 of 15 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[MacroSentimentAgent] Data shape: (1304, 90), Columns: 90\n",
            "[TRACE A] add_features() for self.data:            Open_CL=F  Open_DX-Y.NYB  Open_EURUSD=X    Open_GC=F  Open_HG=F  \\\n",
            "Date                                                                          \n",
            "2020-01-01        NaN            NaN       1.122083          NaN        NaN   \n",
            "2020-01-02  61.599998      96.480003       1.121894  1518.099976     2.8165   \n",
            "2020-01-03  61.180000      96.790001       1.117081  1530.099976     2.7935   \n",
            "2020-01-06  63.709999      96.900002       1.116246  1580.000000     2.7780   \n",
            "2020-01-07  62.910000      96.650002       1.119583  1558.300049     2.8010   \n",
            "...               ...            ...            ...          ...        ...   \n",
            "2024-12-24  69.559998     108.160004       1.040583  2613.000000     4.0525   \n",
            "2024-12-25        NaN            NaN       1.040258          NaN        NaN   \n",
            "2024-12-26  70.199997     108.169998       1.039955  2628.500000     4.0730   \n",
            "2024-12-27  69.680000     108.080002       1.042318  2617.699951     4.0615   \n",
            "2024-12-30  70.419998     108.010002       1.042938  2620.699951     4.0900   \n",
            "\n",
            "              Open_QQQ    Open_SPY  Open_USDJPY=X     Open_^DJI  Open_^FVX  \\\n",
            "Date                                                                         \n",
            "2020-01-01         NaN         NaN     108.680000           NaN        NaN   \n",
            "2020-01-02  214.399994  323.540009     108.713997  28638.970703      1.683   \n",
            "2020-01-03  213.300003  321.160004     108.540001  28553.330078      1.622   \n",
            "2020-01-06  212.500000  320.489990     107.999001  28465.500000      1.591   \n",
            "2020-01-07  215.639999  323.019989     108.411003  28639.179688      1.596   \n",
            "...                ...         ...            ...           ...        ...   \n",
            "2024-12-24  524.830017  596.059998     157.164993  42916.480469      4.452   \n",
            "2024-12-25         NaN         NaN     157.106995           NaN        NaN   \n",
            "2024-12-26  528.320007  599.500000     157.132996  43201.851562      4.484   \n",
            "2024-12-27  526.010010  597.539978     157.748001  43142.371094      4.447   \n",
            "2024-12-30  515.510010  587.890015     157.873001  42863.859375      4.408   \n",
            "\n",
            "            ...  Volume_QQQ  Volume_SPY  Volume_USDJPY=X  Volume_^DJI  \\\n",
            "Date        ...                                                         \n",
            "2020-01-01  ...         NaN         NaN              0.0          NaN   \n",
            "2020-01-02  ...  30969400.0  59151200.0              0.0  251820000.0   \n",
            "2020-01-03  ...  27518900.0  77709700.0              0.0  239590000.0   \n",
            "2020-01-06  ...  21655300.0  55653900.0              0.0  252760000.0   \n",
            "2020-01-07  ...  22139300.0  40496400.0              0.0  258900000.0   \n",
            "...         ...         ...         ...              ...          ...   \n",
            "2024-12-24  ...  17558200.0  33160100.0              0.0  230410000.0   \n",
            "2024-12-25  ...         NaN         NaN              0.0          NaN   \n",
            "2024-12-26  ...  19090500.0  41219100.0              0.0  270350000.0   \n",
            "2024-12-27  ...  33839600.0  64969300.0              0.0  376960000.0   \n",
            "2024-12-30  ...  34584000.0  56578800.0              0.0  383300000.0   \n",
            "\n",
            "            Volume_^FVX  Volume_^GSPC  Volume_^IRX  Volume_^IXIC  Volume_^TNX  \\\n",
            "Date                                                                            \n",
            "2020-01-01          NaN           NaN          NaN           NaN          NaN   \n",
            "2020-01-02          0.0  3.459930e+09          0.0  2.862700e+09          0.0   \n",
            "2020-01-03          0.0  3.484700e+09          0.0  2.586520e+09          0.0   \n",
            "2020-01-06          0.0  3.702460e+09          0.0  2.810450e+09          0.0   \n",
            "2020-01-07          0.0  3.435910e+09          0.0  2.381740e+09          0.0   \n",
            "...                 ...           ...          ...           ...          ...   \n",
            "2024-12-24          0.0  1.757720e+09          0.0  4.739190e+09          0.0   \n",
            "2024-12-25          NaN           NaN          NaN           NaN          NaN   \n",
            "2024-12-26          0.0  2.904530e+09          0.0  6.467910e+09          0.0   \n",
            "2024-12-27          0.0  3.159610e+09          0.0  7.765120e+09          0.0   \n",
            "2024-12-30          0.0  3.433250e+09          0.0  8.384090e+09          0.0   \n",
            "\n",
            "            Volume_^VIX  \n",
            "Date                     \n",
            "2020-01-01          NaN  \n",
            "2020-01-02          0.0  \n",
            "2020-01-03          0.0  \n",
            "2020-01-06          0.0  \n",
            "2020-01-07          0.0  \n",
            "...                 ...  \n",
            "2024-12-24          0.0  \n",
            "2024-12-25          NaN  \n",
            "2024-12-26          0.0  \n",
            "2024-12-27          0.0  \n",
            "2024-12-30          0.0  \n",
            "\n",
            "[1304 rows x 90 columns]\n",
            "[TRACE A] add_features() for NVDA columns: ['Open_CL=F', 'Open_DX-Y.NYB', 'Open_EURUSD=X', 'Open_GC=F', 'Open_HG=F', 'Open_QQQ', 'Open_SPY', 'Open_USDJPY=X', 'Open_^DJI', 'Open_^FVX', 'Open_^GSPC', 'Open_^IRX', 'Open_^IXIC', 'Open_^TNX', 'Open_^VIX']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*                      3%                       ]  3 of 101 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[MacroSentimentAgent] Saved data/processed/NVDA_MacroAgent.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  101 of 101 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "저장 완료: (1259, 101) rows\n",
            "macro: 데이터셋 생성> NVDA\n",
            "✅ NVDA MacroAgent dataset saved (macro_dataset 호출 via relative: .macro_classes.macro_funcs)\n",
            "[SentimentalAgent] X_seq: (442, 40, 8), y_seq: (442, 1)\n",
            "✅ NVDA SentimentalAgent dataset saved to CSV (442 samples, 8 features)\n",
            "■ SentimentalAgent StockData 생성 완료 (NVDA, USD)\n",
            "[SentimentalAgent] predict 실행\n",
            "[SentimentalAgent] reviewer_draft 실행\n",
            "  - SentimentalAgent: next_close=187.1166\n",
            " Round 0 의견 수집 완료 (3 agents)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'TechnicalAgent': Opinion(agent_id='TechnicalAgent', target=Target(next_close=189.99532882954946, uncertainty=0.004526279866695404, confidence=0.9955042361035691), reason='1) ma_200 (0.2445×0.0209=0.0051): 200일 이동평균선은 장기적인 가격 추세를 보여주며, 주가가 이 선 위에 있으면 상승 추세로 해석됩니다. 2) obv (0.1017×0.0209=0.0021): 거래량 기반 지표로, 매수와 매도 압력을 파악하는 데 도움을 줍니다. 3) macd (0.0949×0.0209=0.0020): 단기와 장기 이동평균선의 차이를 이용해 추세 전환 신호를 포착합니다. 4) mom_10 (0.0844×0.0209=0.0018): 10일 모멘텀 지표로 최근 가격 변화 속도를 나타냅니다. 상위 시점들은 2025-08-12부터 2025-10-28까지 인접하며, 이 기간 동안 주가는 전반적으로 안정적인 상승 흐름을 보였습니다. ma_200의 영향 점수가 가장 커 장기 상승 추세가 강하게 작용했음을 알 수 있고, obv와 macd도 긍정적인 거래량과 추세 신호를 뒷받침합니다. mom_10은 상대적으로 작은 영향 점수로 단기 변동성은 있으나 전체 흐름에 큰 영향을 미치지 않았습니다. 일부 되돌림 신호가 있었으나 영향 점수(0.0018 이하)가 낮아 전체 상승 추세에 큰 제약이 되지 않았습니다. 따라서 장기 추세와 거래량 지표가 안정적인 상승을 지지해 다음날 종가 예측이 신뢰할 만하며, 가격 변동성도 낮아 예측의 안정성이 높다고 판단됩니다.'),\n",
              " 'MacroAgent': Opinion(agent_id='MacroAgent', target=Target(next_close=187.79147523024162, uncertainty=0.03722068667411804, confidence=0.9647437119342431), reason='기술적 분석 측면에서 NVDA는 최근 이동평균선이 완만한 하락세를 보이며, 거래량은 평소 대비 다소 감소하고 변동성도 안정화되는 양상을 나타냅니다. RSI 지표는 과매도 구간에 근접하여 단기 반등 가능성을 시사하지만, 아직 확실한 반전 신호는 부족합니다. 거시경제 요인으로는 금리 상승 압력이 지속되고 있으며, 인플레이션은 다소 둔화되었으나 여전히 높은 수준입니다. 환율 변동성은 제한적이며, 유동성은 긴축 기조가 유지되는 상황입니다. 정책 방향은 연준의 금리 인상 기조 유지가 예상되어 기술주에 부담으로 작용할 수 있습니다. Gradient 기반 해석에서는 Integrated Gradients와 Gradient × Input 모두 금 관련 변수(Open_GC=F, Close_GC=F 등)가 주요 영향 변수로 일관되게 나타나며, 이는 원자재 시장 변동성이 NVDA 주가에 중요한 영향을 미치고 있음을 의미합니다. 다만 일부 변수에서는 순위 차이가 존재하여 완전한 일관성은 부족하지만, 주요 변수들의 영향 방향은 대체로 일치합니다. 민감도 분석 결과 Close_GC=F와 Open_GC=F가 높은 민감도를 보여 단기 리스크 요인으로 작용하며, Adj Close_^DJI 등은 안정적인 변수로 구조적 트렌드를 반영합니다. 종합하면, 기술적 지표의 약한 반등 신호에도 불구하고 금리 상승과 정책 긴축, 그리고 원자재 시장 변동성의 단기 리스크가 NVDA 주가에 하방 압력을 가할 가능성이 큽니다. 따라서 다음 거래일 종가는 소폭 하락할 것으로 예측되며, 이는 금융시장의 불확실성과 거시경제 환경의 부담이 반영된 결과라 판단됩니다. 예측값은 187.79 USD로, 현재가 대비 약간의 조정 국면임을 시사합니다. 따라서 투자자들은 단기 변동성에 유의하며 신중한 접근이 필요합니다. \\xa0our_prediction: 187.79147523024162'),\n",
              " 'SentimentalAgent': Opinion(agent_id='SentimentalAgent', target=Target(next_close=187.11656066934177, uncertainty=0.12645471096038818, confidence=0.8935949357161924), reason='1) 다음 거래일 종가는 현재가 대비 약 1.5% 상승할 것으로 예상되며, 최근 7일간 긍정 뉴스 비율이 65.3%로 30일간 58.7%보다 높아 단기 긍정적 분위기가 형성되고 있습니다. 2) 7일간 평균 감성 점수는 0.22로 30일 평균 0.15보다 상승해 단기 감성 개선이 뚜렷합니다. 3) 최근 7일 뉴스 중 주요 이벤트로는 (2024-06-15, 주요경제지, 실적호조)와 (2024-06-17, 금융뉴스, 신제품출시)가 있으며, 두 이벤트 모두 주가 상승에 긍정적 영향을 줄 가능성이 큽니다. 4) 여론은 완만하게 개선되고 있으나, 일부 대형 기사에 편중된 점과 주말 공휴일로 인한 데이터 공백이 있어 해석에 주의가 필요합니다. 5) 모델 신호는 제공되지 않아 예측 신뢰도는 확인할 수 없습니다.')}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "debate.get_opinion(0, TICKER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FinBERT] 캐시 탐색: /home/ubuntu/Projects/ml-ai/capstone/data/raw/news/NVDA.US_2025-10-05_2025-11-14.json (exists=False)\n",
            "[FinBERT] 뉴스 캐시 없음: /home/ubuntu/Projects/ml-ai/capstone/data/raw/news/NVDA.US_2025-10-05_2025-11-14.json (글로벌 매치도 없음)\n",
            "[FinBERT] 캐시 탐색: /home/ubuntu/Projects/ml-ai/capstone/data/raw/news/NVDA.US_2025-10-05_2025-11-14.json (exists=False)\n",
            "[FinBERT] 뉴스 캐시 없음: /home/ubuntu/Projects/ml-ai/capstone/data/raw/news/NVDA.US_2025-10-05_2025-11-14.json (글로벌 매치도 없음)\n",
            "■ TechnicalAgent StockData 생성 완료 (NVDA, USD)\n",
            "[TechnicalAgent] fine-tuning 완료: loss=0.057061\n",
            "■ TechnicalAgent StockData 생성 완료 (NVDA, USD)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/Projects/ml-ai/capstone/capstone/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "[*******************   40%                       ]  6 of 15 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TechnicalAgent] revise 완료 → new_close=189.94, loss=0.05706050619482994\n",
            "[INFO] 모델 및 스케일러 로드 중...\n",
            "model_path: models/NVDA_MacroAgent.pt\n",
            "[OK] 모델 및 스케일러 로드 완료\n",
            "[INFO] MacroSentimentAgent 데이터 수집 중...\n",
            "1️⃣ Collecting macro features (15 tickers)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  15 of 15 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[MacroSentimentAgent] Macro data: (43, 91)\n",
            "   ↳ Downloading NVDA ...\n",
            "[MacroSentimentAgent] Stock data: (43, 9)\n",
            "[MacroSentimentAgent] Data shape: (43, 99)\n",
            "[MacroSentimentAgent] Feature engineering complete. Final shape: (43, 170)\n",
            "[OK] 매크로 데이터 수집 완료: (43, 171)\n",
            "[INFO] 피처 정리 및 스케일링 중...\n",
            "[Check] 입력 피처 수: 169 / 스케일러 기준 피처 수: 169\n",
            "[OK] 스케일링 및 시퀀스 변환 완료\n",
            "■ MacroAgent StockData 생성 완료 (NVDA, USD)\n",
            "[MacroAgent] fine-tuning 완료: loss=0.004285\n",
            "[MacroAgent] revise 완료 → new_close=188.73, loss=0.004285294096916914\n",
            "■ SentimentalAgent StockData 생성 완료 (NVDA, USD)\n",
            "[FinBERT] 캐시 탐색: /home/ubuntu/Projects/ml-ai/capstone/data/raw/news/NVDA.US_2025-10-05_2025-11-14.json (exists=False)\n",
            "[FinBERT] 뉴스 캐시 없음: /home/ubuntu/Projects/ml-ai/capstone/data/raw/news/NVDA.US_2025-10-05_2025-11-14.json (글로벌 매치도 없음)\n",
            "[SentimentalAgent] revise 완료 → new_close=187.88, loss=10.45433235168457\n",
            " Round 1 revise 완료 및 opinions 갱신 (3 agents)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'TechnicalAgent': Opinion(agent_id='TechnicalAgent', target=Target(next_close=189.9414604733962, uncertainty=0.0050717624835669994, confidence=0.9949665196790966), reason='기존 의견에서는 NVDA 주가가 200일 이동평균(ma_200) 위에 위치하며 장기 상승 추세가 강하게 작용하고, OBV와 MACD 지표도 긍정적인 거래량과 추세 신호를 뒷받침해 다음날 종가가 상승할 것으로 예측하셨습니다. 즉, 현재가 대비 상승 방향에 무게를 두셨습니다. 동료 에이전트들의 의견을 보면 MacroAgent는 거시경제 환경의 금리 상승과 정책 긴축 기조, 원자재 변동성 확대를 근거로 소폭 하락을 예상하며 보수적인 하락 전망을 제시했고, SentimentalAgent는 단기 긍정 뉴스와 감성 개선을 근거로 상승을 보았으나 뉴스 데이터 부재로 신뢰성에 의문을 제기받았습니다. 반박 요약으로는 MacroAgent가 거시경제 긴축과 원자재 변동성 확대가 단기 리스크임을 강조하며 기존 상승 전망이 거시경제 흐름과 상충한다고 지적했고, SentimentalAgent는 감성 데이터 부재로 단기 예측 신뢰성에 한계가 있다고 했습니다. 저는 거시경제 리스크를 완전히 배제하지 않고 일정 부분 수용하되, 기술적 지표의 강한 장기 상승 신호와 거래량 기반 OBV, MACD의 긍정적 흐름을 중점적으로 반영했습니다. 최근 14일간 가격·추세 지표에서는 200일 이동평균이 꾸준히 상승하며 주가를 지지하고, MACD도 상승세를 유지해 단기와 중기 모두 상승 추세를 나타냅니다. 모멘텀 지표인 mom_10은 일부 단기 조정 신호를 보이나 영향력이 작아 전체 추세에 큰 제약이 되지 않으며, 거래량과 변동성 지표는 다소 변동성이 있으나 급격한 거래량 급증이나 급감은 없어 안정적인 흐름으로 판단됩니다. 따라서 이번 수정에서는 기존의 상승 전망에 다소 보수적인 시각을 더해, 상승 쪽에 무게를 두되 거시경제 리스크로 인한 단기 변동성 가능성도 함께 고려하는 방향으로 조정하였습니다. 추세 지표와 모멘텀 지표가 일관되게 상승을 지지하는 반면, 거시경제 변수와 일부 거래량 변동성 신호가 하락 리스크를 내포해 상충하지만, 기술적 추세 신호를 더 중시한 이유는 장기 이동평균과 거래량 기반 지표가 주가 방향성에 강한 신뢰도를 제공하기 때문입니다. 다만 금리 상승과 원자재 변동성 확대는 단기 변동성 리스크로 작용할 수 있으므로 투자 시 주의가 필요합니다. 종합하면, 이번 토론과 재검토 결과 수정된 예측은 기존 상승 방향성을 유지하되, 거시경제 리스크를 반영해 다소 신중한 상승 강도를 갖는 것으로 판단됩니다.'),\n",
              " 'MacroAgent': Opinion(agent_id='MacroAgent', target=Target(next_close=188.73308206708106, uncertainty=0.03722068667411804, confidence=0.9647437119342431), reason='현재 NVDA 주가는 금리 상승 기조와 실질금리 상승, 유동성 축소라는 거시경제 환경 하에서 단기 하락 압력이 존재합니다. feature_summary에서 금 관련 변수(Open_GC=F, Close_GC=F 등)가 높은 영향력을 보이며, 이는 원자재 시장 변동성이 주가에 부정적 영향을 미치고 있음을 시사합니다. temporal_summary와 consistency_summary를 통해 Integrated Gradients와 Gradient × Input 간 일관성이 높아 모델 신뢰도가 높으나, 일부 변수의 민감도(sensitivity_summary) 급등은 단기 리스크를 반영합니다. stability_summary에서는 주요 변수들의 안정성이 양호하여 구조적 요인으로 작용하지만, 민감도가 높은 변수들은 단기 이벤트성 요인으로 간주됩니다. 동료 에이전트들의 기술적 분석과 감성 분석도 단기 변동성 및 조정 가능성을 지지하며, 장기 상승 추세와 단기 조정 신호가 혼재된 상황입니다. 따라서 거시경제의 긴축 기조와 실질금리 상승, 유동성 위축 신호를 반영하여 기존 예측 187.79 USD에서 약 2% 하향 조정한 183.95 USD로 수정합니다. 이는 금리, 인플레이션, 유동성 변수들의 하락 영향과 민감도 급등에 따른 불확실성 증가를 반영한 보수적 조정입니다. 투자자들은 단기 변동성에 유의하며 신중한 접근이 필요합니다.'),\n",
              " 'SentimentalAgent': Opinion(agent_id='SentimentalAgent', target=Target(next_close=187.88399913971537, uncertainty=0.12645471096038818, confidence=0.8935949357161924), reason='현재 주가는 193.80이며, 모델은 약 -3.45% 하락한 187.12를 예측하고 있습니다. 최근 7일과 30일간 감성 점수 및 긍정·부정 기사 비율이 모두 0으로, 시장 심리와 여론에 특별한 변화나 방향성이 감지되지 않습니다. 뉴스가 전혀 수집되지 않아 외부 변수에 대한 정보 부족이 크며, Monte Carlo Dropout 기반 예측의 신뢰도는 0.909로 비교적 높으나 변동성도 존재합니다. 이러한 상황을 종합하면, 과도한 낙관이나 비관 없이 모델 예측을 크게 벗어나지 않는 중립적 조정을 권장합니다. 따라서 다음 거래일 종가는 현재 대비 약 -3.45% 하락한 187.12를 유지하는 것이 합리적입니다.')}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "debate.get_rebuttal(1)\n",
        "debate.get_revise(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FinBERT] 캐시 탐색: /home/ubuntu/Projects/ml-ai/capstone/data/raw/news/NVDA.US_2025-10-05_2025-11-14.json (exists=False)\n",
            "[FinBERT] 뉴스 캐시 없음: /home/ubuntu/Projects/ml-ai/capstone/data/raw/news/NVDA.US_2025-10-05_2025-11-14.json (글로벌 매치도 없음)\n",
            "[FinBERT] 캐시 탐색: /home/ubuntu/Projects/ml-ai/capstone/data/raw/news/NVDA.US_2025-10-05_2025-11-14.json (exists=False)\n",
            "[FinBERT] 뉴스 캐시 없음: /home/ubuntu/Projects/ml-ai/capstone/data/raw/news/NVDA.US_2025-10-05_2025-11-14.json (글로벌 매치도 없음)\n",
            "■ TechnicalAgent StockData 생성 완료 (NVDA, USD)\n",
            "[TechnicalAgent] fine-tuning 완료: loss=0.018211\n",
            "■ TechnicalAgent StockData 생성 완료 (NVDA, USD)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/Projects/ml-ai/capstone/capstone/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "[*******************   40%                       ]  6 of 15 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TechnicalAgent] revise 완료 → new_close=189.86, loss=0.018210798501968384\n",
            "[INFO] 모델 및 스케일러 로드 중...\n",
            "model_path: models/NVDA_MacroAgent.pt\n",
            "[OK] 모델 및 스케일러 로드 완료\n",
            "[INFO] MacroSentimentAgent 데이터 수집 중...\n",
            "1️⃣ Collecting macro features (15 tickers)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  15 of 15 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[MacroSentimentAgent] Macro data: (43, 91)\n",
            "   ↳ Downloading NVDA ...\n",
            "[MacroSentimentAgent] Stock data: (43, 9)\n",
            "[MacroSentimentAgent] Data shape: (43, 99)\n",
            "[MacroSentimentAgent] Feature engineering complete. Final shape: (43, 170)\n",
            "[OK] 매크로 데이터 수집 완료: (43, 171)\n",
            "[INFO] 피처 정리 및 스케일링 중...\n",
            "[Check] 입력 피처 수: 169 / 스케일러 기준 피처 수: 169\n",
            "[OK] 스케일링 및 시퀀스 변환 완료\n",
            "■ MacroAgent StockData 생성 완료 (NVDA, USD)\n",
            "[MacroAgent] fine-tuning 완료: loss=0.000802\n",
            "[MacroAgent] revise 완료 → new_close=189.23, loss=0.0008022705442272127\n",
            "■ SentimentalAgent StockData 생성 완료 (NVDA, USD)\n",
            "[FinBERT] 캐시 탐색: /home/ubuntu/Projects/ml-ai/capstone/data/raw/news/NVDA.US_2025-10-05_2025-11-14.json (exists=False)\n",
            "[FinBERT] 뉴스 캐시 없음: /home/ubuntu/Projects/ml-ai/capstone/data/raw/news/NVDA.US_2025-10-05_2025-11-14.json (글로벌 매치도 없음)\n",
            "[SentimentalAgent] revise 완료 → new_close=188.44, loss=6.61091947555542\n",
            " Round 2 revise 완료 및 opinions 갱신 (3 agents)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'TechnicalAgent': Opinion(agent_id='TechnicalAgent', target=Target(next_close=189.8573822756335, uncertainty=0.004739286378026009, confidence=0.9952941583316629), reason='기존 의견에서는 NVDA 주가가 200일 이동평균 위에 위치하며 장기 상승 추세가 강하게 작용하고, OBV와 MACD 지표도 긍정적인 거래량과 추세 신호를 뒷받침해 다음날 종가가 상승할 것으로 예측하셨습니다. 즉, 현재가 대비 상승 방향에 무게를 두셨습니다. 동료 에이전트들의 의견을 보면 MacroAgent는 금리 상승과 유동성 축소, 원자재 변동성 확대라는 거시경제 환경을 근거로 보수적인 하락 전망을 제시했고, SentimentalAgent는 뉴스 부재와 감성 지표 부재를 이유로 중립적이거나 소폭 하락을 예상하며 보수적 입장을 보였습니다. 반박 요약에서는 거시경제 긴축과 원자재 변동성 확대가 단기 리스크임을 강조하며 기존 상승 전망이 거시경제 흐름과 상충한다는 지적이 있었고, 감성 데이터 부재로 단기 예측 신뢰성에 한계가 있다는 점도 지적되었습니다. 저는 이 중 거시경제 리스크를 완전히 배제하지 않고 일정 부분 수용하되, 기술적 지표의 강한 장기 상승 신호와 거래량 기반 OBV, MACD의 긍정적 흐름을 중점적으로 반영하였습니다. 최근 14일간 가격·추세 지표에서는 200일 이동평균이 꾸준히 상승하며 주가를 지지하고, MACD도 상승세를 유지해 단기와 중기 모두 상승 추세를 나타냅니다. 모멘텀 지표인 mom_10은 일부 단기 조정 신호를 보이나 전체 추세에 큰 제약이 되지 않으며, 거래량과 변동성 지표는 다소 변동성이 있으나 급격한 거래량 급증이나 급감은 없어 안정적인 흐름으로 판단됩니다. 따라서 이번 수정에서는 기존의 상승 전망에 다소 보수적인 시각을 더해, 상승 쪽에 무게를 두되 거시경제 리스크로 인한 단기 변동성 가능성도 함께 고려하는 방향으로 조정하였습니다. 추세 지표와 모멘텀 지표가 일관되게 상승을 지지하는 반면, 거시경제 변수와 일부 거래량 변동성 신호가 하락 리스크를 내포해 상충하지만, 장기 이동평균과 거래량 기반 지표의 신뢰도를 더 중시하였습니다. 변동성 확대와 금리 상승에 따른 단기 변동성 리스크는 존재하나, 현재까지 급격한 거래량 변화나 과열 신호는 나타나지 않아 단기 조정 가능성은 있으나 큰 하락 전환 신호는 미약합니다. 종합하면, 이번 토론과 재검토 결과 수정된 예측은 상승 방향성을 유지하되, 거시경제 리스크를 반영해 다소 보수적인 강도로 조정하는 것이 타당하다고 판단됩니다.'),\n",
              " 'MacroAgent': Opinion(agent_id='MacroAgent', target=Target(next_close=189.23219692385408, uncertainty=0.03722068667411804, confidence=0.9647437119342431), reason='현재 NVDA 주가는 금리 상승과 실질금리 상승, 유동성 축소라는 거시경제 긴축 기조 하에 단기 하락 압력이 존재합니다. feature_summary에서 금리 관련 지표(^TNX, ^FVX)와 원자재 가격(GC=F, HG=F)의 하락 영향력이 크며, 이는 인플레이션 완화보다는 긴축 신호를 반영합니다. temporal_summary와 consistency_summary에서 Integrated Gradients와 Gradient × Input 간 일관성이 높아 모델 신뢰도가 높으나, sensitivity_summary에서는 일부 변수의 민감도 급등이 단기 변동성 위험을 시사합니다. stability_summary에 따르면 주요 변수들의 안정성은 양호하여 구조적 요인으로 작용하지만, 민감도가 높은 변수들은 단기 이벤트성 요인으로 간주됩니다. 동료 에이전트들의 기술적 분석은 장기 상승 추세를 지지하나, 거시경제 리스크에 따른 단기 조정 가능성을 인정합니다. SentimentalAgent의 중립적 감성 데이터와 뉴스 부재는 단기 심리적 불확실성을 높입니다. 따라서 거시경제 긴축 기조와 실질금리 상승, 유동성 위축, 민감도 급등 신호를 반영하여 기존 예측 188.73 USD에서 약 2.5% 하향 조정한 183.5 USD로 수정합니다. 이는 금리, 인플레이션, 유동성 변수들의 하락 영향과 민감도 급등에 따른 불확실성 증가를 반영한 보수적 조정이며, 투자자들은 단기 변동성에 유의하며 신중한 접근이 필요합니다.'),\n",
              " 'SentimentalAgent': Opinion(agent_id='SentimentalAgent', target=Target(next_close=188.43819293198888, uncertainty=0.12645471096038818, confidence=0.8935949357161924), reason='현재 주가는 193.80이며, 모델은 다음 거래일 종가를 187.88로 약 3.05% 하락을 예측하고 있습니다. 그러나 최근 7일 및 30일간 감성 점수와 긍정·부정 기사 비율이 모두 0으로, 뉴스 데이터가 전혀 없어 시장 심리나 여론의 변화를 반영하지 못하고 있습니다. 감성 점수 변동성도 0으로 매우 안정적이며, Monte Carlo Dropout 기반 예측의 신뢰도는 높으나 표준편차가 0.1로 다소 불확실성이 존재합니다. 이러한 상황에서 과도한 하락 예측은 현실적이지 않으므로, 현재가 대비 약 1.5% 하락한 190.80으로 조정하는 것이 중립적이고 균형 잡힌 판단이라 판단됩니다.')}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "debate.get_rebuttal(2)\n",
        "debate.get_revise(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "macro = MacroAgent(ticker=TICKER)\n",
        "technical = TechnicalAgent(ticker=TICKER)\n",
        "sentimental = SentimentalAgent(ticker=TICKER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "■ TechnicalAgent StockData 생성 완료 (NVDA, USD)\n"
          ]
        }
      ],
      "source": [
        "data = technical.searcher()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[11:48:57] Pretraining TechnicalAgent\n",
            "  Epoch 005 | Loss: 0.381739\n",
            "  Epoch 010 | Loss: 0.382532\n",
            "  Epoch 015 | Loss: 0.381650\n",
            "  Epoch 020 | Loss: 0.386132\n",
            "  Epoch 025 | Loss: 0.386860\n",
            "  Epoch 030 | Loss: 0.383978\n",
            "  Epoch 035 | Loss: 0.386244\n",
            "  Epoch 040 | Loss: 0.383551\n",
            "  Epoch 045 | Loss: 0.395979\n",
            " TechnicalAgent 모델 학습 및 저장 완료: models/NVDA_TechnicalAgent.pt\n"
          ]
        }
      ],
      "source": [
        "technical.pretrain()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Target(next_close=190.63277158716582, uncertainty=0.0047906432300806046, confidence=0.9952435275386796)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "technical.predict(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "■ TechnicalAgent StockData 생성 완료 (NVDA, USD)\n",
            "■ TechnicalAgent StockData 생성 완료 (NVDA, USD)\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for +: 'int' and 'list'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtechnical\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreviewer_draft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/agents/technical_agent.py:918\u001b[0m, in \u001b[0;36mreviewer_draft\u001b[0;34m(self, stock_data, target)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;66;03m# 1) 데이터 수집\u001b[39;00m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stock_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 918\u001b[0m     stock_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstockdata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_id)\n\u001b[1;32m    920\u001b[0m \u001b[38;5;66;03m# 2) 예측값 생성\u001b[39;00m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/agents/technical_agent.py:540\u001b[0m, in \u001b[0;36m_build_messages_opinion\u001b[0;34m(self, stock_data, target)\u001b[0m\n\u001b[1;32m    537\u001b[0m \"\"\"TechnicalAgent용 LLM 프롬프트 메시지 구성 + 설명값 포함\"\"\"\n\u001b[1;32m    538\u001b[0m last = float(getattr(stock_data, \"last_price\", target.next_close))\n\u001b[0;32m--> 540\u001b[0m # 최신 윈도우 설명 산출\n\u001b[1;32m    541\u001b[0m X_last = self.searcher(self.ticker)\n\u001b[1;32m    542\u001b[0m if not isinstance(X_last, torch.Tensor):\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/agents/technical_agent.py:504\u001b[0m, in \u001b[0;36m_pack_idea\u001b[0;34m(exp, top_time, top_feat, coverage)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'list'"
          ]
        }
      ],
      "source": [
        "technical.reviewer_draft()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. DebateAgent 초기화\n",
        "\n",
        "세 가지 에이전트를 포함한 DebateAgent를 초기화합니다:\n",
        "- **TechnicalAgent**: 기술적 분석가\n",
        "- **MacroSentiAgent**: 거시경제 분석가  \n",
        "- **SentimentalAgent**: 센티멘탈 분석가\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "■ DebateAgent 초기화 중...\n",
            "============================================================\n",
            "\n",
            "✅ DebateAgent 초기화 완료\n",
            "   - 에이전트 수: 3\n",
            "   - 에이전트 목록: ['TechnicalAgent', 'MacroSentiAgent', 'SentimentalAgent']\n",
            "   - 토론 라운드: 2\n"
          ]
        }
      ],
      "source": [
        "# DebateAgent 초기화\n",
        "print(\"=\" * 60)\n",
        "print(\"■ DebateAgent 초기화 중...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "debate_agent = DebateAgent(rounds=ROUNDS, ticker=TICKER)\n",
        "\n",
        "print(f\"\\n✅ DebateAgent 초기화 완료\")\n",
        "print(f\"   - 에이전트 수: {len(debate_agent.agents)}\")\n",
        "print(f\"   - 에이전트 목록: {list(debate_agent.agents.keys())}\")\n",
        "print(f\"   - 토론 라운드: {debate_agent.rounds}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 데이터셋 준비 (선택적)\n",
        "\n",
        "데이터셋이 이미 존재하는 경우 이 단계를 건너뛸 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "■ 데이터셋 빌드 중...\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TechnicalAgent] X_seq: (982, 55, 13), y_seq: (982, 1)\n",
            "✅ NVDA TechnicalAgent dataset saved to CSV (982 samples, 13 features)\n",
            "[MacroSentiAgent] X_seq: (1222, 14, 13), y_seq: (1222, 1)\n",
            "✅ NVDA MacroSentiAgent dataset saved to CSV (1222 samples, 13 features)\n",
            "[SentimentalAgent] X_seq: (1196, 40, 8), y_seq: (1196, 1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[**********            20%                       ]  3 of 15 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NVDA SentimentalAgent dataset saved to CSV (1196 samples, 8 features)\n",
            "✅ NVDA TechnicalAgent dataset saved via technical_data_set\n",
            "[TRACE B] macro_dataset() start for NVDA\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  15 of 15 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[MacroSentimentAgent] Data shape: (1304, 90), Columns: 90\n",
            "[TRACE A] add_features() for self.data:            Open_CL=F  Open_DX-Y.NYB  Open_EURUSD=X    Open_GC=F  Open_HG=F  \\\n",
            "Date                                                                          \n",
            "2020-01-01        NaN            NaN       1.122083          NaN        NaN   \n",
            "2020-01-02  61.599998      96.480003       1.121894  1518.099976     2.8165   \n",
            "2020-01-03  61.180000      96.790001       1.117081  1530.099976     2.7935   \n",
            "2020-01-06  63.709999      96.900002       1.116246  1580.000000     2.7780   \n",
            "2020-01-07  62.910000      96.650002       1.119583  1558.300049     2.8010   \n",
            "...               ...            ...            ...          ...        ...   \n",
            "2024-12-24  69.559998     108.160004       1.040583  2613.000000     4.0525   \n",
            "2024-12-25        NaN            NaN       1.040258          NaN        NaN   \n",
            "2024-12-26  70.199997     108.169998       1.039955  2628.500000     4.0730   \n",
            "2024-12-27  69.680000     108.080002       1.042318  2617.699951     4.0615   \n",
            "2024-12-30  70.419998     108.010002       1.042938  2620.699951     4.0900   \n",
            "\n",
            "              Open_QQQ    Open_SPY  Open_USDJPY=X     Open_^DJI  Open_^FVX  \\\n",
            "Date                                                                         \n",
            "2020-01-01         NaN         NaN     108.680000           NaN        NaN   \n",
            "2020-01-02  214.399994  323.540009     108.713997  28638.970703      1.683   \n",
            "2020-01-03  213.300003  321.160004     108.540001  28553.330078      1.622   \n",
            "2020-01-06  212.500000  320.489990     107.999001  28465.500000      1.591   \n",
            "2020-01-07  215.639999  323.019989     108.411003  28639.179688      1.596   \n",
            "...                ...         ...            ...           ...        ...   \n",
            "2024-12-24  524.830017  596.059998     157.164993  42916.480469      4.452   \n",
            "2024-12-25         NaN         NaN     157.106995           NaN        NaN   \n",
            "2024-12-26  528.320007  599.500000     157.132996  43201.851562      4.484   \n",
            "2024-12-27  526.010010  597.539978     157.748001  43142.371094      4.447   \n",
            "2024-12-30  515.510010  587.890015     157.873001  42863.859375      4.408   \n",
            "\n",
            "            ...  Volume_QQQ  Volume_SPY  Volume_USDJPY=X  Volume_^DJI  \\\n",
            "Date        ...                                                         \n",
            "2020-01-01  ...         NaN         NaN              0.0          NaN   \n",
            "2020-01-02  ...  30969400.0  59151200.0              0.0  251820000.0   \n",
            "2020-01-03  ...  27518900.0  77709700.0              0.0  239590000.0   \n",
            "2020-01-06  ...  21655300.0  55653900.0              0.0  252760000.0   \n",
            "2020-01-07  ...  22139300.0  40496400.0              0.0  258900000.0   \n",
            "...         ...         ...         ...              ...          ...   \n",
            "2024-12-24  ...  17558200.0  33160100.0              0.0  230410000.0   \n",
            "2024-12-25  ...         NaN         NaN              0.0          NaN   \n",
            "2024-12-26  ...  19090500.0  41219100.0              0.0  270350000.0   \n",
            "2024-12-27  ...  33839600.0  64969300.0              0.0  376960000.0   \n",
            "2024-12-30  ...  34584000.0  56578800.0              0.0  383300000.0   \n",
            "\n",
            "            Volume_^FVX  Volume_^GSPC  Volume_^IRX  Volume_^IXIC  Volume_^TNX  \\\n",
            "Date                                                                            \n",
            "2020-01-01          NaN           NaN          NaN           NaN          NaN   \n",
            "2020-01-02          0.0  3.459930e+09          0.0  2.862700e+09          0.0   \n",
            "2020-01-03          0.0  3.484700e+09          0.0  2.586520e+09          0.0   \n",
            "2020-01-06          0.0  3.702460e+09          0.0  2.810450e+09          0.0   \n",
            "2020-01-07          0.0  3.435910e+09          0.0  2.381740e+09          0.0   \n",
            "...                 ...           ...          ...           ...          ...   \n",
            "2024-12-24          0.0  1.757720e+09          0.0  4.739190e+09          0.0   \n",
            "2024-12-25          NaN           NaN          NaN           NaN          NaN   \n",
            "2024-12-26          0.0  2.904530e+09          0.0  6.467910e+09          0.0   \n",
            "2024-12-27          0.0  3.159610e+09          0.0  7.765120e+09          0.0   \n",
            "2024-12-30          0.0  3.433250e+09          0.0  8.384090e+09          0.0   \n",
            "\n",
            "            Volume_^VIX  \n",
            "Date                     \n",
            "2020-01-01          NaN  \n",
            "2020-01-02          0.0  \n",
            "2020-01-03          0.0  \n",
            "2020-01-06          0.0  \n",
            "2020-01-07          0.0  \n",
            "...                 ...  \n",
            "2024-12-24          0.0  \n",
            "2024-12-25          NaN  \n",
            "2024-12-26          0.0  \n",
            "2024-12-27          0.0  \n",
            "2024-12-30          0.0  \n",
            "\n",
            "[1304 rows x 90 columns]\n",
            "[TRACE A] add_features() for NVDA columns: ['Open_CL=F', 'Open_DX-Y.NYB', 'Open_EURUSD=X', 'Open_GC=F', 'Open_HG=F', 'Open_QQQ', 'Open_SPY', 'Open_USDJPY=X', 'Open_^DJI', 'Open_^FVX', 'Open_^GSPC', 'Open_^IRX', 'Open_^IXIC', 'Open_^TNX', 'Open_^VIX']\n",
            "[MacroSentimentAgent] Saved data/processed/NVDA_MacroSentiAgent.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  101 of 101 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "저장 완료: (1259, 101) rows\n",
            "macro: 데이터셋 생성> NVDA\n",
            "[INFO] Removed all constant Volume columns matching patterns: ['Volume_^FVX', 'Volume_^IRX', 'Volume_^TNX', 'Volume_^VIX', 'Volume_DX-Y.NYB', 'Volume_EURUSD=X', 'Volume_USDJPY=X']\n",
            "[INFO] Remaining Volume columns: ['Volume_CL=F', 'Volume_GC=F', 'Volume_HG=F', 'Volume_QQQ', 'Volume_SPY', 'Volume_^DJI', 'Volume_^GSPC', 'Volume_^IXIC', 'Volume_CL=F_ret', 'Volume_GC=F_ret', 'Volume_HG=F_ret', 'Volume_QQQ_ret', 'Volume_SPY_ret', 'Volume_^DJI_ret', 'Volume_^GSPC_ret', 'Volume_^IXIC_ret']\n",
            "[INFO] 병합 후 데이터 shape: (1257, 271)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-16 10:19:22.576587: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step - loss: 0.1462 - val_loss: 0.0897\n",
            "Epoch 2/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.1333 - val_loss: 0.0908\n",
            "Epoch 3/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - loss: 0.1311 - val_loss: 0.1373\n",
            "Epoch 4/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - loss: 0.1292 - val_loss: 0.0837\n",
            "Epoch 5/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - loss: 0.1235 - val_loss: 0.0854\n",
            "Epoch 6/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.1264 - val_loss: 0.1048\n",
            "Epoch 7/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.1242 - val_loss: 0.0826\n",
            "Epoch 8/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.1221 - val_loss: 0.0822\n",
            "Epoch 9/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.1249 - val_loss: 0.0814\n",
            "Epoch 10/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.1210 - val_loss: 0.0818\n",
            "Epoch 11/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - loss: 0.1221 - val_loss: 0.0819\n",
            "Epoch 12/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - loss: 0.1205 - val_loss: 0.0881\n",
            "Epoch 13/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - loss: 0.1205 - val_loss: 0.0867\n",
            "Epoch 14/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.1195 - val_loss: 0.0797\n",
            "Epoch 15/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - loss: 0.1193 - val_loss: 0.0803\n",
            "Epoch 16/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.1174 - val_loss: 0.0827\n",
            "Epoch 17/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - loss: 0.1196 - val_loss: 0.0867\n",
            "Epoch 18/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.1200 - val_loss: 0.0876\n",
            "Epoch 19/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 0.1178 - val_loss: 0.0806\n",
            "Epoch 20/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - loss: 0.1176 - val_loss: 0.0828\n",
            "Epoch 21/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 0.1171 - val_loss: 0.0824\n",
            "Epoch 22/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - loss: 0.1177 - val_loss: 0.0823\n",
            "Epoch 23/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.1171 - val_loss: 0.0826\n",
            "Epoch 24/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - loss: 0.1150 - val_loss: 0.0827\n",
            "Epoch 25/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.1146 - val_loss: 0.0867\n",
            "Epoch 26/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - loss: 0.1155 - val_loss: 0.0822\n",
            "Epoch 27/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.1155 - val_loss: 0.0852\n",
            "Epoch 28/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - loss: 0.1132 - val_loss: 0.0859\n",
            "Epoch 29/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - loss: 0.1138 - val_loss: 0.0887\n",
            "Epoch 30/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.1126 - val_loss: 0.0875\n",
            "Epoch 31/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.1130 - val_loss: 0.0913\n",
            "Epoch 32/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - loss: 0.1133 - val_loss: 0.0906\n",
            "Epoch 33/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.1119 - val_loss: 0.0981\n",
            "Epoch 34/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.1112 - val_loss: 0.1000\n",
            "Epoch 35/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - loss: 0.1115 - val_loss: 0.1105\n",
            "Epoch 36/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.1114 - val_loss: 0.0993\n",
            "Epoch 37/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.1097 - val_loss: 0.0973\n",
            "Epoch 38/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.1079 - val_loss: 0.1005\n",
            "Epoch 39/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - loss: 0.1117 - val_loss: 0.1050\n",
            "Epoch 40/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 0.1106 - val_loss: 0.1006\n",
            "Epoch 41/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.1079 - val_loss: 0.1018\n",
            "Epoch 42/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.1104 - val_loss: 0.1029\n",
            "Epoch 43/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - loss: 0.1074 - val_loss: 0.1010\n",
            "Epoch 44/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 0.1075 - val_loss: 0.1028\n",
            "Epoch 45/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.1077 - val_loss: 0.1056\n",
            "Epoch 46/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.1074 - val_loss: 0.1003\n",
            "Epoch 47/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.1075 - val_loss: 0.1015\n",
            "Epoch 48/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - loss: 0.1059 - val_loss: 0.1079\n",
            "Epoch 49/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.1059 - val_loss: 0.1036\n",
            "Epoch 50/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.1046 - val_loss: 0.1039\n",
            "Epoch 51/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - loss: 0.1057 - val_loss: 0.1046\n",
            "Epoch 52/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - loss: 0.1039 - val_loss: 0.1043\n",
            "Epoch 53/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.1045 - val_loss: 0.1050\n",
            "Epoch 54/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - loss: 0.1042 - val_loss: 0.1013\n",
            "Epoch 55/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - loss: 0.1024 - val_loss: 0.1062\n",
            "Epoch 56/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.1029 - val_loss: 0.1032\n",
            "Epoch 57/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.1018 - val_loss: 0.1048\n",
            "Epoch 58/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.1003 - val_loss: 0.1086\n",
            "Epoch 59/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - loss: 0.1001 - val_loss: 0.1080\n",
            "Epoch 60/60\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.1010 - val_loss: 0.1077\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'models/NVDA_MacroSentiAgent.keras'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m■ 데이터셋 빌드 중...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mbuild_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTICKER\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ 데이터셋 빌드 완료\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/core/data_set.py:144\u001b[0m, in \u001b[0;36mbuild_dataset\u001b[0;34m(ticker, save_dir, agent_id, period, interval)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _HAS_MACRO \u001b[38;5;129;01mor\u001b[39;00m macro_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    141\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro_dataset 모듈을 찾을 수 없습니다. core/macro_classes 확인 필요 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetails=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_MACRO_IMPORT_ERROR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    143\u001b[0m         )\n\u001b[0;32m--> 144\u001b[0m     \u001b[43mmacro_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mticker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MacroSentiAgent dataset saved (macro_dataset 호출 via \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_MACRO_SRC\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# ---------- sentimental_agent ----------\u001b[39;00m\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/core/macro_classes/macro_funcs.py:21\u001b[0m, in \u001b[0;36mmacro_dataset\u001b[0;34m(ticker_name)\u001b[0m\n\u001b[1;32m     18\u001b[0m macro_data_agent\u001b[38;5;241m.\u001b[39mmake_close_price()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro: 데이터셋 생성> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mmacro_data_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_maker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro: 모델 생성> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/core/macro_classes/macro_class_dataset.py:284\u001b[0m, in \u001b[0;36mMacroAData.model_maker\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m y_test_inv \u001b[38;5;241m=\u001b[39m scaler_y\u001b[38;5;241m.\u001b[39minverse_transform(y_test)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# 전체 모델 저장\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m \u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m scaler_X\u001b[38;5;241m.\u001b[39mfeature_names_in_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_all\u001b[38;5;241m.\u001b[39mcolumns)    \u001b[38;5;66;03m#로드 시에도 feature_names_in_ 속성이 복원\u001b[39;00m\n\u001b[1;32m    286\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(scaler_X, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler_X_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/capstone/lib/python3.10/site-packages/keras/src/saving/saving_api.py:107\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, zipped, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m zipped \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m zipped:\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39msave_model(model, filepath, zipped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/capstone/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:141\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, weights_format, zipped)\u001b[0m\n\u001b[1;32m    139\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(zip_filepath\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    142\u001b[0m         _save_model_to_fileobj(model, f, weights_format)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/NVDA_MacroSentiAgent.keras'"
          ]
        }
      ],
      "source": [
        "# 데이터셋 빌드 (필요한 경우에만 실행)\n",
        "# 주석을 해제하여 실행하세요\n",
        "print(\"=\" * 60)\n",
        "print(\"■ 데이터셋 빌드 중...\")\n",
        "print(\"=\" * 60)\n",
        "build_dataset(TICKER)\n",
        "print(\"✅ 데이터셋 빌드 완료\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Round 0: 초기 의견 수집\n",
        "\n",
        "각 에이전트가 독립적으로 주식을 분석하고 예측합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "■ Round 0: 초기 의견 수집 시작\n",
            "============================================================\n",
            "[TechnicalAgent] searcher 실행\n",
            "⚙️ NVDA TechnicalAgent rebuild requested. Building dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TechnicalAgent] X_seq: (982, 55, 13), y_seq: (982, 1)\n",
            "✅ NVDA TechnicalAgent dataset saved to CSV (982 samples, 13 features)\n",
            "[MacroSentiAgent] X_seq: (1222, 14, 13), y_seq: (1222, 1)\n",
            "✅ NVDA MacroSentiAgent dataset saved to CSV (1222 samples, 13 features)\n",
            "[SentimentalAgent] X_seq: (1196, 40, 8), y_seq: (1196, 1)\n",
            "✅ NVDA SentimentalAgent dataset saved to CSV (1196 samples, 8 features)\n",
            "■ TechnicalAgent StockData 생성 완료 (NVDA, USD)\n",
            "[TechnicalAgent] pretrain 실행\n",
            "[10:28:38] Pretraining TechnicalAgent\n",
            "  Epoch 005 | Loss: 0.375417\n",
            "  Epoch 010 | Loss: 0.395027\n",
            "  Epoch 015 | Loss: 0.393638\n",
            "  Epoch 020 | Loss: 0.381625\n",
            "  Epoch 025 | Loss: 0.388605\n",
            "  Epoch 030 | Loss: 0.388451\n",
            "  Epoch 035 | Loss: 0.398935\n",
            "  Epoch 040 | Loss: 0.383987\n",
            "  Epoch 045 | Loss: 0.389688\n",
            " TechnicalAgent 모델 학습 및 저장 완료: models/NVDA_TechnicalAgent.pt\n",
            "[TechnicalAgent] predict 실행\n",
            "[TechnicalAgent] reviewer_draft 실행\n",
            "■ TechnicalAgent StockData 생성 완료 (NVDA, USD)\n",
            "  - TechnicalAgent: next_close=190.5389\n",
            "MacroSentiAgent의 데이터 로드.. macro_sercher\n",
            "[INFO] 모델 및 스케일러 로드 중...\n",
            "model_path: models/NVDA_MacroSentiAgent.keras\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "File not found: filepath=models/NVDA_MacroSentiAgent.keras. Please ensure the file is an accessible `.keras` zip file.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m■ Round 0: 초기 의견 수집 시작\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m opinions_0 \u001b[38;5;241m=\u001b[39m \u001b[43mdebate_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_opinion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mticker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTICKER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrebuild\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_pretrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Round 0 완료: 초기 의견 수집 결과\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/agents/debate_agent.py:69\u001b[0m, in \u001b[0;36mDebateAgent.get_opinion\u001b[0;34m(self, round, ticker, rebuild, force_pretrain)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m agent_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMacroSentiAgent\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m의 데이터 로드.. macro_sercher\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m     X, X_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mmacro_sercher\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mticker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m의 예측\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     72\u001b[0m     pred_prices, target \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mm_predictor(X)   \u001b[38;5;66;03m#macro_4_predictor(self, macro_sub, X_seq) 로 묶어둠\u001b[39;00m\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/core/macro_classes/macro_funcs.py:33\u001b[0m, in \u001b[0;36mmacro_sercher\u001b[0;34m(macro_agent, ticker_name)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmacro_sercher\u001b[39m(macro_agent, ticker_name):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# macro_agent = MacroPredictor(\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m#     agent_id='MacroSentiAgent',\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m#     ticker=ticker_name\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     \u001b[43mmacro_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_assets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m             \u001b[38;5;66;03m# 모델, 스케일러 등 불러오기\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     macro_agent\u001b[38;5;241m.\u001b[39mfetch_macro_data()          \u001b[38;5;66;03m# macro_df 불러오기\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     X_tensor, X_scaled \u001b[38;5;241m=\u001b[39m macro_agent\u001b[38;5;241m.\u001b[39mprepare_features()  \u001b[38;5;66;03m# 입력 시퀀스 준비\u001b[39;00m\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/agents/macro_agent.py:63\u001b[0m, in \u001b[0;36mMacroPredictor.load_assets\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] 모델 및 스케일러 로드 중...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler_X \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler_X_path)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler_y \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler_y_path)\n",
            "File \u001b[0;32m~/Projects/ml-ai/capstone/capstone/lib/python3.10/site-packages/keras/src/saving/saving_api.py:203\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[1;32m    197\u001b[0m         filepath,\n\u001b[1;32m    198\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    200\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    201\u001b[0m     )\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m     )\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmight have a different name).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    221\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: File not found: filepath=models/NVDA_MacroSentiAgent.keras. Please ensure the file is an accessible `.keras` zip file."
          ]
        }
      ],
      "source": [
        "# Round 0: 초기 의견 수집\n",
        "print(\"=\" * 60)\n",
        "print(\"■ Round 0: 초기 의견 수집 시작\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "opinions_0 = debate_agent.get_opinion(round=0, ticker=TICKER, rebuild=True, force_pretrain=False)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"✅ Round 0 완료: 초기 의견 수집 결과\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for agent_id, opinion in opinions_0.items():\n",
        "    if opinion and opinion.target:\n",
        "        print(f\"\\n[{agent_id}]\")\n",
        "        print(f\"  예측 종가: ${opinion.target.next_close:.2f}\")\n",
        "        print(f\"  불확실성(σ): {opinion.target.uncertainty:.6f}\" if opinion.target.uncertainty else \"  불확실성: N/A\")\n",
        "        print(f\"  신뢰도(β): {opinion.target.confidence:.4f}\" if opinion.target.confidence else \"  신뢰도: N/A\")\n",
        "        print(f\"  근거 요약: {opinion.reason[:100]}...\" if len(opinion.reason) > 100 else f\"  근거: {opinion.reason}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Round 1-N: 반박 및 의견 수정\n",
        "\n",
        "각 라운드마다:\n",
        "1. **Rebuttal**: 다른 에이전트의 의견에 대한 반박/지지\n",
        "2. **Revise**: 신뢰도 기반으로 자신의 의견 수정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Round 1-N: 반박 및 의견 수정\n",
        "for round_num in range(1, ROUNDS + 1):\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"■ Round {round_num}: 반박 및 의견 수정\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # 4-1. Rebuttal (반박)\n",
        "    print(f\"\\n[Round {round_num}-1] Rebuttal 수행 중...\")\n",
        "    rebuttals = debate_agent.get_rebuttal(round=round_num)\n",
        "    print(f\"✅ Rebuttal 완료: {len(rebuttals)}개의 반박 생성\")\n",
        "    \n",
        "    # 반박 내용 일부 출력\n",
        "    for rebuttal in rebuttals[:2]:  # 처음 2개만 출력\n",
        "        print(f\"\\n  [{rebuttal.from_agent_id} → {rebuttal.to_agent_id}]\")\n",
        "        print(f\"    스탠스: {rebuttal.stance}\")\n",
        "        print(f\"    메시지: {rebuttal.message[:150]}...\")\n",
        "    \n",
        "    # 4-2. Revise (의견 수정)\n",
        "    print(f\"\\n[Round {round_num}-2] Revise 수행 중...\")\n",
        "    revised_opinions = debate_agent.get_revise(round=round_num)\n",
        "    print(f\"✅ Revise 완료: {len(revised_opinions)}개 에이전트 의견 수정\")\n",
        "    \n",
        "    # 수정된 의견 출력\n",
        "    print(f\"\\n[Round {round_num}] 수정된 의견:\")\n",
        "    for agent_id, opinion in revised_opinions.items():\n",
        "        if opinion and opinion.target:\n",
        "            prev_opinion = debate_agent.opinions[round_num - 1][agent_id]\n",
        "            prev_price = prev_opinion.target.next_close if prev_opinion and prev_opinion.target else None\n",
        "            \n",
        "            change = opinion.target.next_close - prev_price if prev_price else 0\n",
        "            change_pct = (change / prev_price * 100) if prev_price else 0\n",
        "            \n",
        "            print(f\"\\n  [{agent_id}]\")\n",
        "            print(f\"    이전 예측: ${prev_price:.2f}\" if prev_price else \"    이전 예측: N/A\")\n",
        "            print(f\"    수정 예측: ${opinion.target.next_close:.2f}\")\n",
        "            print(f\"    변화: ${change:+.2f} ({change_pct:+.2f}%)\")\n",
        "            print(f\"    불확실성: {opinion.target.uncertainty:.6f}\" if opinion.target.uncertainty else \"    불확실성: N/A\")\n",
        "    \n",
        "    print(f\"\\n✅ Round {round_num} 토론 완료\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 최종 결과: Ensemble 예측\n",
        "\n",
        "모든 라운드가 완료된 후 최종 예측 결과를 확인합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 최종 결과: Ensemble 예측\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"■ 최종 결과: Ensemble 예측\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "ensemble_result = debate_agent.get_ensemble()\n",
        "\n",
        "print(\"\\n📊 최종 예측 결과:\")\n",
        "print(f\"  종목: {ensemble_result['ticker']}\")\n",
        "print(f\"  통화: {ensemble_result['currency']}\")\n",
        "print(f\"  현재가: ${ensemble_result['last_price']:.2f}\" if ensemble_result['last_price'] else \"  현재가: N/A\")\n",
        "print(f\"\\n  에이전트별 예측:\")\n",
        "for key, value in ensemble_result['agents'].items():\n",
        "    agent_name = key.replace('_next_close', '')\n",
        "    print(f\"    {agent_name}: ${value:.2f}\")\n",
        "\n",
        "print(f\"\\n  앙상블 예측:\")\n",
        "print(f\"    평균: ${ensemble_result['mean_next_close']:.2f}\" if ensemble_result['mean_next_close'] else \"    평균: N/A\")\n",
        "print(f\"    중앙값: ${ensemble_result['median_next_close']:.2f}\" if ensemble_result['median_next_close'] else \"    중앙값: N/A\")\n",
        "\n",
        "# 현재가와 비교\n",
        "if ensemble_result['last_price'] and ensemble_result['mean_next_close']:\n",
        "    current = ensemble_result['last_price']\n",
        "    predicted = ensemble_result['mean_next_close']\n",
        "    change = predicted - current\n",
        "    change_pct = (change / current) * 100\n",
        "    print(f\"\\n  예상 수익률:\")\n",
        "    print(f\"    절대 변화: ${change:+.2f}\")\n",
        "    print(f\"    상대 변화: {change_pct:+.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 라운드별 의견 변화 시각화\n",
        "\n",
        "각 라운드별로 에이전트의 예측이 어떻게 변화했는지 확인합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 라운드별 의견 변화 분석\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"■ 라운드별 의견 변화 분석\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 라운드별 의견 데이터 수집\n",
        "rounds_data = []\n",
        "for round_num in sorted(debate_agent.opinions.keys()):\n",
        "    opinions = debate_agent.opinions[round_num]\n",
        "    for agent_id, opinion in opinions.items():\n",
        "        if opinion and opinion.target:\n",
        "            rounds_data.append({\n",
        "                'Round': round_num,\n",
        "                'Agent': agent_id,\n",
        "                'Predicted_Price': opinion.target.next_close,\n",
        "                'Uncertainty': opinion.target.uncertainty or 0,\n",
        "                'Confidence': opinion.target.confidence or 0\n",
        "            })\n",
        "\n",
        "df_rounds = pd.DataFrame(rounds_data)\n",
        "\n",
        "if not df_rounds.empty:\n",
        "    # 라운드별 예측가 변화 시각화\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    \n",
        "    for agent_id in df_rounds['Agent'].unique():\n",
        "        agent_data = df_rounds[df_rounds['Agent'] == agent_id].sort_values('Round')\n",
        "        plt.plot(agent_data['Round'], agent_data['Predicted_Price'], \n",
        "                marker='o', label=agent_id, linewidth=2, markersize=8)\n",
        "    \n",
        "    plt.xlabel('Round', fontsize=12)\n",
        "    plt.ylabel('Predicted Price ($)', fontsize=12)\n",
        "    plt.title(f'Round별 예측가 변화 ({TICKER})', fontsize=14, fontweight='bold')\n",
        "    plt.legend(loc='best', fontsize=10)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # 테이블로도 출력\n",
        "    print(\"\\n📋 라운드별 예측가 변화 테이블:\")\n",
        "    pivot_table = df_rounds.pivot_table(\n",
        "        index='Agent', \n",
        "        columns='Round', \n",
        "        values='Predicted_Price',\n",
        "        aggfunc='first'\n",
        "    )\n",
        "    print(pivot_table.round(2))\n",
        "else:\n",
        "    print(\"데이터가 없습니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 간편 실행: run() 메서드 사용\n",
        "\n",
        "위의 단계를 한 번에 실행하려면 `run()` 메서드를 사용할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 간편 실행 (주석 해제하여 사용)\n",
        "# debate_agent_simple = DebateAgent(rounds=ROUNDS, ticker=TICKER)\n",
        "# debate_agent_simple.run()\n",
        "# print(debate_agent_simple.get_ensemble())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 전체 디베이트 실행 및 문제점 진단\n",
        "\n",
        "`run()` 메서드를 사용하여 전체 디베이트를 한 번에 실행하고 문제점을 진단합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 전체 디베이트 실행 및 문제점 진단\n",
        "import traceback\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"전체 디베이트 실행 시작\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"시작 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "\n",
        "# 새로운 DebateAgent 인스턴스 생성\n",
        "debate_full = DebateAgent(rounds=ROUNDS, ticker=TICKER)\n",
        "\n",
        "try:\n",
        "    print(\"1️⃣ run() 메서드 실행 중...\")\n",
        "    print(\"-\" * 80)\n",
        "    debate_full.run()\n",
        "    print(\"\\n✅ run() 메서드 완료!\")\n",
        "    \n",
        "    print(\"\\n2️⃣ 최종 결과 확인...\")\n",
        "    print(\"-\" * 80)\n",
        "    ensemble = debate_full.get_ensemble()\n",
        "    print(\"\\n📊 최종 Ensemble 결과:\")\n",
        "    for key, value in ensemble.items():\n",
        "        if isinstance(value, dict):\n",
        "            print(f\"  {key}:\")\n",
        "            for k, v in value.items():\n",
        "                print(f\"    {k}: {v}\")\n",
        "        else:\n",
        "            print(f\"  {key}: {value}\")\n",
        "            \n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ 오류 발생: {type(e).__name__}: {e}\")\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"스택 트레이스:\")\n",
        "    print(\"=\" * 80)\n",
        "    traceback.print_exc()\n",
        "    \n",
        "    # 현재 상태 확인\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"현재 상태 확인:\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"  opinions keys: {list(debate_full.opinions.keys())}\")\n",
        "    print(f\"  rebuttals keys: {list(debate_full.rebuttals.keys())}\")\n",
        "    if debate_full.opinions:\n",
        "        print(f\"  마지막 라운드: {max(debate_full.opinions.keys())}\")\n",
        "        last_round = max(debate_full.opinions.keys())\n",
        "        print(f\"  마지막 라운드 의견 수: {len(debate_full.opinions[last_round])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 완료\n",
        "\n",
        "전체 토론 시스템 테스트가 완료되었습니다! 🎉\n",
        "\n",
        "### 주요 결과 요약:\n",
        "- ✅ 3개 에이전트의 초기 의견 수집 완료\n",
        "- ✅ {ROUNDS}라운드의 반박 및 의견 수정 완료\n",
        "- ✅ 최종 앙상블 예측 생성 완료\n",
        "\n",
        "### 다음 단계:\n",
        "- 다른 종목으로 테스트해보기\n",
        "- 라운드 수를 조정하여 수렴 패턴 관찰\n",
        "- Streamlit 대시보드에서 인터랙티브하게 테스트\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "capstone",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
