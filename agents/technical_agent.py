import torch
import torch.nn as nn
import yfinance as yf
import pandas as pd
import os
from agents.base_agent import BaseAgent, StockData, Target, Opinion, Rebuttal
from config.agents import agents_info, dir_info
from agents.base_agent import r4 # ì•„ì—°ìˆ˜ì •
import json
from prompts import OPINION_PROMPTS, REBUTTAL_PROMPTS, REVISION_PROMPTS
import torch.nn as nn
from agents.base_agent import BaseAgent, StockData, Target, Opinion, Rebuttal
from config.agents import agents_info, dir_info
import json
from prompts import OPINION_PROMPTS, REBUTTAL_PROMPTS, REVISION_PROMPTS
from typing import List, Optional
import numpy as np
from agents.base_agent import r4, pct4  # ì•„ì—°ìˆ˜ì •



class TechnicalAgent(BaseAgent, nn.Module):
    """Technical Agent: BaseAgent + LSTMÃ—2 + time-attention"""
    def __init__(self,
        agent_id="TechnicalAgent",
        input_dim=agents_info["TechnicalAgent"]["input_dim"],
        rnn_units1=agents_info["TechnicalAgent"]["rnn_units1"], # 1ì¸µ hidden (ì•„ì—°ìˆ˜ì •)
        rnn_units2=agents_info["TechnicalAgent"]["rnn_units2"], # 2ì¸µ hidden (ì•„ì—°ìˆ˜ì •)
        dropout=agents_info["TechnicalAgent"]["dropout"],
        data_dir=dir_info["data_dir"],
        window_size=agents_info["TechnicalAgent"]["window_size"],
        epochs=agents_info["TechnicalAgent"]["epochs"],
        learning_rate=agents_info["TechnicalAgent"]["learning_rate"],
        batch_size=agents_info["TechnicalAgent"]["batch_size"],
        **kwargs
    ):
        BaseAgent.__init__(self, agent_id, **kwargs)
        nn.Module.__init__(self)


        # ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • (ì•„ì—°ìˆ˜ì •)
        self.input_dim = int(input_dim)
        self.u1         = int(rnn_units1)
        self.u2         = int(rnn_units2)
        self.window_size= int(window_size)
        self.epochs     = int(epochs)
        self.lr         = float(learning_rate)
        self.batch_size = int(batch_size)

        # LSTMx2 + time attention (ì•„ì—°ìˆ˜ì •)
        self.lstm1 = nn.LSTM(self.input_dim, self.u1, batch_first=True)
        self.lstm2 = nn.LSTM(self.u1, self.u2, batch_first=True)
        self.attn_vec = nn.Parameter(torch.randn(self.u2))
        self.fc = nn.Linear(self.u2, 1)
        self.drop = nn.Dropout(float(dropout))


        # Optimizer / Loss ì„¤ì •
        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.lr) # ì•„ì—°ìˆ˜ì • lr
        # ê¸°ì¡´: MSE Loss ì‚¬ìš©
        # self.loss_fn = nn.MSELoss()
        # ìˆ˜ì •: Huber Loss ì‚¬ìš© - ì´ìƒì¹˜ì— ëœ ë¯¼ê°í•˜ê³  ë” ì•ˆì •ì ì¸ í•™ìŠµ
        # delta=1.0ìœ¼ë¡œ ì¡°ì • (íƒ€ê²Ÿ ìŠ¤ì¼€ì¼ë§ í›„ ì ì ˆí•œ ê°’)
        self.loss_fn = nn.HuberLoss(delta=1.0)
        self.last_pred = None
        self.last_attn = None  # (ì•„ì—°ìˆ˜ì •) time-attention ìºì‹œ



    '''
    ìƒëµ(ì•„ì—°ìˆ˜ì •)
    def _build_model(self):
        """TechnicalAgent ê¸°ë³¸ GRU ëª¨ë¸ ìë™ ìƒì„±"""
        import torch.nn as nn
        import torch

        input_dim = getattr(self, "input_dim", 10)
        hidden_dim = getattr(self, "hidden_dim", 64)
        dropout_rate = getattr(self, "dropout_rate", 0.2)

        class GRUNet(nn.Module):
            def __init__(self, input_dim, hidden_dim, dropout_rate):
                super().__init__()
                self.gru = nn.GRU(input_dim, hidden_dim, batch_first=True, dropout=dropout_rate)
                self.dropout = nn.Dropout(dropout_rate)
                self.fc = nn.Sequential(
                    nn.Linear(hidden_dim, 1),
                    # nn.Tanh()  # ê¸°ì¡´: ì¶œë ¥ì„ -1~1ë¡œ ì œí•œ (ë¬¸ì œ ì›ì¸)
                    # ìˆ˜ì •: Tanh ì œê±°í•˜ì—¬ ì„ í˜• ì¶œë ¥ìœ¼ë¡œ ë³€ê²½ - ìƒìŠ¹/í•˜ë½ìœ¨ ì˜ˆì¸¡ì— ì í•©
                )

            def forward(self, x):
                out, _ = self.gru(x)          # out: (batch, seq, hidden)
                out = out[:, -1, :]           # ë§ˆì§€ë§‰ ì‹œì (hidden state)
                out = self.dropout(out)
                return self.fc(out)           # (batch, 1)

        model = GRUNet(input_dim, hidden_dim, dropout_rate)
        print(f"ğŸ§  GRU ëª¨ë¸ ìƒì„±ë¨ (input={input_dim}, hidden={hidden_dim}, dropout={dropout_rate})")
        return model
    '''

    # (ì•„ì—°ìˆ˜ì •) ê¸°ì¡´ GRU íŒ©í† ë¦¬ ìš°íšŒ ìš©ë„
    def _build_model(self):
        """TechnicalAgentìš© LSTMÃ—2 + time-attention ëª¨ë¸ ìƒì„±ê¸°"""
        return self  # ì´ë¯¸ __init__ì—ì„œ ëª¨ë¸ êµ¬ì„± ì™„ë£Œ


    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # LSTMÃ—2 + time-attentionì´ ìˆìœ¼ë©´ ì‚¬ìš© (ì•„ì—°ìˆ˜ì •)
        h1, _ = self.lstm1(x)
        h1 = self.drop(h1)
        h2, _ = self.lstm2(h1)
        h2 = self.drop(h2)

        w = torch.softmax(torch.matmul(h2, self.attn_vec), dim=1)  # [B,T]
        self._last_attn = w.detach()                               # ì•„ì—°ìˆ˜ì •
        ctx = (h2 * w.unsqueeze(-1)).sum(dim=1)                    # [B,u2]
        return self.fc(ctx)                                        # [B,1]


    # ì•„ì—°ìˆ˜ì •
    # ------------ ì„¤ëª… ìœ í‹¸ ------------
    @torch.no_grad()
    def time_attention_dict(self, dates: list) -> dict:
        """ì§ì „ forwardì˜ softmax ê°€ì¤‘ì¹˜(w)ë¥¼ ë‚ ì§œì™€ ë§¤í•‘."""
        attn = getattr(self, "_last_attn", None)          # [B,T]
        if attn is None:
            return {}
        a = attn[0].detach().cpu().tolist()

        # ë‚ ì§œ ê¸¸ì´ì™€ ë§ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ ì¸ë±ìŠ¤ ì‚¬ìš©
        if not dates or len(dates) != len(a):
            dates = [f"t-{len(a)-1-i}" for i in range(len(a))]
        return {str(d): float(w) for d, w in zip(dates, a)}

    def _time_feature_attrib_gradxinput(self, x: torch.Tensor, dates: list, top_k: int = 5) -> dict:
        """
        x: [1,T,F] ë‹¨ì¼ ë°°ì¹˜ ì…ë ¥. ë‚ ì§œ ê¸¸ì´=T.
        ë°˜í™˜: {date: {feature: score,...}}  (ìƒìœ„ top_k)
        """
        self.eval()
        with torch.enable_grad():
            x = x.clone().detach().requires_grad_(True)
            y = self(x).sum()
            self.zero_grad(set_to_none=True)
            y.backward()
            grads = x.grad.abs()    # [1, T, F]
            attn = getattr(self, "_last_attn", None)  # [1,T] or None
            contrib = grads * x.abs()    # [1,T,F]

        # attention ê°€ì¤‘ì¹˜ê°€ ìˆìœ¼ë©´ ê³±í•˜ê¸°
        if attn is not None:
            contrib = contrib * attn.detach().unsqueeze(-1)

        contrib = contrib[0].detach().cpu().numpy()        # [T,F]
        cols = list(getattr(self.stockdata, "feature_cols", []))[: self.input_dim] # ì•„ì—°ìˆ˜ì •
        if not dates or len(dates) != contrib.shape[0]: # ì•„ì—°ìˆ˜ì •
            dates = [f"t-{contrib.shape[0] - 1 - i}" for i in range(contrib.shape[0])]

        out = {}
        for t, d in enumerate(dates):
            pairs = sorted(
                zip(cols, contrib[t].tolist()), key=lambda z: z[1], reverse=True)[:top_k]
            out[str(d)] = {k: float(v) for k, v in pairs}
        return out

    def _safe_names(self, feature_cols, F):
        """
        ê¸°ëŠ¥: í”¼ì²˜ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ë¥¼ ëª¨ë¸ ì…ë ¥ ì°¨ì›(F)ì— ë§ì¶° ë³´ì •.
        ì…ë ¥: feature_cols(list|None), F(int)
        ì¶œë ¥: ê¸¸ì´ Fì˜ í”¼ì²˜ëª… ë¦¬ìŠ¤íŠ¸
        """
        cols = list(feature_cols) if feature_cols else []
        if len(cols) != F:
            cols = cols[:F] + [f"f{i}" for i in range(len(cols), F)]
        return cols

    def _safe_dates(self, dates, T):
        """
        ê¸°ëŠ¥: ë‚ ì§œ ë¦¬ìŠ¤íŠ¸ë¥¼ ìœˆë„ìš° ê¸¸ì´(T)ì— ë§ì¶° ë³´ì •.
        ì…ë ¥: dates(list|None), T(int)
        ì¶œë ¥: ê¸¸ì´ Tì˜ ë‚ ì§œ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸
        """
        if not dates or len(dates) != T:
            return [f"t-{T-1-i}" for i in range(T)]
        return [str(d) for d in dates]

    def _scale_like_train(self, X_np):
        """
        ê¸°ëŠ¥: í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ìŠ¤ì¼€ì¼ëŸ¬(self.scaler)ë¡œ ì…ë ¥ ìŠ¤ì¼€ì¼ ì •í•©.
        ì…ë ¥: X_np(np.ndarray) (1,T,F)
        ì¶œë ¥: ìŠ¤ì¼€ì¼ëœ np.ndarray (ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜)
        """
        try:
            out = self.scaler.transform(X_np)
            if isinstance(out, tuple) and len(out) >= 1:
                return out[0]
            return out
        except Exception:
            return X_np

    @torch.no_grad()
    def time_importance_from_attention(self, X_last: torch.Tensor) -> np.ndarray:
        """
        ê¸°ëŠ¥: ëª¨ë¸ì˜ time-attention ê°€ì¤‘ì¹˜ë¡œ ì‹œê°„ ì¤‘ìš”ë„ ê³„ì‚°.
        ì…ë ¥: X_last(torch.Tensor) (1,T,F)
        ì¶œë ¥: ì •ê·œí™”ëœ ì‹œê°„ ì¤‘ìš”ë„ np.ndarray (T,)
        ì£¼ì˜: forwardë¥¼ 1íšŒ í˜¸ì¶œí•´ _last_attn ìƒì„±.
        """
        self.eval()
        _ = self(X_last)
        attn = getattr(self, "_last_attn", None)  # [B,T]

        if attn is None:
            T = X_last.shape[1]
            return np.ones(T, dtype=float) / T
        w = attn[0].abs().cpu().numpy()
        s = w.sum()
        return w / s if s > 0 else np.ones_like(w) / len(w)

    def gradxinput_attrib(self, X_last: torch.Tensor, eps: float = 0.0):
        """
        ê¸°ëŠ¥: GradÃ—Inputìœ¼ë¡œ (ì‹œê°„, í”¼ì²˜) ê¸°ì—¬ë„ ì‚°ì¶œ.
        ì…ë ¥: X_last(torch.Tensor):(1,T,F), eps(float): ì…ë ¥ ë…¸ì´ì¦ˆ ì•ˆì •í™”
        ì¶œë ¥: (per_time(T,), per_feat(F,), gi(T,F)) ê° np.ndarray
        ì£¼ì˜: eval ëª¨ë“œ, y.sum()ì— ëŒ€í•´ ì—­ì „íŒŒ.
        """
        self.eval()
        x = X_last.clone().detach().to(next(self.parameters()).device)

        if eps > 0:
            x = x + eps * torch.randn_like(x)
        x.requires_grad_(True)
        y = self(x).sum()
        self.zero_grad(set_to_none=True)
        y.backward()
        gi = (x.grad * x).abs()[0].detach().cpu().numpy()  # (T,F)
        per_time = gi.sum(axis=1)
        per_feat = gi.mean(axis=0)
        return per_time, per_feat, gi

    @torch.no_grad()
    def occlusion_time(self, X_last: torch.Tensor, fill: str = "zero", batch: int = 32):
        """
        ê¸°ëŠ¥: í•œ ì‹œì ì”© ê°€ë ¤ Î”ì˜ˆì¸¡ìœ¼ë¡œ ì‹œê°„ ì¤‘ìš”ë„ ê³„ì‚°.
        ì…ë ¥: X_last(1,T,F), fill: 'zero' ë˜ëŠ” í‰ê· ì¹˜ ëŒ€ì²´, batch: ë°°ì¹˜ í¬ê¸°
        ì¶œë ¥: ì •ê·œí™”ëœ ì‹œê°„ ì¤‘ìš”ë„ np.ndarray (T,)
        ë³µì¡ë„: O(T) ì „í–¥ íŒ¨ìŠ¤(ë°°ì¹˜ ì²˜ë¦¬)
        """
        self.eval()
        base = float(self(X_last).item())
        _, T, F = X_last.shape
        Xs = []
        for t in range(T):
            x = X_last.clone()
            if fill == "zero":
                x[:, t, :] = 0
            else:
                x[:, t, :] = X_last.mean(dim=1, keepdim=True)[:, 0, :]
            Xs.append(x)
        deltas = []
        for i in range(0, T, batch):
            xb = torch.cat(Xs[i:i+batch], dim=0)
            yb = self(xb).flatten().cpu().numpy()
            deltas.extend(np.abs(yb - base).tolist())
        s = sum(deltas)
        return np.array([v/s if s > 0 else 1.0/T for v in deltas], dtype=float)

    @torch.no_grad()
    def occlusion_feature(self, X_last: torch.Tensor, fill: str = "zero", batch: int = 32):
        """
        ê¸°ëŠ¥: í•œ í”¼ì²˜ì”© ê°€ë ¤ Î”ì˜ˆì¸¡ìœ¼ë¡œ í”¼ì²˜ ì¤‘ìš”ë„ ê³„ì‚°.
        ì…ë ¥: X_last(1,T,F), fill: 'zero' ë˜ëŠ” í‰ê· ì¹˜ ëŒ€ì²´, batch: ë°°ì¹˜ í¬ê¸°
        ì¶œë ¥: ì •ê·œí™”ëœ í”¼ì²˜ ì¤‘ìš”ë„ np.ndarray (F,)
        ë³µì¡ë„: O(F) ì „í–¥ íŒ¨ìŠ¤(ë°°ì¹˜ ì²˜ë¦¬)
        """
        self.eval()
        base = float(self(X_last).item())
        _, T, F = X_last.shape
        Xs = []
        for f in range(F):
            x = X_last.clone()
            if fill == "zero":
                x[:, :, f] = 0
            else:
                x[:, :, f] = X_last.mean(dim=(1, 2), keepdim=True)[:, 0, 0]
            Xs.append(x)
        deltas = []
        for i in range(0, F, batch):
            xb = torch.cat(Xs[i:i+batch], dim=0)
            yb = self(xb).flatten().cpu().numpy()
            deltas.extend(np.abs(yb - base).tolist())
        s = sum(deltas)
        return np.array([v/s if s > 0 else 1.0/F for v in deltas], dtype=float)

    def explain_last(self, X_last: torch.Tensor, dates: list | None = None, top_k: int = 3):
        """
        ê¸°ëŠ¥: Attention + GradÃ—Input + Occlusion ìœµí•©ìœ¼ë¡œ ìµœì‹  ìœˆë„ìš° ì„¤ëª… íŒ¨í‚· ìƒì„±.
        ì…ë ¥: X_last(1,T,F), dates(list|None), top_k(int)
        ì²˜ë¦¬:
        1) í•™ìŠµ ìŠ¤ì¼€ì¼ ì •í•© â†’ í…ì„œí™”
        2) time-attention, GradÃ—Input, Occlusion ê³„ì‚°
        3) ì •ê·œí™”Â·ê°€ì¤‘ í‰ê· ìœ¼ë¡œ per_time/per_feature ì‚°ì¶œ
        4) ë‚ ì§œë³„ ìƒìœ„ í”¼ì²˜(top_k)ì™€ ì¦ê±° ë²¡í„°(evidence) í¬í•¨
        ì¶œë ¥: dict
        - per_time: [{date,sum_abs}]
        - per_feature: [{feature,sum_abs}]
        - time_attention: {date:weight}
        - time_feature: {date:{feat:score}}
        - evidence: ì›ì²œ ì§€í‘œë“¤(attention, gradxinput, occlusion)
        - raw: GradÃ—Input ì›ì‹œ(TÃ—F)
        """
        # 1) ìŠ¤ì¼€ì¼ ì •í•©
        device = next(self.parameters()).device
        X_np = X_last.detach().cpu().numpy()
        X_scaled = self._scale_like_train(X_np)
        Xs = torch.tensor(X_scaled, dtype=torch.float32, device=device)

        T, F = Xs.shape[1], Xs.shape[2]
        feat_cols_src = getattr(self.stockdata, "feature_cols", [])
        feat_names = self._safe_names(feat_cols_src, F)
        if dates is None:
            dates = getattr(self.stockdata, f"{self.agent_id}_dates", [])
        dates = self._safe_dates(dates, T)

        # 2) Attention
        time_attn = self.time_importance_from_attention(Xs)  # (T,)

        # 3) GradÃ—Input
        g_time, g_feat, gi_raw = self.gradxinput_attrib(Xs, eps=0.0)

        # 4) Occlusion
        occ_time = self.occlusion_time(Xs, fill="zero", batch=32)
        occ_feat = self.occlusion_feature(Xs, fill="zero", batch=32)

        # 5) ìœµí•© ìš”ì•½(ê°€ì¤‘ í‰ê· )
        g_time_n = g_time / (g_time.sum() + 1e-12)
        g_feat_n = g_feat / (g_feat.sum() + 1e-12)
        per_time = 0.5 * time_attn + 0.3 * g_time_n + 0.2 * occ_time
        occ_feat_n = occ_feat / (occ_feat.sum() + 1e-12)
        per_feat = 0.7 * g_feat_n + 0.3 * occ_feat_n

        # 6) ë‚ ì§œë³„ ìƒìœ„ í”¼ì²˜(GradÃ—Input ê¸°ì¤€)
        time_feature = {}
        gi_abs = np.abs(gi_raw)
        for t_idx, d in enumerate(dates):
            pairs = sorted(zip(feat_names, gi_abs[t_idx].tolist()), key=lambda z: z[1], reverse=True)[:top_k]
            time_feature[str(d)] = {k: float(v) for k, v in pairs}

        # 7) time-attention ë§µ
        time_attention = {str(d): r4(w) for d, w in zip(dates, time_attn.tolist())}

        # 8) íŒ¨í‚·
        per_time_list = [{"date": str(d), "sum_abs": r4(v)} for d, v in zip(dates, per_time.tolist())]
        per_feat_list = [{"feature": k, "sum_abs": r4(v)} for k, v in sorted(zip(feat_names, per_feat.tolist()),
                                                                          key=lambda z: z[1], reverse=True)]
        # ë‚ ì§œë³„ ìƒìœ„ í”¼ì²˜(GradÃ—Input ê¸°ì¤€, ë¼ìš´ë”©)
        time_feature = {}
        gi_abs = np.abs(gi_raw)
        for t_idx, d in enumerate(dates):
            pairs = sorted(zip(feat_names, gi_abs[t_idx].tolist()),
                       key=lambda z: z[1], reverse=True)[:top_k]
            time_feature[str(d)] = {k: r4(v) for k, v in pairs}

        evidence = {
            "attention": [r4(x) for x in time_attn.tolist()],
            "gradxinput_feat": [r4(x) for x in g_feat.tolist()],
            "occlusion_time": [r4(x) for x in occ_time.tolist()],
            "window_size": int(T),
            }

        return {
            "per_time": per_time_list,
            "per_feature": per_feat_list,
            "time_attention": time_attention,
            "time_feature": time_feature,
            "evidence": evidence,
            "raw": {"gradxinput": gi_abs.tolist()}  # ì›ì‹œê°’ì€ ë¹„ë¼ìš´ë”© ìœ ì§€ ê°€ëŠ¥
          }

    # idea í•µì‹¬ë§Œ
    def _pack_idea(exp: dict, top_time=8, top_feat=6, coverage=0.8):
        per_time = sorted(exp["per_time"], key=lambda z: z["sum_abs"], reverse=True)
        total = sum(z["sum_abs"] for z in per_time) or 1.0
        acc, picked = 0.0, []
        for z in per_time:
            acc += z["sum_abs"]
            picked.append({"date": z["date"], "weight": r4(z["sum_abs"]/total)})
            if acc/total >= coverage or len(picked) >= top_time:
                break

        per_feat = sorted(exp["per_feature"], key=lambda z: z["sum_abs"], reverse=True)[:top_feat]
        top_features = [{"feature": f["feature"], "weight": r4(f["sum_abs"])} for f in per_feat]

        attn = exp.get("evidence", {}).get("attention", [])
        peak = picked[0]["date"] if picked else None
        return {"top_time": picked, "top_features": top_features,
            "peak_date": peak, "window_size": exp.get("evidence",{}).get("window_size")}


   # LLM Reasoning ë©”ì‹œì§€ (ì•„ì—°ìˆ˜ì •)

    def _build_messages_opinion(self, stock_data, target):
        """TechnicalAgentìš© LLM í”„ë¡¬í”„íŠ¸ ë©”ì‹œì§€ êµ¬ì„± + ì„¤ëª…ê°’ í¬í•¨"""
        last = float(getattr(stock_data, "last_price", target.next_close))
        delta = (target.next_close / last) - 1.0

        # ìµœì‹  ìœˆë„ìš° ì„¤ëª… ì‚°ì¶œ
        X_last = self.searcher(self.ticker)
        if not isinstance(X_last, torch.Tensor):
          X_last = torch.tensor(X_last, dtype=torch.float32)
        T = X_last.shape[1]
        dates = getattr(self.stockdata, f"{self.agent_id}_dates", [])[-T:] or [f"t-{T-1-i}" for i in range(T)]
        exp = self.explain_last(X_last, dates, top_k=5) if not getattr(target, "idea", None) else None
        idea = target.idea if target.idea else _pack_idea(exp)
        target.idea = idea  # Targetì— ì €ì¥


        # ê¸°ë³¸ ì»¨í…ìŠ¤íŠ¸
        ctx = {
            "ticker": getattr(stock_data, "ticker", "Unknown"),
            "last_price": r4(last),
            "next_close": r4(target.next_close),
            "uncertainty": r4(target.uncertainty),
            "confidence": r4(target.confidence),
            "delta_pct": pct4(delta),
            "sigma": r4(target.uncertainty or 0.0),
            "beta": r4(target.confidence or 0.0),
            "window_size": int(self.window_size),
            "idea": idea,  # í•µì‹¬ë§Œ
        }



        from prompts import OPINION_PROMPTS

        system_text = OPINION_PROMPTS[self.agent_id]["system"]
        user_text = OPINION_PROMPTS[self.agent_id]["user"].format(
        context=json.dumps(ctx, ensure_ascii=False)
        )
        return system_text, user_text



    def _build_messages_rebuttal(self,
                                my_opinion: Opinion,
                                target_opinion: Opinion,
                                stock_data: StockData) -> tuple[str, str]:

        t = stock_data.ticker or "UNKNOWN"
        ccy = (stock_data.currency or "USD").upper()
        agent_data = getattr(stock_data, self.agent_id, None)
        if not agent_data or not isinstance(agent_data, dict):
            raise ValueError(f"{self.agent_id} ë°ì´í„° êµ¬ì¡° ì˜¤ë¥˜: dictí˜• ì»¬ëŸ¼ ë°ì´í„°ê°€ í•„ìš”í•¨")

        ctx = {
            "ticker": t,
            "currency": ccy,
            "data_summary": getattr(stock_data, self.agent_id, {}).get("feature_cols", []),
            "me": {
                "agent_id": self.agent_id,
                "next_close": float(my_opinion.target.next_close),
                "reason": str(my_opinion.reason)[:2000],
                "uncertainty": float(my_opinion.target.uncertainty),
                "confidence": float(my_opinion.target.confidence),
            },
            "other": {
                "agent_id": target_opinion.agent_id,
                "next_close": float(target_opinion.target.next_close),
                "reason": str(target_opinion.reason)[:2000],
                "uncertainty": float(target_opinion.target.uncertainty),
                "confidence": float(target_opinion.target.confidence),
            }
        }
        # ê° ì»¬ëŸ¼ë³„ ìµœê·¼ ì‹œê³„ì—´ ê·¸ëŒ€ë¡œ í¬í•¨
        # (ìµœê·¼ 7~14ì¼ ì •ë„ë©´ LLMì´ ì´í•´ ê°€ëŠ¥í•œ ë²”ìœ„)
        for col, values in agent_data.items():
            if isinstance(values, (list, tuple)):
                ctx[col] = values[self.window_size:]  # ìµœê·¼ 14ì¼ì¹˜ ì „ì²´ ì‹œê³„ì—´
            else:
                ctx[col] = [values]

        system_text = REBUTTAL_PROMPTS[self.agent_id]["system"]
        user_text   = REBUTTAL_PROMPTS[self.agent_id]["user"].format(
            context=json.dumps(ctx, ensure_ascii=False)
        )
        return system_text, user_text

    def _build_messages_revision(
        self,
        my_opinion: Opinion,
        others: List[Opinion],
        rebuttals: Optional[List[Rebuttal]] = None,
        stock_data: StockData = None,
    ) -> tuple[str, str]:
        """
        Revisionìš© LLM ë©”ì‹œì§€ ìƒì„±ê¸°
        - ë‚´ ì˜ê²¬(my_opinion), íƒ€ ì—ì´ì „íŠ¸ ì˜ê²¬(others), ì£¼ê°€ë°ì´í„°(stock_data) ê¸°ë°˜
        - rebuttals ì¤‘ ë‚˜(self.agent_id)ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•œ ë‚´ìš©ë§Œ í¬í•¨
        """
        # ê¸°ë³¸ ë©”íƒ€ë°ì´í„°
        t = getattr(stock_data, "ticker", "UNKNOWN")
        ccy = getattr(stock_data, "currency", "USD").upper()
        agent_data = getattr(stock_data, self.agent_id, None)
        if not agent_data or not isinstance(agent_data, dict):
            raise ValueError(f"{self.agent_id} ë°ì´í„° êµ¬ì¡° ì˜¤ë¥˜: dictí˜• ì»¬ëŸ¼ ë°ì´í„°ê°€ í•„ìš”í•¨")

        # íƒ€ ì—ì´ì „íŠ¸ ì˜ê²¬ ë° rebuttal í†µí•© ìš”ì•½
        others_summary = []
        for o in others:
            entry = {
                "agent_id": o.agent_id,
                "predicted_price": float(o.target.next_close),
                "confidence": float(o.target.confidence),
                "uncertainty": float(o.target.uncertainty),
                "reason": str(o.reason)[:500],
            }

            # ë‚˜ì—ê²Œ ì˜¨ rebuttalë§Œ stance/message ì¶”ì¶œ
            if rebuttals:
                related_rebuts = [
                    {"stance": r.stance, "message": r.message}
                    for r in rebuttals
                    if r.from_agent_id == o.agent_id and r.to_agent_id == self.agent_id
                ]
                if related_rebuts:
                    entry["rebuttals_to_me"] = related_rebuts

            others_summary.append(entry)

        # Context êµ¬ì„±
        ctx = {
            "ticker": t,
            "currency": ccy,
            "agent_type": self.agent_id,
            "my_opinion": {
                "predicted_price": float(my_opinion.target.next_close),
                "confidence": float(my_opinion.target.confidence),
                "uncertainty": float(my_opinion.target.uncertainty),
                "reason": str(my_opinion.reason)[:1000],
            },
            "others_summary": others_summary,
            "data_summary": getattr(stock_data, self.agent_id, {}).get("feature_cols", []),
        }

        # ìµœê·¼ ì‹œê³„ì—´ ë°ì´í„° í¬í•¨ (ê¸°ìˆ /ì‹¬ë¦¬ì  íŒ¨í„´)
        for col, values in agent_data.items():
            if isinstance(values, (list, tuple)):
                ctx[col] = values[-14:]  # ìµœê·¼ 14ì¼ì¹˜
            else:
                ctx[col] = [values]

        # Prompt êµ¬ì„±
        prompt_set = REVISION_PROMPTS.get(self.agent_id)
        system_text = prompt_set["system"]
        user_text = prompt_set["user"].format(context=json.dumps(ctx, ensure_ascii=False, indent=2))

        return system_text, user_text