# ===============================================================
# BaseAgent: LLM ê¸°ë°˜ ê³µí†µ ì¸í„°í˜ì´ìŠ¤
# ===============================================================
from __future__ import annotations
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Literal, Tuple, Any
from collections import defaultdict
import os, json, time, requests, yfinance as yf
from datetime import datetime
from dotenv import load_dotenv

from prompts import OPINION_PROMPTS, REBUTTAL_PROMPTS, REVISION_PROMPTS
from config.agents import agents_info, dir_info
from core.data_set import build_dataset, load_dataset

import torch
import numpy as np
from torch.utils.data import DataLoader, TensorDataset
from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler
import joblib


# ===============================================================
# ë°ì´í„° êµ¬ì¡° ì •ì˜
# ===============================================================

@dataclass
class Target:
    """ì˜ˆì¸¡ ëª©í‘œê°’ + ë¶ˆí™•ì‹¤ì„± ì •ë³´ í¬í•¨
    - next_close: ë‹¤ìŒ ê±°ë˜ì¼ ì¢…ê°€ ì˜ˆì¸¡ì¹˜
    - uncertainty: Monte Carlo Dropout ê¸°ë°˜ ì˜ˆì¸¡ í‘œì¤€í¸ì°¨(Ïƒ)
    - confidence: ëª¨ë¸ ì‹ ë¢°ë„ Î² (ì •ê·œí™”ëœ ì‹ ë¢°ë„; ì„ íƒì )
    """
    next_close: float
    uncertainty: Optional[float] = None
    confidence: Optional[float] = None


@dataclass
class Opinion:
    agent_id: str
    target: Target
    reason: str


@dataclass
class Rebuttal:
    from_agent_id: str
    to_agent_id: str
    stance: Literal["REBUT", "SUPPORT"]
    message: str


@dataclass
class RoundLog:
    round_no: int
    opinions: List[Opinion]
    rebuttals: List[Rebuttal]
    summary: Dict[str, Target]


@dataclass
class StockData:
    """ì—ì´ì „íŠ¸ ì…ë ¥ ì›ì²œ ë°ì´í„°(í•„ìš” ì‹œ ììœ  í™•ì¥)
    - SentimentalAgent: ì‹¬ë¦¬/ì»¤ë®¤ë‹ˆí‹°/ë‰´ìŠ¤ ìŠ¤ëƒ…ìƒ·
    - MacroSentiAgent : ê±°ì‹œ + ì‹¬ë¦¬ ìŠ¤ëƒ…ìƒ·
    - TechnicalAgent  : ê°€ê²©/ì§€í‘œ ìŠ¤ëƒ…ìƒ·
    - last_price      : ìµœì‹  ì¢…ê°€
    - currency        : í†µí™”ì½”ë“œ
    """
    SentimentalAgent: Optional[Dict[str, Any]] = field(default_factory=dict)
    MacroSentiAgent: Optional[Dict[str, Any]] = field(default_factory=dict)
    TechnicalAgent: Optional[Dict[str, Any]] = field(default_factory=dict)
    last_price: Optional[float] = None
    currency: Optional[str] = None
    ticker: Optional[str] = None
    snapshot: Optional[Dict[str, Any]] = field(default_factory=dict)
    meta: Optional[Dict[str, Any]] = field(default_factory=dict)
    raw_df: Optional[Any] = None 


# ===============================================================
# DataScaler: í•™ìŠµ/ì¶”ë¡ ìš© ìŠ¤ì¼€ì¼ëŸ¬ ìœ í‹¸ë¦¬í‹°
# ===============================================================
class DataScaler:
    """í•™ìŠµ/ì¶”ë¡ ìš© ì •ê·œí™” ìœ í‹¸ë¦¬í‹° (BaseAgent / TechnicalAgent ë“±ì—ì„œ ê³µí†µ ì‚¬ìš©)"""

    def __init__(self, agent_id: str):
        self.agent_id = agent_id
        self.save_dir = dir_info["scaler_dir"]

        info = agents_info.get(self.agent_id, {})
        # configì— ì—†ìœ¼ë©´ "None" ê¸°ë³¸ê°’
        self.x_scaler = info.get("x_scaler", "None")
        self.y_scaler = info.get("y_scaler", "None")

    # --------- í•™ìŠµìš© ---------
    def fit_scalers(self, X_train, y_train):
        ScalerMap = {
            "StandardScaler": StandardScaler,
            "MinMaxScaler": MinMaxScaler,
            "RobustScaler": RobustScaler,
            "None": None,
        }

        Sx = ScalerMap[self.x_scaler] if isinstance(self.x_scaler, str) else self.x_scaler
        Sy = ScalerMap[self.y_scaler] if isinstance(self.y_scaler, str) else self.y_scaler

        # 3D ì…ë ¥ (samples, seq_len, features) â†’ 2Dë¡œ ë³€í™˜
        n_samples, seq_len, n_feats = X_train.shape
        X_2d = X_train.reshape(-1, n_feats)

        self.x_scaler = (Sx().fit(X_2d) if isinstance(Sx, type) else Sx.fit(X_2d)) if Sx else None
        self.y_scaler = (
            Sy().fit(y_train.reshape(-1, 1)) if isinstance(Sy, type) else Sy.fit(y_train.reshape(-1, 1))
        ) if Sy else None

    def transform(self, X, y=None):
        # 3D ì…ë ¥ (samples, seq_len, features) â†’ 2Dë¡œ ë³€í™˜
        if X.ndim == 3:
            n_samples, seq_len, n_feats = X.shape
            X_2d = X.reshape(-1, n_feats)
            X_t = (
                self.x_scaler.transform(X_2d).reshape(n_samples, seq_len, n_feats)
                if self.x_scaler
                else X
            )
        else:
            X_t = self.x_scaler.transform(X) if self.x_scaler else X

        y_t = (
            self.y_scaler.transform(y.reshape(-1, 1)).flatten()
            if (self.y_scaler and y is not None)
            else y
        )
        return X_t, y_t
    
    # ğŸ”¹ ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
    def save(self, ticker: str, agent_id: str = "SentimentalAgent"):
        """
        í˜„ì¬ ìŠ¤ì¼€ì¼ëŸ¬ ê°ì²´(self)ë¥¼ models/scalers/{ticker}_{agent_id}.pkl ë¡œ ì €ì¥
        """
        model_dir = Path("models/scalers")
        model_dir.mkdir(parents=True, exist_ok=True)

        path = model_dir / f"{ticker}_{agent_id}.pkl"
        with open(path, "wb") as f:
            pickle.dump(self, f)
        print(f"[DataScaler.save] scaler saved to {path}")

    # ğŸ”¹ í´ë˜ìŠ¤ ë©”ì„œë“œ í˜•íƒœ ë¡œë“œ
    @classmethod
    def load(cls, ticker: str, agent_id: str = "SentimentalAgent"):
        """
        ì €ì¥ëœ ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ ë¡œë“œí•´ì„œ ë°˜í™˜.
        ì—†ìœ¼ë©´ None ë°˜í™˜.
        """
        model_dir = Path("models/scalers")
        path = model_dir / f"{ticker}_{agent_id}.pkl"

        if not path.exists():
            print(f"[DataScaler.load] no scaler file found: {path}")
            return None

        with open(path, "rb") as f:
            scaler = pickle.load(f)

        # íƒ€ì… ì²´í¬ (ì„ íƒ)
        if not isinstance(scaler, cls):
            print(f"[DataScaler.load] warning: loaded object is {type(scaler)}, expected {cls}")
        else:
            print(f"[DataScaler.load] scaler loaded from {path}")

        return scaler

    # ğŸ”¹ ì¸ìŠ¤í„´ìŠ¤ ë©”ì„œë“œ í˜•íƒœì˜ load (ì§€ê¸ˆ ì½”ë“œì™€ í˜¸í™˜ìš©)
    def load_for_agent(self, ticker: str, agent_id: str = "SentimentalAgent"):
        """
        self.load(...) ëŒ€ì‹  type(self).load(...) ë¥¼ ë¶€ë¥´ëŠ” helper.
        """
        return type(self).load(ticker, agent_id)
        
    # --------- ì—­ë³€í™˜/ì €ì¥ ---------
    def inverse_y(self, y_pred):
        if self.y_scaler and self.y_scaler != "None" and hasattr(self.y_scaler, "inverse_transform"):
            if isinstance(y_pred, (list, tuple)):
                y_pred = np.array(y_pred)
            return self.y_scaler.inverse_transform(np.asarray(y_pred).reshape(-1, 1)).flatten()
        return y_pred

    def _convert_uncertainty_to_confidence(self, sigma: float) -> float:
        """
        std(Ïƒ)ë¥¼ 0~1 ì‚¬ì´ confidenceë¡œ ë°”ê¿”ì£¼ëŠ” í—¬í¼.
        Ïƒê°€ ì‘ì„ìˆ˜ë¡ confidence â†‘
        """
        import numpy as np

        sigma = float(abs(sigma) or 1e-6)
        return float(1.0 / (1.0 + np.log1p(sigma)))

    def save(self, ticker: str):
        os.makedirs(self.save_dir, exist_ok=True)
        if self.x_scaler and self.x_scaler != "None":
            joblib.dump(
                self.x_scaler,
                os.path.join(self.save_dir, f"{ticker}_{self.agent_id}_xscaler.pkl"),
            )
        if self.y_scaler and self.y_scaler != "None":
            joblib.dump(
                self.y_scaler,
                os.path.join(self.save_dir, f"{ticker}_{self.agent_id}_yscaler.pkl"),
            )

    def load(self, ticker: str):
        x_path = os.path.join(self.save_dir, f"{ticker}_{self.agent_id}_xscaler.pkl")
        y_path = os.path.join(self.save_dir, f"{ticker}_{self.agent_id}_yscaler.pkl")
        if os.path.exists(x_path):
            self.x_scaler = joblib.load(x_path)
        if os.path.exists(y_path):
            self.y_scaler = joblib.load(y_path)


# ===============================================================
# BaseAgent í´ë˜ìŠ¤
# ===============================================================
class BaseAgent:
    """LLM ê¸°ë°˜ Multi-Agent Debate ê³µí†µ í´ë˜ìŠ¤"""

    OPENAI_URL = "https://api.openai.com/v1/responses"

    def __init__(
        self,
        agent_id: str,
        model: Optional[str] = None,
        preferred_models: Optional[List[str]] = None,
        temperature: float = 0.2,
        verbose: bool = False,
        need_training: bool = True,
        data_dir: str = dir_info["data_dir"],
        model_dir: str = dir_info["model_dir"],
        ticker: str | None = None,
        gamma: float = 0.3,
        delta_limit: float = 0.05,
    ):
        load_dotenv()

        self.agent_id = agent_id
        self.model = None  # torch.nn.Module ë˜ëŠ” ì—ì´ì „íŠ¸ë³„ ëª¨ë¸
        self.temperature = temperature
        self.verbose = verbose
        self.need_training = need_training
        self.data_dir = data_dir
        self.model_dir = model_dir
        self.ticker = ticker

        # ìŠ¤ì¼€ì¼ëŸ¬ (agentë³„ë¡œ configì—ì„œ x_scaler / y_scaler ì§€ì •)
        self.scaler: DataScaler | None = DataScaler(agent_id)

        # ìœˆë„ìš°/ìˆ˜ë ´ìœ¨/ì´ë™í•œê³„ëŠ” config ìš°ì„ 
        info = agents_info.get(agent_id, {})
        self.window_size = info.get("window_size", 40)
        self.gamma = info.get("gamma", gamma)
        self.delta_limit = info.get("delta_limit", delta_limit)

        # ëª¨ë¸ í´ë°± ìš°ì„ ìˆœìœ„
        self.preferred_models = preferred_models or ["gpt-5-mini", "gpt-4.1-mini"]
        if model:
            self.preferred_models = [model] + [m for m in self.preferred_models if m != model]

        # API í‚¤
        self.api_key = os.getenv("CAPSTONE_OPENAI_API") or ""
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }

        # ìƒíƒœê°’
        self.stockdata: Optional[StockData] = None
        self.targets: List[Target] = []
        self.opinions: List[Opinion] = []
        self.rebuttals: Dict[int, List[Rebuttal]] = defaultdict(list)

        # JSON Schema (Opinion/Rebuttal)
        self.schema_obj_opinion = {
            "type": "object",
            "properties": {
                "next_close": {"type": "number"},
                "reason": {"type": "string"},
            },
            "required": ["next_close", "reason"],
            "additionalProperties": False,
        }
        self.schema_obj_rebuttal = {
            "type": "object",
            "properties": {
                "stance": {"type": "string", "enum": ["REBUT", "SUPPORT"]},
                "message": {"type": "string"},
            },
            "required": ["stance", "message"],
            "additionalProperties": False,
        }

    # -----------------------------------------------------------
    # ë°ì´í„° ê²€ìƒ‰ (ë°ì´í„°ì…‹ ë¡œë“œ + StockData ìŠ¤ëƒ…ìƒ· êµ¬ì„±)
    # -----------------------------------------------------------
    def searcher(self, ticker: Optional[str] = None, rebuild: bool = False):
        import pandas as pd

        agent_id = self.agent_id
        if ticker is None:
            ticker = self.ticker
        self.ticker = ticker

        dataset_path = os.path.join(self.data_dir, f"{ticker}_{agent_id}_dataset.csv")

        # ë°ì´í„°ì…‹ì´ ì—†ìœ¼ë©´ ìë™ ìƒì„±
        if not os.path.exists(dataset_path) or rebuild:
            print(f"âš™ï¸ {ticker} {agent_id} dataset not found. Building new dataset...")
            build_dataset(ticker=ticker, save_dir=self.data_dir)

        # CSV ë¡œë“œ
        X, y, feature_cols = load_dataset(ticker, agent_id=agent_id, save_dir=self.data_dir)

        # StockData ì´ˆê¸°í™”
        if self.stockdata is None:
            self.stockdata = StockData()
        sd = self.stockdata

        # ìµœê·¼ window
        X_latest = X[-1:]
        X_tensor = torch.tensor(X_latest, dtype=torch.float32)

        # DataFrame ë³€í™˜
        df_latest = pd.DataFrame(X_latest[0], columns=feature_cols)
        feature_dict = {col: df_latest[col].tolist() for col in df_latest.columns}
        setattr(sd, agent_id, feature_dict)

        # ì¢…ê°€ ë° í†µí™”
        sd.ticker = ticker
        try:
            data = yf.download(ticker, period="1d", interval="1d", auto_adjust=False, progress=False)
            val = data["Close"].iloc[-1]
            sd.last_price = float(val.item() if hasattr(val, "item") else val)
        except Exception:
            print("yfinance ì˜¤ë¥˜ ë°œìƒ (last_price)")

        try:
            sd.currency = yf.Ticker(ticker).info.get("currency", "USD")
        except Exception as e:
            print(f"yfinance ì˜¤ë¥˜ ë°œìƒ, í†µí™” ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
            sd.currency = "USD"

        print(f"â–  {agent_id} StockData ìƒì„± ì™„ë£Œ ({ticker}, {sd.currency})")
        return X_tensor

    # -----------------------------------------------------------
    # current_price ì¶”ë¡  ìœ í‹¸
    # -----------------------------------------------------------
    def _infer_current_price(self, X, X_arr, explicit_current_price=None) -> float:
        """
        current_priceê°€ Noneì¼ ë•Œ, StockData / snapshot / ë°°ì—´ì—ì„œ ìµœëŒ€í•œ ì¶”ë¡ .
        ì‹¤íŒ¨í•˜ë©´ RuntimeError ë˜ì§.
        """
        if explicit_current_price is not None:
            return float(explicit_current_price)

        sd = None
        try:
            from agents.base_agent import StockData as _SD
        except Exception:
            _SD = object

        if isinstance(X, _SD):
            sd = X
        elif hasattr(self, "stockdata"):
            sd = getattr(self, "stockdata", None)

        # snapshot/meta ì‚¬ìš©
        if sd is not None:
            snap = getattr(sd, "snapshot", None) or getattr(sd, "meta", None) or {}
            if isinstance(snap, dict):
                for key in ("last_price", "current_price", "close", "adj_close"):
                    v = snap.get(key)
                    if v is not None:
                        try:
                            return float(v)
                        except Exception:
                            pass

        # ë°°ì—´ì—ì„œ ì¶”ë¡ 
        import numpy as _np

        if X_arr is not None and _np.ndim(X_arr) >= 2:
            last_step = X_arr[-1]
            if _np.ndim(last_step) == 2:
                last_step = last_step[-1]
            try:
                return float(last_step[-1])
            except Exception:
                pass

        raise RuntimeError(
            "[BaseAgent.predict] current_priceë¥¼ ìë™ìœ¼ë¡œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n"
            "- StockData.snapshot ë˜ëŠ” StockData.metaì— 'last_price'/'current_price'ë¥¼ ë„£ê±°ë‚˜,\n"
            "- predict(X, current_price=...) ë¡œ ì§ì ‘ ì „ë‹¬í•´ ì£¼ì„¸ìš”."
        )

    # -----------------------------------------------------------
    # Monte Carlo Dropout ê¸°ë°˜ ì˜ˆì¸¡ (ê³µí†µ)
    # -----------------------------------------------------------
    def predict(self, X, n_samples: int = 30, current_price: float | None = None) -> Target:
        """
        Monte Carlo Dropout ê¸°ë°˜ ì˜ˆì¸¡ + ë¶ˆí™•ì‹¤ì„±(Ïƒ) ë° confidence ê³„ì‚° (ì•ˆì •í˜•)

        ê¸°ë³¸ê°’:
        - ëª¨ë¸ì´ "ë‹¤ìŒë‚  ìˆ˜ìµë¥ (return)"ì„ ì˜ˆì¸¡í•œë‹¤ê³  ê°€ì •í•˜ê³ 
          current_price * (1 + return) ìœ¼ë¡œ ì¢…ê°€ë¥¼ ë³µì›.
        - ì—ì´ì „íŠ¸ê°€ decode_prediction(y_pred_raw, stock_data, current_price)
          ë¥¼ êµ¬í˜„í–ˆë‹¤ë©´ ê·¸ ë¡œì§ì„ ìš°ì„  ì‚¬ìš©.
        """
        import numpy as _np
        import torch as _torch

        X_original = X

        # StockData â†’ ë‚´ë¶€ ë°°ì—´ë¡œ ë³€í™˜
        try:
            from agents.base_agent import StockData as _SD
        except Exception:
            _SD = None

        if _SD is not None and isinstance(X, _SD):
            X_arr = None
            for name in ["X", "x", "X_seq", "data", "inputs"]:
                if hasattr(X, name):
                    X_arr = getattr(X, name)
                    break
            if X_arr is None and hasattr(X, "__dict__"):
                for name, val in X.__dict__.items():
                    if isinstance(val, (np.ndarray, torch.Tensor)):
                        X_arr = val
                        break
            if X_arr is None:
                raise AttributeError(
                    "StockData ì•ˆì—ì„œ ì…ë ¥ ë°°ì—´(np.ndarray/torch.Tensor) í•„ë“œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                )
            X = X_arr

        # numpy / tensor ì •ê·œí™”
        if isinstance(X, _torch.Tensor):
            X_tensor = X.float()
        else:
            X_np = _np.asarray(X, dtype=_np.float32)
            X_tensor = _torch.from_numpy(X_np)

        # [T, F] â†’ [1, T, F]
        if X_tensor.dim() == 2:
            X_tensor = X_tensor.unsqueeze(0)

        # ëª¨ë¸ ì¤€ë¹„
        if not hasattr(self, "model") or self.model is None:
            # í•„ìš”í•œ ê²½ìš° ì—¬ê¸°ì„œ self.pretrain() ë˜ëŠ” load_model() í˜¸ì¶œí•´ë„ ë¨
            raise RuntimeError(f"{self.agent_id} ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        device = next(self.model.parameters()).device
        X_tensor = X_tensor.to(device)

        # Monte Carlo Dropout
        self.model.train()
        preds = []
        with _torch.no_grad():
            for _ in range(n_samples):
                out = self.model(X_tensor)
                if isinstance(out, (tuple, list)):
                    out = out[0]
                preds.append(out.detach().cpu().numpy())

        preds_arr = _np.stack(preds, axis=0)  # [S, B, D]
        mean_pred = preds_arr.mean(axis=0).squeeze()
        std_pred = preds_arr.std(axis=0).squeeze()

        # Ïƒ, confidence
        if _np.ndim(std_pred) > 0:
            sigma = float(std_pred[-1])
        else:
            sigma = float(std_pred)
        confidence = float(1.0 / (1.0 + sigma))

        # current_price ì¶”ë¡ 
        X_arr_for_price = X_tensor.detach().cpu().numpy()
        current_price_val = self._infer_current_price(
            X_original,
            X_arr_for_price,
            explicit_current_price=current_price,
        )

        mean_pred = _np.asarray(mean_pred)

        # decode_predictionì´ ìˆìœ¼ë©´ ì‚¬ìš©
        if hasattr(self, "decode_prediction"):
            next_close = float(
                self.decode_prediction(
                    mean_pred,
                    stock_data=getattr(self, "stockdata", None),
                    current_price=current_price_val,
                )
            )
        else:
            # ê¸°ë³¸: return â†’ price
            if mean_pred.ndim == 0:
                predicted_return = float(mean_pred)
            else:
                predicted_return = float(mean_pred[-1])
            next_close = float(current_price_val * (1.0 + predicted_return))

        # uncertainty ì •ë¦¬
        if std_pred is not None:
            std_pred = _np.asarray(std_pred)
            if std_pred.ndim == 0:
                uncertainty = float(std_pred)
            else:
                uncertainty = float(std_pred[-1])
        else:
            uncertainty = None

        target = Target(
            next_close=next_close,
            uncertainty=uncertainty,
            confidence=confidence,
        )
        self.targets.append(target)
        return target

    # -----------------------------------------------------------
    # ë©”ì¸ ì›Œí¬í”Œë¡œ (Opinion / Rebuttal / Revision)
    # -----------------------------------------------------------
    def reviewer_draft(self, stock_data=None, target: Target | None = None) -> Opinion:
        # 1) StockData í™•ë³´
        if stock_data is None:
            sd = getattr(self, "stockdata", None)
            if sd is None:
                raise RuntimeError(
                    f"[{self.agent_id}] stockdataê°€ None ì…ë‹ˆë‹¤. "
                    "ë¨¼ì € run_dataset()/searcher() ë“±ì„ í˜¸ì¶œí•˜ì„¸ìš”."
                )
            if isinstance(sd, dict):
                stock_data = sd.get(self.agent_id, None)
            else:
                stock_data = sd

            if stock_data is None:
                raise RuntimeError(
                    f"[{self.agent_id}] stockdataì—ì„œ ìœ íš¨í•œ StockDataë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                )

        # 2) ì˜ˆì¸¡ê°’ ìƒì„±
        if target is None:
            target = self.predict(stock_data)

        # 3) LLM í˜¸ì¶œ(reason ìƒì„±)
        sys_text, user_text = self._build_messages_opinion(self.stockdata, target)
        parsed = self._ask_with_fallback(
            self._msg("system", sys_text),
            self._msg("user", user_text),
            {
                "type": "object",
                "properties": {"reason": {"type": "string"}},
                "required": ["reason"],
                "additionalProperties": False,
            },
        )
        reason = parsed.get("reason", "(ì‚¬ìœ  ìƒì„± ì‹¤íŒ¨)")

        op = Opinion(agent_id=self.agent_id, target=target, reason=reason)
        self.opinions.append(op)
        return op

    def reviewer_rebut(self, my_opinion: Opinion, other_opinion: Opinion, round: int) -> Rebuttal:
        sys_text, user_text = self._build_messages_rebuttal(
            my_opinion=my_opinion,
            target_opinion=other_opinion,
            stock_data=self.stockdata,
        )
        parsed = self._ask_with_fallback(
            self._msg("system", sys_text),
            self._msg("user", user_text),
            self.schema_obj_rebuttal,
        )

        result = Rebuttal(
            from_agent_id=my_opinion.agent_id,
            to_agent_id=other_opinion.agent_id,
            stance=parsed.get("stance", "REBUT"),
            message=parsed.get("message", "(ë°˜ë°•/ì§€ì§€ ì‚¬ìœ  ìƒì„± ì‹¤íŒ¨)"),
        )
        self.rebuttals[round].append(result)

        if self.verbose:
            print(
                f"[{self.agent_id}] rebuttal ìƒì„± â†’ {result.stance} "
                f"({my_opinion.agent_id} â†’ {other_opinion.agent_id})"
            )
        return result

    def reviewer_revise(
        self,
        my_opinion: Opinion,
        others: List[Opinion],
        rebuttals: List[Rebuttal],
        stock_data: StockData,
        fine_tune: bool = True,
        lr: float = 1e-4,
        epochs: int = 20,
    ) -> Opinion:
        """
        Revision ë‹¨ê³„
        - Ïƒ ê¸°ë°˜ Î²-weighted ì‹ ë¢°ë„ ê³„ì‚°
        - Î³ ìˆ˜ë ´ìœ¨ë¡œ ì˜ˆì¸¡ê°’ ë³´ì •
        - fine-tuning (return ë‹¨ìœ„, ì„ íƒ)
        - reasoning ìƒì„±
        """
        gamma = getattr(self, "gamma", 0.3)
        delta_limit = getattr(self, "delta_limit", 0.05)

        # â‘  ìˆ˜ë ´ ì—…ë°ì´íŠ¸
        try:
            my_price = my_opinion.target.next_close
            my_sigma = abs(my_opinion.target.uncertainty or 1e-6)

            other_prices = np.array([o.target.next_close for o in others])
            other_sigmas = np.array([abs(o.target.uncertainty or 1e-6) for o in others])

            all_sigmas = np.concatenate([[my_sigma], other_sigmas])
            all_prices = np.concatenate([[my_price], other_prices])

            inv_sigmas = 1 / (all_sigmas + 1e-6)
            betas = inv_sigmas / inv_sigmas.sum()

            delta = np.sum(betas[1:] * (other_prices - my_price))
            revised_price = my_price + gamma * delta

            current_price = getattr(self.stockdata, "last_price", 100.0)
            up = current_price * (1 + delta_limit)
            down = current_price * (1 - delta_limit)
            revised_price = float(np.clip(revised_price, down, up))
        except Exception as e:
            print(f"[{self.agent_id}] revised_target ê³„ì‚° ì‹¤íŒ¨: {e}")
            revised_price = my_opinion.target.next_close

        # â‘¡ Fine-tuning (ì„ íƒ)
        loss_value = None
        if fine_tune and hasattr(self, "model") and self.model is not None:
            try:
                current_price = getattr(self.stockdata, "last_price", 100.0)
                revised_return = (revised_price / current_price) - 1

                X_input = self.searcher(self.ticker)
                device = next(self.model.parameters()).device
                X_tensor = torch.tensor(X_input, dtype=torch.float32).to(device)
                y_tensor = torch.tensor([[revised_return]], dtype=torch.float32).to(device)

                self.model.train()
                optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)
                criterion = torch.nn.MSELoss()

                for _ in range(epochs):
                    optimizer.zero_grad()
                    pred = self.model(X_tensor)
                    loss = criterion(pred, y_tensor)
                    loss.backward()
                    optimizer.step()

                loss_value = float(loss.item())
                print(f"[{self.agent_id}] fine-tuning ì™„ë£Œ: loss={loss_value:.6f}")
            except Exception as e:
                print(f"[{self.agent_id}] fine-tuning ì‹¤íŒ¨: {e}")

        # â‘¢ fine-tuning ì´í›„ ìƒˆ ì˜ˆì¸¡
        try:
            X_latest = self.searcher(self.ticker)
            new_target = self.predict(X_latest)
        except Exception as e:
            print(f"[{self.agent_id}] predict ì‹¤íŒ¨: {e}")
            new_target = my_opinion.target

        # â‘£ reasoning ìƒì„±
        try:
            sys_text, user_text = self._build_messages_revision(
                my_opinion=my_opinion,
                others=others,
                rebuttals=rebuttals,
                stock_data=stock_data,
            )
        except Exception as e:
            print(f"[{self.agent_id}] _build_messages_revision ì‹¤íŒ¨: {e}")
            sys_text, user_text = (
                "ë„ˆëŠ” ê¸ˆìœµ ë¶„ì„ê°€ë‹¤. ê°„ë‹¨íˆ reasonë§Œ ìƒì„±í•˜ë¼.",
                json.dumps({"reason": "ê¸°ë³¸ ë©”ì‹œì§€ ìƒì„± ì‹¤íŒ¨"}),
            )

        parsed = self._ask_with_fallback(
            self._msg("system", sys_text),
            self._msg("user", user_text),
            {
                "type": "object",
                "properties": {"reason": {"type": "string"}},
                "required": ["reason"],
                "additionalProperties": False,
            },
        )
        revised_reason = parsed.get("reason", "(ìˆ˜ì • ì‚¬ìœ  ìƒì„± ì‹¤íŒ¨)")

        revised_opinion = Opinion(
            agent_id=self.agent_id,
            target=new_target,
            reason=revised_reason,
        )
        self.opinions.append(revised_opinion)
        print(
            f"[{self.agent_id}] revise ì™„ë£Œ â†’ new_close={new_target.next_close:.2f}, "
            f"loss={loss_value}"
        )
        return revised_opinion

    # -----------------------------------------------------------
    # ì—ì´ì „íŠ¸ë³„ êµ¬í˜„ì´ í•„ìš”í•œ ë©”ì„œë“œ (í”„ë¡¬í”„íŠ¸ ë¹Œë”)
    # -----------------------------------------------------------
    def _build_messages_opinion(self, stock_data: StockData, target: Target) -> Tuple[str, str]:
        raise NotImplementedError(
            f"{self.__class__.__name__} must implement _build_messages_opinion method"
        )

    def _build_messages_rebuttal(self, *args, **kwargs) -> Tuple[str, str]:
        raise NotImplementedError(
            f"{self.__class__.__name__} must implement _build_messages_rebuttal method"
        )

    def _build_messages_revision(self, *args, **kwargs) -> Tuple[str, str]:
        raise NotImplementedError(
            f"{self.__class__.__name__} must implement _build_messages_revision method"
        )

    # -----------------------------------------------------------
    # ëª¨ë¸ ë¡œë“œ / pretrain
    # -----------------------------------------------------------
    def load_model(self, model_path: Optional[str] = None):
        """ì €ì¥ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ (ê°ì²´/ë”•ì…”ë„ˆë¦¬/state_dict ìë™ ì¸ì‹ + model ìë™ ìƒì„±)"""
        if model_path is None:
            model_path = os.path.join(self.model_dir, f"{self.ticker}_{self.agent_id}.pt")

        if not os.path.exists(model_path):
            print(f"â–  ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
            return False

        try:
            checkpoint = torch.load(model_path, map_location=torch.device("cpu"))

            if getattr(self, "model", None) is None:
                if hasattr(self, "_build_model"):
                    self.model = self._build_model()
                    print(f"â–  {self.agent_id} ëª¨ë¸ ìƒˆë¡œ ìƒì„±ë¨ (ë¡œë“œ ì „ ì´ˆê¸°í™”).")
                elif hasattr(self, "forward"):
                    self.model = self
                    print(f"â–  {self.agent_id} ëª¨ë¸ ì§ì ‘ selfë¡œ ì„¤ì •ë¨.")
                else:
                    raise RuntimeError(f"{self.agent_id}ì— _build_model()ì´ ì •ì˜ë˜ì–´ ìˆì§€ ì•ŠìŒ.")

            model = self.model

            if isinstance(checkpoint, torch.nn.Module):
                model.load_state_dict(checkpoint.state_dict())
                print(f" {self.agent_id} ëª¨ë¸(ê°ì²´) ë¡œë“œ ì™„ë£Œ ({model_path})")
            elif isinstance(checkpoint, dict):
                state_dict = (
                    checkpoint.get("model_state_dict")
                    or checkpoint.get("state_dict")
                    or checkpoint
                )
                model.load_state_dict(state_dict)
                print(f" {self.agent_id} ëª¨ë¸(state_dict) ë¡œë“œ ì™„ë£Œ ({model_path})")
            else:
                print(f" ì•Œ ìˆ˜ ì—†ëŠ” ì²´í¬í¬ì¸íŠ¸ í¬ë§·: {type(checkpoint)}")
                return False

            self.model = model
            model.eval()
            return True

        except Exception as e:
            print(f"â–  ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {model_path}")
            print(f"ì˜¤ë¥˜ ë‚´ìš©: {e}")
            return False

    def pretrain(self):
        """Agentë³„ ì‚¬ì „í•™ìŠµ ë£¨í‹´ (ëª¨ë¸ ìƒì„±, í•™ìŠµ, ì €ì¥, self.model ì—°ê²°ê¹Œì§€ í¬í•¨)"""
        info = agents_info[self.agent_id]
        epochs = info["epochs"]
        lr = info["learning_rate"]
        batch_size = info["batch_size"]

        # --------------------------
        # ë°ì´í„° ë¡œë“œ
        # --------------------------
        X, y, cols = load_dataset(self.ticker, self.agent_id, save_dir=self.data_dir)
        print(f"[{datetime.now().strftime('%H:%M:%S')}] Pretraining {self.agent_id}")

        split_idx = int(len(X) * 0.8)
        X_train, X_val = X[:split_idx], X[split_idx:]
        y_train, y_val = y[:split_idx], y[split_idx:]

        # íƒ€ê¹ƒ ìŠ¤ì¼€ì¼ ì¡°ì • (ìˆ˜ìµë¥  Ã— 100)
        y_train *= 100.0
        y_val *= 100.0

        # --------------------------
        # ìŠ¤ì¼€ì¼ë§ (ìˆìœ¼ë©´ ì‚¬ìš©)
        # --------------------------
        use_scaler = (
            getattr(self, "scaler", None) is not None
            and hasattr(self.scaler, "fit_scalers")
            and hasattr(self.scaler, "transform")
        )

        if use_scaler:
            self.scaler.fit_scalers(X_train, y_train)
            if hasattr(self.scaler, "save"):
                self.scaler.save(self.ticker)
            X_train, y_train = self.scaler.transform(X_train, y_train)
        else:
            print(f"[WARN] {self.agent_id}: scaler ì—†ìŒ â†’ ë¹„ìŠ¤ì¼€ì¼ë§ ë°ì´í„°ë¡œ pretrain ì§„í–‰")

        X_train = torch.tensor(X_train, dtype=torch.float32)
        y_train = torch.tensor(y_train, dtype=torch.float32)

        # --------------------------
        # ëª¨ë¸ ìƒì„±
        # --------------------------
        if getattr(self, "model", None) is None:
            if hasattr(self, "_build_model"):
                self.model = self._build_model()
                print(f"â–  {self.agent_id} ëª¨ë¸ ìƒˆë¡œ ìƒì„±ë¨.")
            else:
                raise RuntimeError(f"{self.agent_id}ì— _build_model()ì´ ì •ì˜ë˜ì§€ ì•ŠìŒ")

        model = self.model
        model.train()

        optimizer = torch.optim.Adam(model.parameters(), lr=lr)
        loss_fn = torch.nn.HuberLoss(delta=1.0)
        train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)

        # --------------------------
        # í•™ìŠµ ë£¨í”„
        # --------------------------
        for epoch in range(epochs):
            total_loss = 0.0
            for Xb, yb in train_loader:
                y_pred = model(Xb)
                loss = loss_fn(y_pred, yb)
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                total_loss += loss.item()

            if (epoch + 1) % 5 == 0:
                print(f"  Epoch {epoch+1:03d} | Loss: {total_loss/len(train_loader):.6f}")

        # --------------------------
        # ëª¨ë¸ ì €ì¥ ë° ì—°ê²°
        # --------------------------
        os.makedirs(self.model_dir, exist_ok=True)
        model_path = os.path.join(self.model_dir, f"{self.ticker}_{self.agent_id}.pt")
        torch.save({"model_state_dict": model.state_dict()}, model_path)
        self.model = model

        print(f" {self.agent_id} ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ: {model_path}")

    # -----------------------------------------------------------
    # OpenAI API í˜¸ì¶œ
    # -----------------------------------------------------------
    def _ask_with_fallback(self, msg_sys: dict, msg_user: dict, schema_obj: dict) -> dict:
        """ëª¨ë¸ í´ë°± í¬í•¨ OpenAI Responses API í˜¸ì¶œ"""
        if not msg_sys or not msg_user:
            raise ValueError("Invalid messages: system or user message is None.")

        if schema_obj and isinstance(schema_obj, dict):
            schema_obj.setdefault("additionalProperties", False)
            if "type" not in schema_obj:
                schema_obj["type"] = "object"

        payload_base = {
            "input": [msg_sys, msg_user],
            "text": {
                "format": {
                    "type": "json_schema",
                    "name": "Response",
                    "strict": True,
                    "schema": schema_obj,
                }
            },
            "temperature": self.temperature,
        }

        last_err = None
        for model in self.preferred_models:
            payload = dict(payload_base, model=model)
            try:
                r = requests.post(self.OPENAI_URL, headers=self.headers, json=payload, timeout=120)
                if r.ok:
                    data = r.json()
                    if isinstance(data.get("output_text"), str) and data["output_text"].strip():
                        try:
                            return json.loads(data["output_text"])
                        except Exception:
                            return {"reason": data["output_text"]}

                    out = data.get("output")
                    if isinstance(out, list) and out:
                        texts = []
                        for blk in out:
                            for c in blk.get("content", []):
                                if "text" in c:
                                    texts.append(c["text"])
                        joined = "\n".join(t for t in texts if t)
                        if joined.strip():
                            try:
                                return json.loads(joined)
                            except Exception:
                                return {"reason": joined}
                    return {}

                if r.status_code in (400, 404):
                    last_err = (r.status_code, r.text)
                    continue
                r.raise_for_status()
            except Exception as e:
                print(f"â–  {self.agent_id} - ëª¨ë¸ {model} ì‹¤íŒ¨: {e}")
                last_err = str(e)
                continue

        raise RuntimeError(f"ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨. ë§ˆì§€ë§‰ ì˜¤ë¥˜: {last_err}")

    # -----------------------------------------------------------
    # í‰ê°€ ìœ í‹¸
    # -----------------------------------------------------------
    def evaluate(self, ticker: str | None = None):
        """ê²€ì¦ ë°ì´í„°ë¡œ ì„±ëŠ¥ í‰ê°€"""
        if ticker is None:
            ticker = self.ticker

        X, y, feature_cols = load_dataset(ticker, agent_id=self.agent_id, save_dir=self.data_dir)

        split_idx = int(len(X) * 0.8)
        X_val = X[split_idx:]
        y_val = y[split_idx:]

        if self.scaler:
            self.scaler.load(ticker)

        predictions = []
        actual_returns = []

        for i in range(len(X_val)):
            X_input = X_val[i:i+1]
            X_tensor = torch.tensor(X_input, dtype=torch.float32)

            with torch.no_grad():
                pred_return = self.model(X_tensor).item()
                predictions.append(pred_return)
                actual_returns.append(y_val[i, 0])

        predictions = np.array(predictions)
        actual_returns = np.array(actual_returns)

        mae = np.mean(np.abs(predictions - actual_returns))
        rmse = np.sqrt(np.mean((predictions - actual_returns) ** 2))
        correlation = np.corrcoef(predictions, actual_returns)[0, 1]

        pred_direction = np.sign(predictions)
        actual_direction = np.sign(actual_returns)
        direction_accuracy = np.mean(pred_direction == actual_direction) * 100

        return {
            "mae": mae,
            "rmse": rmse,
            "correlation": correlation,
            "direction_accuracy": direction_accuracy,
            "n_samples": len(predictions),
        }

    # -----------------------------------------------------------
    # ê¸°íƒ€
    # -----------------------------------------------------------
    def _msg(self, role: str, content: str) -> dict:
        if not isinstance(role, str) or not isinstance(content, str):
            raise ValueError(f"_msg() ì¸ì ì˜¤ë¥˜: role={role}, content={type(content)}")
        return {"role": role, "content": content}
