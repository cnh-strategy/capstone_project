# agents/sentimental_agent.py

from __future__ import annotations

import os
import json
from typing import Optional, Tuple, Dict, Any, List, Union
from pathlib import Path
from datetime import datetime, timedelta, date

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import joblib
import yfinance as yf

from prompts import OPINION_PROMPTS, REBUTTAL_PROMPTS, REVISION_PROMPTS

from agents.base_agent import BaseAgent, StockData, Target, Opinion, Rebuttal
from config.agents import agents_info, dir_info
from core.utils_datetime import today_kst
from core.data_set import load_dataset, build_dataset
from core.sentimental_classes.lstm_model import SentimentalLSTM
from core.sentimental_classes.news import merge_price_with_news_features

FEATURE_COLS = [
    "return_1d",
    "hl_range",
    "Volume",
    "news_count_1d",
    "news_count_7d",
    "sentiment_mean_1d",
    "sentiment_mean_7d",
    "sentiment_vol_7d",
]

WINDOW_SIZE = 40
HIDDEN_DIM = 64
NUM_LAYERS = 2
DROPOUT = 0.2

class SentimentalAgent(BaseAgent):
    def __init__(self, ticker: str, agent_id: str = "SentimentalAgent", **kwargs):
        # 0) BaseAgent ì´ˆê¸°í™” (í•œ ë²ˆë§Œ!)
        super().__init__(ticker=ticker, agent_id=agent_id, **kwargs)

        # ìŠ¤ì¼€ì¼ëŸ¬ëŠ” ì•„ì§ ì•ˆ ì“°ë”ë¼ë„ ì†ì„±ì€ ì¡ì•„ë‘ê¸°
        self.scaler = None

        # 1) ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # 2) train_sentimental.py ì˜ ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë°˜ì˜
        #    (ì´ë¯¸ ìƒë‹¨ì—ì„œ HIDDEN_DIM, NUM_LAYERS, DROPOUT, WINDOW_SIZE, FEATURE_COLS import ë˜ì–´ ìˆë‹¤ê³  ê°€ì •)
        self.window_size: int = int(WINDOW_SIZE)
        self.hidden_dim: int = int(HIDDEN_DIM)
        self.num_layers: int = int(NUM_LAYERS)
        self.dropout: float = float(DROPOUT)

        # 3) feature ëª©ë¡ (í›ˆë ¨ ë•Œ ì‚¬ìš©í•œ ì „ì²´ ë¦¬ìŠ¤íŠ¸)
        self.feature_cols: List[str] = list(FEATURE_COLS)
        input_dim = len(self.feature_cols)

        # 4) agents_info ì„¤ì •ìœ¼ë¡œ override (ìˆìœ¼ë©´)
        cfg = (agents_info or {}).get(agent_id, {})
        if not cfg:
            print("[WARN] agents_info['SentimentalAgent'] ì—†ìŒ â†’ ê¸°ë³¸ê°’ ì‚¬ìš©")
            cfg = {
                "window_size": self.window_size,
                "hidden_dim": self.hidden_dim,
                "dropout": self.dropout,
                "epochs": 30,
                "learning_rate": 1e-3,
                "batch_size": 64,
                "gamma": 0.3,
                "delta_limit": 0.05,
            }

        # config ê¸°ë°˜ìœ¼ë¡œ ë®ì–´ì“°ê¸°
        self.window_size = cfg.get("window_size", self.window_size)
        self.hidden_dim = cfg.get("hidden_dim", self.hidden_dim)
        self.dropout = cfg.get("dropout", self.dropout)
        # num_layers ë„ configì— ìˆìœ¼ë©´ ë°˜ì˜
        self.num_layers = cfg.get("num_layers", self.num_layers)

        # 5) LSTM ëª¨ë¸ êµ¬ì„± (í•œ ë²ˆë§Œ!)
        self.model: nn.Module = SentimentalLSTM(
            input_dim=input_dim,
            hidden_dim=self.hidden_dim,
            num_layers=self.num_layers,
            dropout=self.dropout,
        ).to(self.device)

        self.model_loaded: bool = False

        # 6) ì‚¬ì „ í•™ìŠµ weight ë¡œë“œ
        state_path = f"models/{ticker}_SentimentalAgent.pt"
        try:
            state = torch.load(state_path, map_location=self.device)
            self.model.load_state_dict(state)
            self.model.eval()
            self.model_loaded = True
            print(f"[SentimentalAgent] ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ë¡œë“œ: {state_path}")
        except Exception as e:
            print(f"[SentimentalAgent] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

        # 7) ê¸°íƒ€ ìƒíƒœ ë³€ìˆ˜
        self.last_price: Optional[float] = None
        self.currency: str = "USD"
        self._last_input: Optional[np.ndarray] = None  # (1, T, F)
        self.stockdata: Optional[StockData] = None
        self.epochs = cfg.get("epochs", 30)
        self.learning_rate = cfg.get("learning_rate", 1e-3)
        self.batch_size = cfg.get("batch_size", 64)
        self.gamma = cfg.get("gamma", 0.3)
        self.delta_limit = cfg.get("delta_limit", 0.05)

    def _load_model_only(self) -> None:
        """ìŠ¤ì¼€ì¼ëŸ¬ëŠ” DataScalerê°€ ê´€ë¦¬í•˜ë‹ˆê¹Œ, ì—¬ê¸°ì„  LSTM ê°€ì¤‘ì¹˜ë§Œ ë¡œë“œ"""
        base_name = f"{self.ticker}_SentimentalAgent"
        model_path = Path("models") / f"{base_name}.pt"

        if model_path.exists():
            try:
                state = torch.load(model_path, map_location=self.device)
                missing, unexpected = self.model.load_state_dict(state, strict=False)
                print(f"[SentimentalAgent] ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ë¡œë“œ: {model_path}")
                if missing or unexpected:
                    print("[SentimentalAgent] state_dict mismatch:",
                          "missing:", missing, "/ unexpected:", unexpected)
                else:
                    self.model_loaded = True
            except Exception as e:
                print(f"[SentimentalAgent] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.model_loaded = False
        else:
            print(f"[SentimentalAgent] ì‚¬ì „ í•™ìŠµ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
            self.model_loaded = False

    def _convert_uncertainty_to_confidence(self, sigma: float) -> float:
        """
        í‘œì¤€í¸ì°¨ sigmaê°€ ì‘ì„ìˆ˜ë¡ confidence(0~1)ê°€ ì»¤ì§€ë„ë¡ ë³€í™˜.
        """
        import numpy as np
        sigma = float(abs(sigma) or 1e-6)
        return float(1.0 / (1.0 + np.log1p(sigma)))

    def run_dataset(self, days: int = 365) -> StockData:
        """
        ìµœê·¼ daysì¼ì¹˜ ê°€ê²© + ë‰´ìŠ¤ í”¼ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ
        1) FEATURE_COLS ì…ë ¥ í–‰ë ¬ ìƒì„±
        2) LSTM ì…ë ¥ ìœˆë„ìš°(1, T, F) ìƒì„±
        3) StockData ì´ˆê¸° ìŠ¤ëƒ…ìƒ· ìƒì„±
        """
        # 0) ë‚ ì§œ ë²”ìœ„ ì„¤ì •
        end = pd.Timestamp.today().normalize()
        start = end - pd.Timedelta(days=days)

        # 1) ê°€ê²© ë°ì´í„° (yfinance)
        df_price = yf.download(self.ticker, start=start, end=end)

        # yfinance MultiIndex column ëŒ€ì‘ + ì†Œë¬¸ì í†µì¼
        if isinstance(df_price.columns, pd.MultiIndex):
            df_price.columns = [c[0].lower() for c in df_price.columns]
        else:
            df_price.columns = [c.lower() for c in df_price.columns]

        df_price = df_price.rename(
            columns={
                "open": "open",
                "high": "high",
                "low": "low",
                "close": "close",
                "volume": "volume",
            }
        )

        df_price["date"] = df_price.index
        df_price = df_price.reset_index(drop=True)

        # 2) ë‰´ìŠ¤ + ê°€ê²© ë³‘í•© (7ì¼ ì§‘ê³„ í”¼ì²˜ í¬í•¨)
        df_merged = merge_price_with_news_features(
            df_price=df_price,
            ticker=self.ticker,
            asof_kst=end.date(),
            base_dir=os.path.join("data", "raw", "news"),
        )

        # merge_price_with_news_features ê°€ (df, meta) íŠœí”Œì„ ë°˜í™˜í•˜ëŠ” ê²½ìš° ë°©ì–´
        if isinstance(df_merged, tuple):
            df_merged_df = df_merged[0]
        else:
            df_merged_df = df_merged

        # 3) FEATURE_COLS ëˆ„ë½ ìë™ ë³´ì •
        df_feat = df_merged_df.sort_values("date").reset_index(drop=True)

        required_cols = list(FEATURE_COLS)
        missing = [c for c in required_cols if c not in df_feat.columns]
        print("[SentimentalAgent.run_dataset] missing(before):", missing)

        # --- ì»¬ëŸ¼ ëŒ€ì†Œë¬¸ì í†µì¼ (ì´ë¯¸ ì†Œë¬¸ìì¼ ê°€ëŠ¥ì„±ì´ ë†’ì§€ë§Œ ë°©ì–´) ---
        close_col = "close" if "close" in df_feat.columns else None
        high_col = "high" if "high" in df_feat.columns else None
        low_col = "low" if "low" in df_feat.columns else None

        # --- return_1d: ì¢…ê°€ ê¸°ì¤€ 1ì¼ ìˆ˜ìµë¥  ---
        if "return_1d" in missing:
            if close_col is not None:
                df_feat["return_1d"] = df_feat[close_col].pct_change().fillna(0.0)
            else:
                print("[SentimentalAgent.run_dataset] WARN: close column not found, return_1d filled with 0.0")
                df_feat["return_1d"] = 0.0

        # --- hl_range: (ê³ ê°€-ì €ê°€)/ì¢…ê°€ ---
        if "hl_range" in missing:
            if high_col is not None and low_col is not None and close_col is not None:
                rng = (df_feat[high_col] - df_feat[low_col]) / df_feat[close_col].replace(0, np.nan)
                df_feat["hl_range"] = rng.fillna(0.0)
            else:
                print("[SentimentalAgent.run_dataset] WARN: high/low/close missing, hl_range filled with 0.0")
                df_feat["hl_range"] = 0.0

        # --- Volume: ì†Œë¬¸ì volume â†’ ëŒ€ë¬¸ì Volume ë§ì¶”ê¸° ---
        if "Volume" not in df_feat.columns:
            if "volume" in df_feat.columns:
                df_feat["Volume"] = df_feat["volume"].fillna(0.0)
            else:
                df_feat["Volume"] = 0.0

        # --- ë‰´ìŠ¤ 1ì¼ ê¸°ì¤€ í”¼ì²˜(ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì±„ìš°ê¸°) ---
        for col in ["news_count_1d", "sentiment_mean_1d"]:
            if col not in df_feat.columns:
                df_feat[col] = 0.0

        # 4) ìµœì¢… FEATURE_COLS ê²€ì¦
        missing_after = [c for c in required_cols if c not in df_feat.columns]
        if missing_after:
            raise ValueError(
                f"[SentimentalAgent.run_dataset] FEATURE_COLS ì¤‘ ì•„ì§ ì—†ëŠ” ì»¬ëŸ¼: {missing_after}\n"
                f"í˜„ì¬ df_feat.columns = {df_feat.columns.tolist()}"
            )

        print("[SentimentalAgent.run_dataset] all FEATURE_COLS present.")

        # 5) ì‹œê³„ì—´ íŠ¹ì„± í–‰ë ¬ ìƒì„±
        feat_values = df_feat[required_cols].values.astype("float32")

        if len(feat_values) < WINDOW_SIZE:
            raise ValueError(
                f"ìœˆë„ìš° í¬ê¸°({WINDOW_SIZE})ë³´ë‹¤ ë°ì´í„° ê¸¸ì´({len(feat_values)})ê°€ ì§§ìŠµë‹ˆë‹¤."
            )

        X_last = feat_values[-WINDOW_SIZE:]      # (T, F)
        X_last = X_last[None, :, :]              # (1, T, F)
        self._last_input = X_last                # predict() ì—ì„œ ì‚¬ìš©

        # 6) StockData ìƒì„± + ë©”íƒ€ ì •ë³´ ë¶€ì°©
        last_row = df_feat.iloc[-1]
        last_price = float(last_row.get("close", np.nan))
        self.last_price = last_price  # predict ì—ì„œ current_price ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©
        currency = "USD"

        # StockData ìƒì„±ìì—ëŠ” ìµœì†Œ ì¸ìë§Œ
        sd = StockData(
            ticker=self.ticker,
            last_price=last_price,
            currency=currency,
        )

        # ë¶€ê°€ ì •ë³´ëŠ” ì†ì„±ìœ¼ë¡œ ë‹¬ê¸° (BaseAgent / DebateAgentì—ì„œ ì‚¬ìš© ê°€ëŠ¥)
        sd.feature_cols = FEATURE_COLS
        sd.window_size = WINDOW_SIZE
        sd.news_feats = {
            "news_count_7d": float(last_row.get("news_count_7d", 0)),
            "sentiment_mean_7d": float(last_row.get("sentiment_mean_7d", 0)),
            "sentiment_vol_7d": float(last_row.get("sentiment_vol_7d", 0)),
        }
        sd.raw_df = df_feat
        sd.agent_id = getattr(self, "agent_id", None)

        # ì˜ˆì „ ì½”ë“œì™€ í˜¸í™˜ë˜ë„ë¡ snapshot ë„ ë§Œë“¤ì–´ ì¤Œ
        sd.snapshot = {
            "agent_id": sd.agent_id,
            "feature_cols": sd.feature_cols,
            "window_size": sd.window_size,
            "news_feats": sd.news_feats,
            "raw_df": sd.raw_df,
        }

        # LSTM ì…ë ¥ ì‹œí€€ìŠ¤
        sd.X_seq = X_last  # (1, T, F)
        self.stockdata = sd
        return sd

    def predict(
        self,
        X,
        n_samples: int = 100,
        current_price: float | None = None,
    ):
        """
        Xë¡œ StockData ë˜ëŠ” (T, F)/(1, T, F) ë„˜íŒŒì´/í…ì„œë¥¼ ëª¨ë‘ í—ˆìš©í•œë‹¤.
        StockDataê°€ ë“¤ì–´ì˜¤ë©´ ë‚´ë¶€ì—ì„œ X_seqì™€ last_priceë¥¼ êº¼ë‚´ ì“´ë‹¤.
        """
        # 1) StockDataê°€ ë“¤ì–´ì˜¨ ê²½ìš° ì²˜ë¦¬
        if isinstance(X, StockData):
            sd = X

            # run_datasetì—ì„œ X_seqë¥¼ ì„¸íŒ…í–ˆëŠ”ì§€ í™•ì¸
            if getattr(sd, "X_seq", None) is None:
                raise ValueError(
                    "StockDataì— X_seqê°€ ì—†ìŠµë‹ˆë‹¤. SentimentalAgent.run_dataset()ì—ì„œ "
                    "sd.X_seqë¥¼ ì„¤ì •í–ˆëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”."
                )

            X_in = sd.X_seq

            # current_priceê°€ ì•ˆ ë“¤ì–´ì™”ìœ¼ë©´ StockDataì˜ last_price ì‚¬ìš©
            if current_price is None and getattr(sd, "last_price", None) is not None:
                current_price = float(sd.last_price)

            # ë””ë²„ê¹…/ì„¤ëª…ìš©ìœ¼ë¡œ ë³´ê´€
            self._last_stockdata = sd
            self._last_input = X_in

        else:
            # ì´ë¯¸ ë„˜íŒŒì´/í…ì„œì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
            X_in = X

        # 2) BaseAgent.predict í˜¸ì¶œ (ì—¬ê¸°ëŠ” ë„˜íŒŒì´/í…ì„œë§Œ ë°›ë„ë¡ ìœ ì§€)
        target = super().predict(X_in, n_samples=n_samples, current_price=current_price)

        # 3) íƒ€ê²Ÿì— ë©”íƒ€ì •ë³´ ë³´ê°•
        target.ticker = self.ticker
        target.agent_id = getattr(self, "agent_id", "SentimentalAgent")
        self.target = target

        return target


    # BaseAgent.decode_prediction
    def decode_prediction(self, y_pred_raw, stock_data=None, current_price=None) -> float:
        """
        BaseAgent.predict ë‚´ë¶€ì—ì„œ ì‚¬ìš©í•  ë””ì½”ë”.
        ëª¨ë¸ ì¶œë ¥(ìˆ˜ìµë¥  ë¹„ìŠ·í•œ ê°’)ì„ [-20%, +20%]ë¡œ ì œí•œ í›„ ê°€ê²©ìœ¼ë¡œ ë³€í™˜.
        """
        y_raw = float(np.asarray(y_pred_raw).reshape(-1)[-1])

        y_scaler = None
        if self.scaler is not None:
            if isinstance(self.scaler, dict):
                y_scaler = self.scaler.get("y_scaler", None)
            else:
                y_scaler = getattr(self.scaler, "y_scaler", None)

        if y_scaler is not None:
            try:
                y_decoded = float(y_scaler.inverse_transform([[y_raw]])[0, 0])
            except Exception:
                y_decoded = y_raw
        else:
            y_decoded = y_raw

        max_abs_return = 0.20
        predicted_return = max(min(y_decoded, max_abs_return), -max_abs_return)

        base_price = None
        if stock_data is not None:
            base_price = getattr(stock_data, "last_price", None)
        if base_price is None:
            base_price = current_price
        if base_price is None:
            base_price = 1.0

        next_close = float(base_price * (1.0 + predicted_return))
        return next_close

    def build_finbert_news_features(
        self,
        ticker: str,
        asof_kst: datetime,
        base_dir: str = "data/raw/news",
        days_list = [7, 30],
    ):
        from core.sentimental_classes.eodhd_client import fetch_news_from_eodhd
        from core.sentimental_classes.finbert_utils import FinBertScorer
        import numpy as np
        import os

        scorer = FinBertScorer()
        feats = {}

        for d in days_list:
            news = fetch_news_from_eodhd(ticker, days=d)

            # ğŸ”¥ ë‰´ìŠ¤ ì—†ìœ¼ë©´ ë°”ë¡œ ì‹¤íŒ¨
            if (news is None) or (len(news) == 0):
                raise RuntimeError(
                    f"[NewsError] {ticker} ìµœê·¼ {d}ì¼ ë‰´ìŠ¤ ì—†ìŒ (fetch_news_from_eodhd)"
                )

            scores = []
            for item in news:
                title = item.get("title", "") or ""
                score = scorer.score(title) or 0
                scores.append(score)

            scores = np.array(scores)

            feats[f"sentiment_mean_{d}d"] = float(np.mean(scores))
            feats[f"sentiment_vol_{d}d"] = float(np.std(scores))
            feats[f"news_count_{d}d"] = len(scores)

            # Trend: ë§ˆì§€ë§‰ 25% í‰ê·  - ì²˜ìŒ 25% í‰ê· 
            if len(scores) >= 4:
                q = len(scores) // 4
                early = np.mean(scores[:q])
                late = np.mean(scores[-q:])
                feats[f"sentiment_trend_{d}d"] = float(late - early)
            else:
                feats[f"sentiment_trend_{d}d"] = 0.0

            # Shock: z-score of last score
            if len(scores) >= 2:
                feats[f"sentiment_shock_z_{d}d"] = float(
                    (scores[-1] - np.mean(scores)) / (np.std(scores) + 1e-6)
                )
            else:
                feats[f"sentiment_shock_z_{d}d"] = 0.0

        return feats

    def _load_scaler_and_model(self) -> None:
        # train_sentimental.pyì—ì„œ ì €ì¥í•œ ìŠ¤ì¼€ì¼ëŸ¬/ëª¨ë¸ ë¡œë“œ
        base_name = f"{self.ticker}_SentimentalAgent"
        scaler_path = Path("models") / "scalers" / f"{base_name}.pkl"
        model_path = Path("models") / f"{base_name}.pt"

        # ìŠ¤ì¼€ì¼ëŸ¬/ë©”íƒ€
        if scaler_path.exists():
            meta = joblib.load(scaler_path)
            meta_feature_cols = None
            meta_window_size = None

            if isinstance(meta, dict) and ("x_scaler" in meta or "y_scaler" in meta):
                self.scaler = meta
                meta_feature_cols = meta.get("feature_cols", None)
                meta_window_size = meta.get("window_size", None)
            elif isinstance(meta, dict) and "scaler" in meta:
                self.scaler = meta.get("scaler", None)
                meta_feature_cols = meta.get("feature_cols", None)
                meta_window_size = meta.get("window_size", None)
            else:
                self.scaler = meta

            if meta_feature_cols is not None:
                self.feature_cols = list(meta_feature_cols)
            if meta_window_size is not None:
                self.window_size = int(meta_window_size)

            print(f"[SentimentalAgent] ìŠ¤ì¼€ì¼ëŸ¬/ë©”íƒ€ ë¡œë“œ: {scaler_path}")
        else:
            print(f"[SentimentalAgent] ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ ì—†ìŒ: {scaler_path}")
            self.scaler = None

        # LSTM ê°€ì¤‘ì¹˜
        if model_path.exists():
            try:
                state = torch.load(model_path, map_location=self.device)
                missing, unexpected = self.model.load_state_dict(state, strict=False)
                print(f"[SentimentalAgent] ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ë¡œë“œ: {model_path}")
                if missing or unexpected:
                    print("[SentimentalAgent] state_dict mismatch:",
                          "missing:", missing, "/ unexpected:", unexpected)
                else:
                    self.model_loaded = True
            except Exception as e:
                print(f"[SentimentalAgent] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.model_loaded = False
        else:
            print(f"[SentimentalAgent] ì‚¬ì „ í•™ìŠµ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
            self.model_loaded = False

    # BaseAgent.pretrain()ìš©
        # BaseAgent.pretrain()ìš©
    def _build_model(self) -> nn.Module:
        """BaseAgent.pretrainì—ì„œ ì‚¬ìš©í•  ëª¨ë¸ ìƒì„±."""
        try:
            X, y, cols = load_dataset(
                ticker=self.ticker,
                agent_id=self.agent_id,
                window_size=self.window_size,
            )
        except Exception:
            # ë°ì´í„°ì…‹ ì—†ìœ¼ë©´ ë¨¼ì € ìƒì„±
            build_dataset(
                ticker=self.ticker,
                agent_id=self.agent_id,
                window_size=self.window_size,
            )
            X, y, cols = load_dataset(
                ticker=self.ticker,
                agent_id=self.agent_id,
                window_size=self.window_size,
            )

        # (N, T, F) ê°€ì •
        input_dim = X.shape[-1]
        self.feature_cols = list(cols)

        net = SentimentalLSTM(
            input_dim=input_dim,
            hidden_dim=self.hidden_dim,
            num_layers=self.num_layers,
            dropout=self.dropout,
        )
        return net

    def model_path(self) -> str:
        """ëª¨ë¸ ì €ì¥ ê²½ë¡œ í†µì¼."""
        try:
            model_dir = dir_info["model_dir"]
        except Exception:
            model_dir = "models"

        ticker = getattr(self, "ticker", "UNKNOWN")
        agent_id = getattr(self, "agent_id", "SentimentalAgent")
        return os.path.join(model_dir, f"{ticker}_{agent_id}.pt")

    def _load_model_if_exists(self) -> None:
        """model_path ê¸°ì¤€ìœ¼ë¡œ íŒŒì¼ì´ ìˆìœ¼ë©´ BaseAgent.load_model ì‚¬ìš©."""
        model_path = self.model_path()
        if not os.path.exists(model_path):
            self.model_loaded = False
            return

        ok = False
        try:
            ok = self.load_model(model_path)
        except Exception as e:
            print(f"[SentimentalAgent] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            ok = False

        self.model_loaded = bool(ok)

    # MC Dropout helper (dataset ê¸°ë°˜)
    @torch.inference_mode()
    def _predict_next_close(self) -> Tuple[float, float, float, List[str]]:
        if not self.ticker:
            raise ValueError("ticker is None in _predict_next_close")

        # 1) ìµœì‹  ì…ë ¥ ìœˆë„ìš° í™•ë³´
        X = getattr(self, "_last_input", None)
        if X is None:
            sd = self.run_dataset()        # run_datasetì´ self._last_input, self.last_price ì±„ì›€
            X = sd.X_seq

        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)

        # 2) LSTMìœ¼ë¡œ ìˆ˜ìµë¥  ì˜ˆì¸¡
        self.model.eval()
        with torch.no_grad():
            out = self.model(X_tensor)

        out = out.reshape(-1)
        mean_ret = float(out[0])   # ì˜ˆ: -0.003 â†’ -0.3%
        std_ret = 0.01             # í•„ìš”í•˜ë©´ ë‚˜ì¤‘ì— _mc_dropout_predictë¡œ êµì²´

        # 3) í˜„ì¬ ì¢…ê°€
        last_close = float(getattr(self, "last_price", 0.0) or 0.0)

        if last_close > 0:
            pred_close = float(last_close * (1.0 + mean_ret))
        else:
            pred_close = float(mean_ret)

        uncertainty_std = float(std_ret)
        confidence = float(1.0 / (1.0 + max(1e-6, uncertainty_std)))

        cols = list(getattr(self, "feature_cols", []))
        return pred_close, uncertainty_std, confidence, cols

    # ctx êµ¬ì„± (ê°€ê²© + ë‰´ìŠ¤ ê°ì„± ìŠ¤ëƒ…ìƒ·)
    def build_ctx(self, asof_date_kst: Optional[str] = None) -> Dict[str, Any]:
        # 0) StockData í™•ë³´
        stockdata: StockData | None = getattr(self, "stockdata", None)
        if stockdata is None:
            # í•„ìš”í•˜ë©´ ìµœì‹  ë°ì´í„°ì…‹ ìƒì„±
            stockdata = self.run_dataset()

        # 1) ê¸°ì¤€ ë‚ ì§œ(asof_date_kst)
        if asof_date_kst is None:
            asof_date_kst = datetime.now().strftime("%Y-%m-%d")

        # 2) ì˜ˆì¸¡ ê°’
        pred_close, uncertainty_std, confidence, cols = self._predict_next_close()

        # 3) ê°€ê²© ìŠ¤ëƒ…ìƒ· (raw_df ë§ˆì§€ë§‰ í–‰ ê¸°ì¤€)
        price_snapshot: Dict[str, Optional[float]] = {}
        df = getattr(stockdata, "raw_df", None)
        if isinstance(df, pd.DataFrame) and len(df) > 0:
            last = df.iloc[-1]
            price_snapshot["Close"] = float(last.get("close", np.nan))
            price_snapshot["Open"] = float(last.get("open", np.nan))
            price_snapshot["High"] = float(last.get("high", np.nan))
            price_snapshot["Low"] = float(last.get("low", np.nan))
            price_snapshot["Volume"] = float(last.get("volume", np.nan))
        else:
            price_snapshot = {
                "Close": getattr(stockdata, "last_price", np.nan),
                "Open": None,
                "High": None,
                "Low": None,
                "Volume": None,
            }

        # 4) ë‰´ìŠ¤/ê°ì„± í”¼ì²˜: run_dataset()ì—ì„œ ì €ì¥í•œ news_feats ì‚¬ìš©
        nf = getattr(stockdata, "news_feats", {}) or {}
        news_count_7d = float(nf.get("news_count_7d", 0.0))
        sentiment_mean_7d = float(nf.get("sentiment_mean_7d", 0.0))
        sentiment_vol_7d = float(nf.get("sentiment_vol_7d", 0.0))

        # ctxì—ì„œ ê¸°ëŒ€í•˜ëŠ” í˜•íƒœë¡œ ë§¤í•‘
        sentiment_summary = {
            "mean_7d": sentiment_mean_7d,
            "mean_30d": 0.0,          # ì•„ì§ì€ 30ì¼ í”¼ì²˜ ì—†ìœ¼ë‹ˆ 0ìœ¼ë¡œ
            "pos_ratio_7d": 0.0,      # í–¥í›„ í•„ìš”ì‹œ í™•ì¥
            "neg_ratio_7d": 0.0,
        }
        sentiment_vol = {"vol_7d": sentiment_vol_7d}
        news_count = {"count_7d": int(news_count_7d)}
        trend_7d = 0.0
        has_news = bool(news_count_7d > 0)

        # 5) snapshot / prediction êµ¬ì„±
        last_price = price_snapshot.get("Close", np.nan)
        if last_price and last_price == last_price:
            pred_return = float(pred_close / last_price - 1.0)
        else:
            pred_return = None

        snapshot = {
            "asof_date": asof_date_kst,
            "last_price": last_price,
            "currency": getattr(stockdata, "currency", "USD"),
            "window_size": self.window_size,
            "feature_cols_preview": [c for c in (cols or [])[:8]],
        }

        feature_importance = {
            "sentiment_score": sentiment_summary.get("mean_7d", 0.0),
            "sentiment_summary": sentiment_summary,
            "sentiment_volatility": sentiment_vol,
            "trend_7d": trend_7d,
            "news_count": news_count,
            "has_news": has_news,
            "price_snapshot": {
                "Close": price_snapshot.get("Close"),
                "Open": price_snapshot.get("Open"),
                "High": price_snapshot.get("High"),
                "Low": price_snapshot.get("Low"),
                "Volume": price_snapshot.get("Volume"),
                "ret_1d": None,
                "ret_5d": None,
                "ret_20d": None,
                "zscore_20d": None,
                "vol_change_5d": None,
            },
        }

        ctx = {
            "agent_id": self.agent_id,
            "ticker": self.ticker,
            "snapshot": snapshot,
            "prediction": {
            "pred_close": pred_close,
            "pred_return": pred_return,
            "uncertainty": {
                "std": uncertainty_std,
                "ci95": float(1.96 * uncertainty_std),
            },
            "confidence": confidence,
        },
            "feature_importance": feature_importance,
        }
        return ctx

    # Opinion / Rebuttal / Revision í”„ë¡¬í”„íŠ¸
    def _build_messages_opinion(
        self,
        stock_data: StockData,
        target: Target,
    ) -> Tuple[str, str]:
        if stock_data is None:
            stock_data = self.stockdata

        # âœ… ê³µí†µ ctx ì‚¬ìš©
        ctx = self.build_ctx()

        # ì˜ˆì¸¡ê°’ì„ target ê¸°ì¤€ìœ¼ë¡œ ê°±ì‹  (DebateAgentì—ì„œ ì—…ë°ì´íŠ¸ëì„ ìˆ˜ ìˆìœ¼ë‹ˆê¹Œ)
        ctx["prediction"]["pred_next_close"] = float(getattr(target, "next_close", 0.0))
        ctx["prediction"]["pred_close"] = ctx["prediction"]["pred_next_close"]

        last_close = ctx["snapshot"].get("last_price")
        if isinstance(last_close, (int, float)) and last_close not in (0, None):
            try:
                chg = ctx["prediction"]["pred_next_close"] / float(last_close) - 1.0
            except ZeroDivisionError:
                chg = None
        else:
            chg = None
        ctx["prediction"]["pred_return"] = chg

        ctx_json = json.dumps(ctx, ensure_ascii=False, indent=2)

        prompts = OPINION_PROMPTS["SentimentalAgent"]
        system_text = prompts["system"]
        user_tmpl = prompts["user"]

        try:
            user_text = user_tmpl.format(context=ctx_json)
        except KeyError:
            user_text = user_tmpl.replace("{context}", ctx_json)

        return system_text, user_text

    def _build_messages_rebuttal(self, *args, **kwargs) -> Tuple[str, str]:
        stock_data = args[0] if len(args) > 0 else kwargs.get("stock_data")
        target: Optional[Target] = args[1] if len(args) > 1 else kwargs.get("target")

        opponent = None
        for key in ("opponent", "opponent_opinion", "other_opinion", "other", "opinion"):
            if key in kwargs:
                opponent = kwargs[key]
                break
        if opponent is None and len(args) > 2:
            opponent = args[2]

        if isinstance(opponent, Opinion):
            opp_agent = getattr(opponent, "agent_id", "UnknownAgent")
            opp_reason = getattr(opponent, "reason", "")
        elif isinstance(opponent, dict):
            opp_agent = opponent.get("agent_id", "UnknownAgent")
            opp_reason = opponent.get("reason", "")
        else:
            opp_agent = "UnknownAgent"
            opp_reason = str(opponent) if opponent is not None else ""

        ctx = self.build_ctx()
        fi = ctx.get("feature_importance", {})
        sent = fi.get("sentiment_summary", {})
        vol7 = fi.get("sentiment_volatility", {}).get("vol_7d", None)
        trend7 = fi.get("trend_7d", None)
        news7 = fi.get("news_count", {}).get("count_7d", None)

        pred_close = float(target.next_close) if target else float(
        ctx["prediction"]["pred_close"]
    )
        last_price = ctx.get("snapshot", {}).get("last_price")
        change_ratio = None
        if last_price and last_price == last_price and last_price != 0:
            change_ratio = pred_close / last_price - 1.0

        pp = REBUTTAL_PROMPTS.get("SentimentalAgent", {})
        system_tmpl = pp.get(
            "system",
            "ë‹¹ì‹ ì€ ê°ì„± ê¸°ë°˜ ë‹¨ê¸° ì£¼ê°€ ë¶„ì„ê°€ë¡œì„œ ìƒëŒ€ ì˜ê²¬ì˜ í—ˆì ì„ ê°ì„± ì§€í‘œì™€ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°˜ë°•í•©ë‹ˆë‹¤.",
        )
        user_tmpl = pp.get(
            "user",
            (
                "í‹°ì»¤: {ticker}\n"
                "ìƒëŒ€ ì—ì´ì „íŠ¸: {opp_agent}\n"
                "ìƒëŒ€ ì˜ê²¬:\n{opp_reason}\n\n"
                "ìš°ë¦¬ ì˜ˆì¸¡:\n- next_close: {pred_close}\n- ì˜ˆìƒ ë³€í™”ìœ¨(í˜„ì¬ê°€ ëŒ€ë¹„): {chg}\n"
                "ê°ì„± ê·¼ê±°:\n- mean7={mean7}, mean30={mean30}, pos7={pos7}, neg7={neg7}\n"
                "- vol7={vol7}, trend7={trend7}, news7={news7}\n\n"
                "ìš”ì²­: ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒëŒ€ ì˜ê²¬ì˜ ì•½ì  2~4ê°œë¥¼ ì¡°ëª©ì¡°ëª© ë°˜ë°•í•˜ì„¸ìš”."
            ),
        )

        user_text = user_tmpl.format(
            ticker=self.ticker,
            opp_agent=opp_agent,
            opp_reason=opp_reason if opp_reason else "(ìƒëŒ€ ì˜ê²¬ ë‚´ìš© ì—†ìŒ)",
            pred_close=f"{pred_close:.4f}",
            chg=("NA" if change_ratio is None else f"{change_ratio*100:.2f}%"),
            mean7=f"{sent.get('mean_7d', 0.0):.4f}",
            mean30=f"{sent.get('mean_30d', 0.0):.4f}",
            pos7=f"{sent.get('pos_ratio_7d', 0.0):.4f}",
            neg7=f"{sent.get('neg_ratio_7d', 0.0):.4f}",
            vol7=("NA" if vol7 is None else f"{vol7:.4f}"),
            trend7=("NA" if trend7 is None else f"{trend7:.4f}"),
            news7=("NA" if news7 is None else f"{news7}"),
        )
        return system_tmpl, user_text

    def _build_messages_revision(self, *args, **kwargs) -> Tuple[str, str]:
        stock_data = args[0] if len(args) > 0 else kwargs.get("stock_data")
        target: Optional[Target] = args[1] if len(args) > 1 else kwargs.get("target")

        # ì´ˆì•ˆ
        prev = None
        rebs = None
        for key in ("previous", "previous_opinion", "draft", "opinion"):
            if key in kwargs:
                prev = kwargs[key]
                break
        if prev is None and len(args) > 2:
            prev = args[2]

        # ë°˜ë°•ë“¤
        for key in ("rebuttals", "replies", "responses"):
            if key in kwargs:
                rebs = kwargs[key]
                break
        if rebs is None and len(args) > 3:
            rebs = args[3]

        def _op_text(x: Union[Opinion, Dict[str, Any], str, None]) -> str:
            if isinstance(x, Opinion):
                return getattr(x, "reason", "")
            if isinstance(x, dict):
                return x.get("reason", "")
            return x or ""

        prev_reason = _op_text(prev)

        reb_texts: List[str] = []
        if isinstance(rebs, list):
            for r in rebs:
                reb_texts.append(_op_text(r))
        elif rebs is not None:
            reb_texts.append(_op_text(rebs))

        ctx = self.build_ctx()
        fi = ctx.get("feature_importance", {})
        sent = fi.get("sentiment_summary", {})
        vol7 = fi.get("sentiment_volatility", {}).get("vol_7d", None)
        trend7 = fi.get("trend_7d", None)
        news7 = fi.get("news_count", {}).get("count_7d", None)

        pred_info = ctx.get("prediction", {}) or {}
        unc_dict = pred_info.get("uncertainty", {}) or {}
        unc_std = unc_dict.get("std", None)
        confidence = pred_info.get("confidence", None)

        pred_close = float(target.next_close) if target else float(
        pred_info.get("pred_close")
    )
        last_price = ctx.get("snapshot", {}).get("last_price")
        change_ratio = None
        if last_price and last_price == last_price and last_price != 0:
            change_ratio = pred_close / last_price - 1.0

        # context ìš”ì•½
        context_parts: List[str] = []
        if last_price is not None:
            if change_ratio is not None:
                context_parts.append(
                    f"í˜„ì¬ ì£¼ê°€ëŠ” {last_price:.2f}ì´ê³ , ëª¨ë¸ì€ ë‹¤ìŒ ê±°ë˜ì¼ ì¢…ê°€ë¥¼ {pred_close:.2f}ë¡œ ì˜ˆì¸¡í–ˆìŠµë‹ˆë‹¤ "
                    f"(ë³€í™”ìœ¨ ì•½ {change_ratio*100:.2f}%)."
                )
            else:
                context_parts.append(
                    f"í˜„ì¬ ì£¼ê°€ëŠ” {last_price:.2f}ì´ë©°, ë‹¤ìŒ ê±°ë˜ì¼ ì¢…ê°€ ì˜ˆì¸¡ê°’ì€ {pred_close:.2f}ì…ë‹ˆë‹¤."
                )
        else:
            context_parts.append(
                f"ë‹¤ìŒ ê±°ë˜ì¼ ì¢…ê°€ ì˜ˆì¸¡ê°’ì€ {pred_close:.2f}ì…ë‹ˆë‹¤."
            )

        mean7 = sent.get("mean_7d", None)
        mean30 = sent.get("mean_30d", None)
        pos7 = sent.get("pos_ratio_7d", None)
        neg7 = sent.get("neg_ratio_7d", None)

        if mean7 is not None and mean30 is not None:
            context_parts.append(
                f"ìµœê·¼ 7ì¼ í‰ê·  ê°ì„± ì ìˆ˜ëŠ” {mean7:.3f}, ìµœê·¼ 30ì¼ í‰ê· ì€ {mean30:.3f}ì…ë‹ˆë‹¤."
            )
        if pos7 is not None and neg7 is not None:
            context_parts.append(
                f"ìµœê·¼ 7ì¼ ê¸°ì¤€ ê¸ì • ê¸°ì‚¬ ë¹„ìœ¨ì€ {pos7:.2%}, ë¶€ì • ê¸°ì‚¬ ë¹„ìœ¨ì€ {neg7:.2%}ì…ë‹ˆë‹¤."
            )
        if vol7 is not None:
            context_parts.append(
                f"ìµœê·¼ 7ì¼ ê°ì„± ì ìˆ˜ì˜ ë³€ë™ì„±(í‘œì¤€í¸ì°¨)ì€ {vol7:.3f}ì…ë‹ˆë‹¤."
            )
        if trend7 is not None:
            context_parts.append(
                f"ìµœê·¼ 7ì¼ ê°ì„± ì¶”ì„¸(íšŒê·€ ê¸°ìš¸ê¸°)ëŠ” {trend7:.4f}ì…ë‹ˆë‹¤."
            )
        if news7 is not None:
            context_parts.append(
                f"ìµœê·¼ 7ì¼ ë™ì•ˆ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ê°œìˆ˜ëŠ” {news7}ê±´ì…ë‹ˆë‹¤."
            )

        if unc_std is not None and confidence is not None:
            context_parts.append(
                f"ì˜ˆì¸¡ í‘œì¤€í¸ì°¨ëŠ” {unc_std:.4f}, ì‹ ë¢°ë„ëŠ” {confidence:.3f}ì…ë‹ˆë‹¤."
            )

        context_str = " ".join(context_parts) if context_parts else (
            "ìµœê·¼ ë‰´ìŠ¤ ê°ì„± ì ìˆ˜, ë³€ë™ì„±, ê¸Â·ë¶€ì • ë¹„ìœ¨, ë‰´ìŠ¤ ìˆ˜, ì˜ˆì¸¡ ë¶ˆí™•ì‹¤ì„± ë“±ì„ ì¢…í•©í•´ ë‹¨ê¸° ì£¼ê°€ë¥¼ í•´ì„í•©ë‹ˆë‹¤."
        )

        pp = REVISION_PROMPTS.get("SentimentalAgent", {})
        system_tmpl = pp.get(
            "system",
            (
                "ë‹¹ì‹ ì€ ê°ì„± ê¸°ë°˜ ë‹¨ê¸° ì£¼ê°€ ë¶„ì„ê°€ì…ë‹ˆë‹¤. "
                "ì´ˆì•ˆ ì˜ê²¬ê³¼ ë°˜ë°•ë“¤ì„ ê²€í† í•´ í•µì‹¬ë§Œ ë‚¨ê¸°ê³ , ë°ì´í„°ì— ê·¼ê±°í•´ ê²°ë¡ ì„ ë‹¤ë“¬ìŠµë‹ˆë‹¤."
            ),
        )
        user_tmpl = pp.get(
            "user",
            (
                "í‹°ì»¤: {ticker}\n"
                "ì´ˆì•ˆ ì˜ê²¬:\n{prev}\n\n"
                "ìˆ˜ì‹ í•œ ë°˜ë°• ìš”ì•½:\n{rebuts}\n\n"
                "ì—…ë°ì´íŠ¸ëœ ìˆ˜ì¹˜:\n- next_close: {pred_close}\n- ì˜ˆìƒ ë³€í™”ìœ¨: {chg}\n"
                "ê°ì„± ê·¼ê±° ìŠ¤ëƒ…ìƒ·:\n- mean7={mean7}, mean30={mean30}, pos7={pos7}, neg7={neg7}\n"
                "- vol7={vol7}, trend7={trend7}, news7={news7}\n\n"
                "ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸:\n{context}\n\n"
                "ìš”ì²­: ì´ˆì•ˆì˜ ê³¼ì¥/ì¤‘ë³µ/ì•½í•œ ê·¼ê±°ë¥¼ ì •ë¦¬í•˜ê³ , ê°•í•œ ê·¼ê±°(ê°ì„± ì¶”ì„¸, ë³€ë™ì„±, ë‰´ìŠ¤ ìˆ˜ ë³€í™”)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ "
                "ìµœì¢… ì˜ê²¬ì„ 3~5ë¬¸ì¥ìœ¼ë¡œ ì¬ì‘ì„±í•˜ì„¸ìš”. ë¶ˆí™•ì‹¤ì„±/ì‹ ë¢°ë„ í•´ì„ì„ í¬í•¨í•˜ì„¸ìš”."
            ),
        )

        rebuts_joined = "- " + "\n- ".join(
            [s for s in reb_texts if s]
        ) if reb_texts else "(ë°˜ë°• ì—†ìŒ)"

        user_text = user_tmpl.format(
            ticker=self.ticker,
            prev=prev_reason if prev_reason else "(ì´ˆì•ˆ ì—†ìŒ)",
            rebuts=rebuts_joined,
            pred_close=f"{pred_close:.4f}",
            chg=("NA" if change_ratio is None else f"{change_ratio*100:.2f}%"),
            mean7=("NA" if mean7 is None else f"{mean7:.4f}"),
            mean30=("NA" if mean30 is None else f"{mean30:.4f}"),
            pos7=("NA" if pos7 is None else f"{pos7:.4f}"),
            neg7=("NA" if neg7 is None else f"{neg7:.4f}"),
            vol7=("NA" if vol7 is None else f"{vol7:.4f}"),
            trend7=("NA" if trend7 is None else f"{trend7:.4f}"),
            news7=("NA" if news7 is None else f"{news7}"),
            context=context_str,
        )
        return system_tmpl, user_text


    # ë ˆê±°ì‹œ Opinion API
    def get_opinion(self, idx: int = 0, ticker: Optional[str] = None) -> Opinion:
        if ticker and ticker != self.ticker:
            self.ticker = str(ticker).upper()

        pred_close, uncertainty_std, confidence, _ = self._predict_next_close()
        target = Target(
            next_close=float(pred_close),
            uncertainty=float(uncertainty_std),
            confidence=float(confidence),
        )

        # BaseAgent.reviewer_draft ì‚¬ìš© ì‹œë„
        try:
            if hasattr(self, "reviewer_draft"):
                op = self.reviewer_draft(getattr(self, "stockdata", None), target)
                return op
        except Exception as e:
            print("[SentimentalAgent] reviewer_draft ì‚¬ìš© ì‹¤íŒ¨:", e)

        # fallback: ë‹¨ìˆœ í…ìŠ¤íŠ¸ ìš”ì•½
        ctx = self.build_ctx()
        fi = ctx["feature_importance"]
        sent = fi["sentiment_summary"]

        reason = (
            f"{self.ticker}ì˜ ìµœê·¼ 7ì¼ ê°ì„± í‰ê· ì€ {sent['mean_7d']:.3f}ì´ë©° "
            f"ë‰´ìŠ¤ ê°œìˆ˜(7d)ëŠ” {fi['news_count']['count_7d']}ê±´ì…ë‹ˆë‹¤. "
            f"ê°ì„± ë³€ë™ì„±(vol_7d)={fi['sentiment_volatility']['vol_7d']:.3f}, "
            f"ê°ì„± ì¶”ì„¸(trend_7d)={fi['trend_7d']:.3f}ì…ë‹ˆë‹¤."
        )

        return Opinion(
            agent_id=self.agent_id,
            target=target,
            reason=reason,
        )
