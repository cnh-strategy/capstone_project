# agents/sentimental_agent.py
# ===============================================================
# SentimentalAgent: ê°ì„±(ë‰´ìŠ¤/í…ìŠ¤íŠ¸) + LSTM ê¸°ë°˜ ì˜ˆì¸¡ ì—ì´ì „íŠ¸
# ===============================================================

from __future__ import annotations
import os
import json
from dataclasses import dataclass
from typing import Optional, Tuple, Dict, Any, List, Union

from pathlib import Path
from datetime import datetime, timedelta, date

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

# ---------------------------
# í”„ë¡œì íŠ¸ ì˜ì¡´ ëª¨ë“ˆ (ì•ˆì „ import)
# ---------------------------
try:
    from agents.base_agent import BaseAgent, StockData, Target, Opinion  # type: ignore
except Exception:
    BaseAgent = object  # type: ignore

    @dataclass
    class Target:  # type: ignore
        next_close: float
        uncertainty: float
        confidence: float

    @dataclass
    class Opinion:  # type: ignore
        agent_id: str
        target: Target
        reason: str

try:
    from config.agents import agents_info, dir_info  # type: ignore
except Exception:
    agents_info = {
        "SentimentalAgent": {
            "window_size": 40,
            "hidden_dim": 128,
            "dropout": 0.2,
            "epochs": 30,
            "learning_rate": 1e-3,
            "batch_size": 64,
            "x_scaler": "StandardScaler",
            "y_scaler": "StandardScaler",
            "gamma": 0.3,
            "delta_limit": 0.05,
        }
    }
    dir_info = {
        "data_dir": "data",
        "model_dir": "models",
        "scaler_dir": os.path.join("models", "scalers"),
    }

try:
    from core.data_set import build_dataset, load_dataset  # type: ignore
except Exception:
    build_dataset = None  # type: ignore

    def load_dataset(*args, **kwargs):  # type: ignore
        raise RuntimeError("core.data_set.load_dataset ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# í”„ë¡¬í”„íŠ¸ ì„¸íŠ¸ (ìˆëŠ” ê²½ìš° ì‚¬ìš©)
try:
    from prompts import OPINION_PROMPTS, REBUTTAL_PROMPTS, REVISION_PROMPTS  # type: ignore
except Exception:
    OPINION_PROMPTS = REBUTTAL_PROMPTS = REVISION_PROMPTS = None  # type: ignore

# FinBERT ìœ í‹¸ (ë‹¨ì¼ ê²½ë¡œë¡œ ê³ ì •)
from core.sentimental_classes.finbert_utils import (
    FinBertScorer,
    score_news_items,
    attach_scores_to_items,
    compute_finbert_features,
)
from core.sentimental_classes.utils_datetime import safe_parse_iso_datetime as _safe_dt

# ---------------------------------------------------------------
# ëª¨ë¸ ì •ì˜: LSTM + Dropout (MC Dropout ì§€ì›)
# ---------------------------------------------------------------
class SentimentalNet(nn.Module):
    def __init__(self, input_dim: int, hidden_dim: int = 128, dropout: float = 0.2):
        super().__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=1, batch_first=True)
        self.drop = nn.Dropout(dropout)
        self.fc = nn.Linear(hidden_dim, 1)

    def forward(self, x):
        # x: [B, T, F]
        out, _ = self.lstm(x)
        out = self.drop(out[:, -1, :])
        out = self.fc(out)  # [B, 1]
        return out


# ---------------------------------------------------------------
# load/build dataset ì‹œê·¸ë‹ˆì²˜ í˜¸í™˜ ìœ í‹¸
# ---------------------------------------------------------------
def _load_dataset_compat(ticker: str, agent_id: str, window_size: Optional[int] = None):
    if not ticker:
        raise ValueError("load_dataset_compat: empty ticker")
    try:
        return load_dataset(ticker, agent_id, window_size=window_size)  # type: ignore
    except TypeError:
        pass
    try:
        return load_dataset(ticker, agent_id, seq_len=window_size)  # type: ignore
    except TypeError:
        pass
    return load_dataset(ticker, agent_id)  # type: ignore


def _build_dataset_compat(ticker: str, agent_id: str, window_size: Optional[int] = None):
    if not ticker:
        raise ValueError("build_dataset_compat: empty ticker")
    if build_dataset is None:
        return
    try:
        return build_dataset(ticker, agent_id, window_size=window_size)  # type: ignore
    except TypeError:
        pass
    try:
        return build_dataset(ticker, agent_id, seq_len=window_size)  # type: ignore
    except TypeError:
        pass
    return build_dataset(ticker, agent_id)  # type: ignore


# ---------------------------------------------------------------
# ìœ í‹¸: ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸ê°€ ì €ì¥í•œ ë‰´ìŠ¤ ìºì‹œë¥¼ ì½ì–´ FinBERT ì§‘ê³„ í”¼ì²˜ ìƒì„±
# ---------------------------------------------------------------
def _utc_from_kst_asof(asof_kst: str, lookback_days: int = 40) -> Tuple[str, str, date]:
    kst_dt = datetime.fromisoformat(asof_kst)
    utc_today = (kst_dt - timedelta(hours=9)).date()
    to_utc_date = utc_today - timedelta(days=1)
    from_utc_date = to_utc_date - timedelta(days=lookback_days)
    return from_utc_date.isoformat(), to_utc_date.isoformat(), to_utc_date


def build_finbert_news_features(
    ticker: str,
    asof_kst: str,
    base_dir: str = "data/raw/news",
    text_fields: Tuple[str, ...] = ("title", "content", "text", "summary"),
) -> Dict[str, Any]:
    """
    SentimentalAgent ê°€ ì‚¬ìš©í•  FinBERT ì…ë ¥ìš© ë‰´ìŠ¤ í”¼ì²˜ ìƒì„±.
    - base_dir ê°€ ìƒëŒ€ê²½ë¡œë©´, í•­ìƒ 'í”„ë¡œì íŠ¸ ë£¨íŠ¸/ë°ì´í„°' ê¸°ì¤€ìœ¼ë¡œ í•´ì„í•˜ë„ë¡ ìˆ˜ì •.
    """
    fr, to, to_date_utc = _utc_from_kst_asof(asof_kst, lookback_days=40)
    symbol_us = f"{ticker}.US"

    # âœ… í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ì ˆëŒ€ ê²½ë¡œ ë§Œë“¤ê¸°
    #   agents/sentimental_agent.py â†’ capstone_project í´ë”
    project_root = Path(__file__).resolve().parent.parent
    base = Path(base_dir)
    if not base.is_absolute():
        base = project_root / base

    path = base / f"{symbol_us}_{fr}_{to}.json"
    print(f"[FinBERT] ìºì‹œ íƒìƒ‰: {path} (exists={path.exists()})")

    if not path.exists():
        print(f"[FinBERT] ë‰´ìŠ¤ ìºì‹œ ì—†ìŒ: {path}")
        return {
            "sentiment_summary": {"mean_7d": 0.0, "mean_30d": 0.0, "pos_ratio_7d": 0.0, "neg_ratio_7d": 0.0},
            "sentiment_volatility": {"vol_7d": 0.0},
            "news_count": {"count_1d": 0, "count_7d": 0},
            "trend_7d": 0.0,
            "has_news": False,
        }

    items = json.loads(path.read_text(encoding="utf-8"))
    if not isinstance(items, list):
        print(f"[FinBERT] ìºì‹œ í˜•ì‹ ê²½ê³ (list ì•„ë‹˜): {path}")
        return {
            "sentiment_summary": {"mean_7d": 0.0, "mean_30d": 0.0, "pos_ratio_7d": 0.0, "neg_ratio_7d": 0.0},
            "sentiment_volatility": {"vol_7d": 0.0},
            "news_count": {"count_1d": 0, "count_7d": 0},
            "trend_7d": 0.0,
            "has_news": False,
        }

    for it in items:
        for k in ("date", "published_date", "time", "pubDate"):
            if not isinstance(it.get(k), str):
                it[k] = ""

    print(f"[FinBERT] {len(items)}ê±´ ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ì‹œì‘... ({path.name})")
    scorer = FinBertScorer()
    scores = score_news_items(items, scorer=scorer, text_fields=text_fields)
    items_scored = attach_scores_to_items(items, scores)

    feats = compute_finbert_features(items_scored, asof_utc_date=to_date_utc)

    vol7 = feats.get("sentiment_volatility", {}).get("vol_7d", 0.0)
    feats["sentiment_volatility"] = {"vol_7d": vol7}

    print(
        f"[FinBERT] 7d_mean={feats['sentiment_summary']['mean_7d']:.3f} "
        f"7d_cnt={feats['news_count']['count_7d']}"
    )
    return feats


# ---------------------------------------------------------------
# ë³¸ì²´: SentimentalAgent
# ---------------------------------------------------------------
class SentimentalAgent(BaseAgent):  # type: ignore
    agent_id: str = "SentimentalAgent"

    def __init__(self, ticker: str, **kwargs):
        try:
            super().__init__(self.agent_id, ticker, **kwargs)  # type: ignore
        except TypeError:
            super().__init__(agent_id=self.agent_id, ticker=ticker, **kwargs)  # type: ignore

        if not getattr(self, "ticker", None):
            self.ticker = ticker
        if self.ticker is None or str(self.ticker).strip() == "":
            raise ValueError("SentimentalAgent: ticker is None/empty")
        self.ticker = str(self.ticker).upper()
        setattr(self, "symbol", self.ticker)

        cfg = (agents_info or {}).get(self.agent_id, {})
        if not cfg:
            print("[WARN] agents_info['SentimentalAgent'] ê°€ ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©")
            cfg = {
                "window_size": 40,
                "hidden_dim": 128,
                "dropout": 0.2,
                "epochs": 30,
                "learning_rate": 1e-3,
                "batch_size": 64,
                "x_scaler": "StandardScaler",
                "y_scaler": "StandardScaler",
                "gamma": 0.3,
                "delta_limit": 0.05,
            }
        self.window_size = cfg.get("window_size", 40)
        self.hidden_dim = cfg.get("hidden_dim", 128)
        self.dropout = cfg.get("dropout", 0.2)

        self.model: Optional[nn.Module] = None
        self.feature_cols: List[str] = []  # ğŸ‘ˆ ctxì—ì„œ ì¨ë¨¹ì„ ìš©ë„

        try:
            self._load_model_if_exists()
        except Exception as e:
            print("[SentimentalAgent] ëª¨ë¸ ë¡œë“œ ìŠ¤í‚µ:", e)

    def _build_model(self) -> nn.Module:
        """
        BaseAgent.pretrain()ì—ì„œ í˜¸ì¶œí•˜ëŠ” ëª¨ë¸ ìƒì„± í•¨ìˆ˜.
        SentimentalNet(LSTM) êµ¬ì¡°ë¥¼ ìƒì„±í•´ì„œ ë°˜í™˜.
        """
        try:
            X, y, cols = _load_dataset_compat(
                self.ticker,
                self.agent_id,
                window_size=self.window_size,
            )
        except Exception:
            # ë°ì´í„°ì…‹ì´ ì—†ë‹¤ë©´ ë¨¼ì € ìƒì„±
            _build_dataset_compat(
                self.ticker,
                self.agent_id,
                window_size=self.window_size,
            )
            X, y, cols = _load_dataset_compat(
                self.ticker,
                self.agent_id,
                window_size=self.window_size,
            )

        input_dim = X.shape[-1]
        self.feature_cols = list(cols)

        net = SentimentalNet(
            input_dim=input_dim,
            hidden_dim=self.hidden_dim,
            dropout=self.dropout,
        )
        return net

    def model_path(self) -> str:
        mdir = dir_info.get("model_dir", "models")
        Path(mdir).mkdir(parents=True, exist_ok=True)
        return os.path.join(mdir, f"{self.ticker}_{self.agent_id}.pt")

    def _sanitize_state_dict(self, sd: dict, model: nn.Module) -> dict:
        want = model.state_dict()
        new_sd = {}
        for k, v in sd.items():
            k2 = k
            if k2.startswith("module."):
                k2 = k2[len("module."):]
            if k2.startswith("_orig_mod."):
                k2 = k2[len("_orig_mod."):]
            if k2 not in want:
                continue
            new_sd[k2] = v
        return new_sd

    def _load_model_if_exists(self):
        p = self.model_path()
        if not os.path.exists(p):
            return

        if not self.ticker:
            raise ValueError("ticker is None in _load_model_if_exists")

        if self.model is None:
            self._build_model()
        net = self.model
        if net is None:
            raise RuntimeError("SentimentalAgent._load_model_if_exists: model ì´ˆê¸°í™” ì‹¤íŒ¨")

        sd = torch.load(p, map_location="cpu")

        if isinstance(sd, nn.Module):
            sd = sd.state_dict()
        elif isinstance(sd, dict) and "model_state_dict" in sd:
            sd = sd["model_state_dict"]
        elif not isinstance(sd, dict):
            raise RuntimeError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì²´í¬í¬ì¸íŠ¸ í˜•ì‹: {type(sd)}")

        sd = self._sanitize_state_dict(sd, net)
        net.load_state_dict(sd, strict=False)
        net.eval()
        self.model = net
        print(f"âœ… {self.ticker} {self.agent_id} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({p})")

    @torch.inference_mode()
    def _mc_dropout_predict(self, x: torch.Tensor, T: int = 30) -> Tuple[float, float]:
        if self.model is None:
            raise RuntimeError("model is None for MC Dropout")

        self.model.train()
        outs = []
        for _ in range(T):
            outs.append(self.model(x).detach())
        self.model.eval()

        y = torch.stack(outs, dim=0).squeeze(-1)
        mean = y.mean(dim=0)
        std = y.std(dim=0)
        return float(mean.squeeze().item()), float(std.squeeze().item())

    @torch.inference_mode()
    def _predict_next_close(self) -> Tuple[float, float, float, List[str]]:
        if not self.ticker:
            raise ValueError("ticker is None in _predict_next_close")

        try:
            X, y, cols = _load_dataset_compat(self.ticker, self.agent_id, window_size=self.window_size)
        except Exception:
            _build_dataset_compat(self.ticker, self.agent_id, window_size=self.window_size)
            X, y, cols = _load_dataset_compat(self.ticker, self.agent_id, window_size=self.window_size)

        last_close_idx = cols.index("Close") if "Close" in cols else -1
        fallback = float(X[-1, -1, last_close_idx]) if last_close_idx >= 0 else float("nan")

        if self.model is None:
            pred_close = fallback
            uncertainty_std = 0.10
            confidence = 1.0 / (1.0 + uncertainty_std)
            return pred_close, uncertainty_std, confidence, cols

        x_last = torch.tensor(X[-1:]).float()
        pred_close, uncertainty_std = self._mc_dropout_predict(x_last, T=30)
        confidence = float(1.0 / (1.0 + max(1e-6, uncertainty_std)))
        return pred_close, uncertainty_std, confidence, cols

    def build_ctx(self, asof_date_kst: Optional[str] = None) -> Dict[str, Any]:
        if asof_date_kst is None:
            asof_date_kst = datetime.now().strftime("%Y-%m-%d")

        pred_close, uncertainty_std, confidence, cols = self._predict_next_close()

        price_snapshot: Dict[str, Optional[float]] = {}
        try:
            X, _, cols2 = _load_dataset_compat(self.ticker, self.agent_id, window_size=self.window_size)
            last = X[-1, -1, :]
            snap_map = {c: float(v) for c, v in zip(cols2, last)}
            for k in ("Close", "Open", "High", "Low", "Volume", "returns"):
                if k in snap_map:
                    price_snapshot[k] = snap_map[k]
        except Exception:
            pass

        news_feats = build_finbert_news_features(
            self.ticker, asof_date_kst, base_dir=os.path.join("data", "raw", "news")
        )

        snapshot = {
            "asof_date": asof_date_kst,
            "last_price": price_snapshot.get("Close", np.nan),
            "currency": "USD",
            "window_size": self.window_size,
            "feature_cols_preview": [c for c in (cols or [])[:8]],
        }

        last_price = snapshot["last_price"]
        pred_return = float(pred_close / last_price - 1.0) if (last_price and last_price == last_price) else None

        feature_importance = {
            "sentiment_score": news_feats["sentiment_summary"]["mean_7d"],
            "sentiment_summary": news_feats["sentiment_summary"],
            "sentiment_volatility": {"vol_7d": news_feats["sentiment_volatility"].get("vol_7d", 0.0)},
            "trend_7d": news_feats["trend_7d"],
            "news_count": news_feats["news_count"],
            "has_news": news_feats.get("has_news", False),
            "price_snapshot": {
                "Close": price_snapshot.get("Close"),
                "Open": price_snapshot.get("Open"),
                "High": price_snapshot.get("High"),
                "Low": price_snapshot.get("Low"),
                "Volume": price_snapshot.get("Volume"),
                "ret_1d": None,
                "ret_5d": None,
                "ret_20d": None,
                "zscore_20d": None,
                "vol_change_5d": None,
            },
        }

        ctx = {
            "agent_id": self.agent_id,
            "ticker": self.ticker,
            "snapshot": snapshot,
            "prediction": {
                "pred_close": pred_close,
                "pred_return": pred_return,
                "uncertainty": {"std": uncertainty_std, "ci95": float(1.96 * uncertainty_std)},
                "confidence": confidence,
                "pred_next_close": pred_close,
            },
            "feature_importance": feature_importance,
        }
        return ctx

    # --------------------------
    # BaseAgent ê·œì•½ ì¶©ì¡±: LLM(system/user) ë©”ì‹œì§€ ìƒì„± (Opinion)
    # --------------------------
    def _build_messages_opinion(
        self,
        stock_data: "StockData",
        target: "Target",
    ):
        """
        SentimentalAgent ì „ìš© Opinion í”„ë¡¬í”„íŠ¸ ë¹Œë”
        - self.stockdata.SentimentalAgent ì—ì„œ í”¼ì²˜ ìŠ¤ëƒ…ìƒ·ì„ ë½‘ê³ 
        - target(next_close, uncertainty, confidence)ê¹Œì§€ í•©ì³ ctx(JSON)ì„ ë§Œë“  ë’¤
        - OPINION_PROMPTS['SentimentalAgent']ì— ì£¼ì…
        """
        from prompts import OPINION_PROMPTS  # ìƒë‹¨ì— ì´ë¯¸ ìˆìœ¼ë©´ ìƒëµ ê°€ëŠ¥

        # 0) stock_dataê°€ Noneìœ¼ë¡œ ë“¤ì–´ì˜¤ë©´ self.stockdata ì‚¬ìš©
        if stock_data is None:
            stock_data = self.stockdata

        # 1) ctx ê¸°ë³¸ êµ¬ì¡° ë§Œë“¤ê¸° ---------------------------------
        ctx: Dict[str, Any] = {}

        # (1) ê¸°ë³¸ ë©”íƒ€ ì •ë³´
        ctx["ticker"] = getattr(stock_data, "ticker", self.ticker)
        ctx["currency"] = getattr(stock_data, "currency", "USD")
        last_close = getattr(stock_data, "last_price", None)
        ctx["last_close"] = last_close
        ctx["next_close"] = float(getattr(target, "next_close", None) or 0.0)

        # (2) ì˜ˆìƒ ë³€í™”ìœ¨ (ìˆìœ¼ë©´)
        change_ratio = None
        if isinstance(last_close, (int, float)) and last_close not in (0, None):
            change_ratio = ctx["next_close"] / float(last_close) - 1.0
        ctx["change_ratio"] = change_ratio

        # (3) ë¶ˆí™•ì‹¤ì„± / ì‹ ë¢°ë„
        ctx["uncertainty_std"] = getattr(target, "uncertainty", None)
        ctx["confidence"] = getattr(target, "confidence", None)

        # (4) SentimentalAgent í”¼ì²˜ ìŠ¤ëƒ…ìƒ· (ë§ˆì§€ë§‰ ì‹œì ë§Œ ì¶”ì¶œ)
        snap = getattr(stock_data, "SentimentalAgent", {}) or {}
        # stock_data.SentimentalAgent ëŠ” {ì»¬ëŸ¼ëª…: [ì‹œê³„ì—´ê°’...]} êµ¬ì¡°ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
        for k, v in snap.items():
            if isinstance(v, (list, tuple)) and len(v) > 0:
                ctx[k] = v[-1]
            else:
                ctx[k] = v

        # 2) JSON ë¬¸ìì—´ë¡œ ë³€í™˜ -----------------------------------
        ctx_json = json.dumps(ctx, ensure_ascii=False, indent=2)

        # 3) í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì ìš© ---------------------------------
        prompts = OPINION_PROMPTS.get("SentimentalAgent", {})
        system_text = prompts.get("system", "ë„ˆëŠ” ê°ì„±/ë‰´ìŠ¤ ì¤‘ì‹¬ì˜ ë‹¨ê¸° ì£¼ê°€ ë¶„ì„ê°€ë‹¤.")
        user_tmpl = prompts.get(
            "user",
            "ctx(JSON):\n{}\n\nìœ„ ctxë¥¼ ë°”íƒ•ìœ¼ë¡œ reasonì„ ìƒì„±í•˜ë¼.",
        )

        # user í…ìŠ¤íŠ¸ëŠ” {}, {context} ë‘˜ ë‹¤ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
        try:
            # 1ìˆœìœ„: {context} ì‚¬ìš©í•˜ëŠ” í…œí”Œë¦¿
            user_text = user_tmpl.format(context=ctx_json)
        except KeyError:
            try:
                # 2ìˆœìœ„: {} ìœ„ì¹˜ ê¸°ë°˜ í…œí”Œë¦¿
                user_text = user_tmpl.format(ctx_json)
            except Exception:
                # ê·¸ë˜ë„ ì‹¤íŒ¨í•˜ë©´ ê·¸ëƒ¥ ì¹˜í™˜
                user_text = user_tmpl.replace("{context}", ctx_json)

        return system_text, user_text

    # --------------------------
    # BaseAgent ê·œì•½ ì¶©ì¡±: LLM(system/user) ë©”ì‹œì§€ ìƒì„± (Rebuttal)
    # --------------------------
    def _build_messages_rebuttal(self, *args, **kwargs) -> Tuple[str, str]:
        """
        ë‹¤ì–‘í•œ í˜¸ì¶œ ì‹œê·¸ë‹ˆì²˜ë¥¼ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬:
         - (stock_data, target, opponent_opinion)
         - í‚¤ì›Œë“œ: opponent / opponent_opinion / other_opinion / other
        """
        # 1) ì¸ì íŒŒì‹±
        stock_data = args[0] if len(args) > 0 else kwargs.get("stock_data")
        target: Optional[Target] = args[1] if len(args) > 1 else kwargs.get("target")

        opponent = None
        # ìš°ì„ ìˆœìœ„ë¡œ opponent í›„ë³´ë¥¼ ì°¾ëŠ”ë‹¤
        for key in ("opponent", "opponent_opinion", "other_opinion", "other", "opinion"):
            if key in kwargs:
                opponent = kwargs[key]
                break
        if opponent is None and len(args) > 2:
            opponent = args[2]

        # Opinion or dict or str ëª¨ë‘ ìˆ˜ìš©
        if isinstance(opponent, Opinion):
            opp_agent = getattr(opponent, "agent_id", "UnknownAgent")
            opp_reason = getattr(opponent, "reason", "")
        elif isinstance(opponent, dict):
            opp_agent = opponent.get("agent_id", "UnknownAgent")
            opp_reason = opponent.get("reason", "")
        else:
            opp_agent = "UnknownAgent"
            opp_reason = str(opponent) if opponent is not None else ""

        # 2) ì»¨í…ìŠ¤íŠ¸/ê°’ ì¤€ë¹„
        ctx = self.build_ctx()
        fi = ctx.get("feature_importance", {})
        sent = fi.get("sentiment_summary", {})
        vol7 = fi.get("sentiment_volatility", {}).get("vol_7d", None)
        trend7 = fi.get("trend_7d", None)
        news7 = fi.get("news_count", {}).get("count_7d", None)

        pred_close = float(target.next_close) if target else float(ctx["prediction"]["pred_next_close"])
        last_price = ctx.get("snapshot", {}).get("last_price")
        change_ratio = None
        if last_price and last_price == last_price and last_price != 0:
            change_ratio = pred_close / last_price - 1.0

        # 3) í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        system_tmpl = None
        user_tmpl = None
        if REBUTTAL_PROMPTS and "SentimentalAgent" in REBUTTAL_PROMPTS:
            pp = REBUTTAL_PROMPTS["SentimentalAgent"]
            system_tmpl = pp.get("system")
            user_tmpl = pp.get("user")

        if not system_tmpl:
            system_tmpl = (
                "ë‹¹ì‹ ì€ ê°ì„± ê¸°ë°˜ ë‹¨ê¸° ì£¼ê°€ ë¶„ì„ê°€ë¡œì„œ ìƒëŒ€ ì˜ê²¬ì˜ ë…¼ë¦¬ì /ìˆ˜ì¹˜ì  í—ˆì ì„ ë¶„ì„í•´ ë°˜ë°•í•©ë‹ˆë‹¤. "
                "ê°ì„±ì§€í‘œ(í‰ê· , ì¶”ì„¸, ë³€ë™ì„±)ì™€ ë‰´ìŠ¤ ê°œìˆ˜, ì˜ˆì¸¡ì˜ ë¶ˆí™•ì‹¤ì„±ì„ ê·¼ê±°ë¡œ ì‚¼ë˜, "
                "í•©ë¦¬ì  í¬ì¸íŠ¸ëŠ” ì¸ì •í•˜ê³  í•µì‹¬ ìŸì  ìœ„ì£¼ë¡œ ê°„ê²°íˆ ë°˜ë°•í•˜ì„¸ìš”."
            )

        if not user_tmpl:
            user_tmpl = (
                "í‹°ì»¤: {ticker}\n"
                "ìƒëŒ€ ì—ì´ì „íŠ¸: {opp_agent}\n"
                "ìƒëŒ€ ì˜ê²¬:\n{opp_reason}\n\n"
                "ìš°ë¦¬ ì˜ˆì¸¡:\n- next_close: {pred_close}\n- ì˜ˆìƒ ë³€í™”ìœ¨(í˜„ì¬ê°€ ëŒ€ë¹„): {chg}\n"
                "ê°ì„± ê·¼ê±°:\n- mean7={mean7}, mean30={mean30}, pos7={pos7}, neg7={neg7}\n"
                "- vol7={vol7}, trend7={trend7}, news7={news7}\n\n"
                "ìš”ì²­: ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒëŒ€ ì˜ê²¬ì˜ ì•½ì  2~4ê°œë¥¼ ì¡°ëª©ì¡°ëª© ë°˜ë°•í•˜ì„¸ìš”. "
                "íŠ¹íˆ ê°ì„± ì¶”ì„¸/ë³€ë™ì„±, ë‰´ìŠ¤ ìˆ˜ì˜ ë§¥ë½, ì˜ˆì¸¡ ë¶ˆí™•ì‹¤ì„±(ë†’/ë‚®ìŒ)ì´ "
                "ìƒëŒ€ ì£¼ì¥ê³¼ ì–´ë–»ê²Œ ìƒì¶©/ë³´ì™„ë˜ëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì§€ì í•˜ì„¸ìš”."
            )

        user_text = user_tmpl.format(
            ticker=self.ticker,
            opp_agent=opp_agent,
            opp_reason=opp_reason if opp_reason else "(ìƒëŒ€ ì˜ê²¬ ë‚´ìš© ì—†ìŒ)",
            pred_close=f"{pred_close:.4f}",
            chg=("NA" if change_ratio is None else f"{change_ratio*100:.2f}%"),
            mean7=f"{sent.get('mean_7d', 0.0):.4f}",
            mean30=f"{sent.get('mean_30d', 0.0):.4f}",
            pos7=f"{sent.get('pos_ratio_7d', 0.0):.4f}",
            neg7=f"{sent.get('neg_ratio_7d', 0.0):.4f}",
            vol7=("NA" if vol7 is None else f"{vol7:.4f}"),
            trend7=("NA" if trend7 is None else f"{trend7:.4f}"),
            news7=("NA" if news7 is None else f"{news7}"),
        )
        return system_tmpl, user_text

    # --------------------------
    # BaseAgent ê·œì•½ ì¶©ì¡±: LLM(system/user) ë©”ì‹œì§€ ìƒì„± (Revision)
    # --------------------------
    def _build_messages_revision(self, *args, **kwargs) -> Tuple[str, str]:
        """
        ë‹¤ì–‘í•œ í˜¸ì¶œ ì‹œê·¸ë‹ˆì²˜ë¥¼ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬:
         - (stock_data, target, previous_opinion, rebuttals)
         - í‚¤ì›Œë“œ: previous / previous_opinion / draft / rebuttals / replies
        """
        # 1) ì¸ì íŒŒì‹±
        stock_data = args[0] if len(args) > 0 else kwargs.get("stock_data")
        target: Optional[Target] = args[1] if len(args) > 1 else kwargs.get("target")

        prev = None
        rebs = None
        for key in ("previous", "previous_opinion", "draft", "opinion"):
            if key in kwargs:
                prev = kwargs[key]
                break
        if prev is None and len(args) > 2:
            prev = args[2]

        for key in ("rebuttals", "replies", "responses"):
            if key in kwargs:
                rebs = kwargs[key]
                break
        if rebs is None and len(args) > 3:
            rebs = args[3]

        def _op_text(x: Union[Opinion, Dict[str, Any], str, None]) -> str:
            if isinstance(x, Opinion):
                return getattr(x, "reason", "")
            if isinstance(x, dict):
                return x.get("reason", "")
            return x or ""

        prev_reason = _op_text(prev)

        # rebuttalsëŠ” ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ ìˆìŒ
        reb_texts: List[str] = []
        if isinstance(rebs, list):
            for r in rebs:
                reb_texts.append(_op_text(r))
        elif rebs is not None:
            reb_texts.append(_op_text(rebs))

        # 2) ì»¨í…ìŠ¤íŠ¸/ê°’ ì¤€ë¹„
        ctx = self.build_ctx()
        fi = ctx.get("feature_importance", {})
        sent = fi.get("sentiment_summary", {})
        vol7 = fi.get("sentiment_volatility", {}).get("vol_7d", None)
        trend7 = fi.get("trend_7d", None)
        news7 = fi.get("news_count", {}).get("count_7d", None)

        pred_close = float(target.next_close) if target else float(ctx["prediction"]["pred_next_close"])
        last_price = ctx.get("snapshot", {}).get("last_price")
        change_ratio = None
        if last_price and last_price == last_price and last_price != 0:
            change_ratio = pred_close / last_price - 1.0

        # 3) í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        system_tmpl = None
        user_tmpl = None
        if REVISION_PROMPTS and "SentimentalAgent" in REVISION_PROMPTS:
            pp = REVISION_PROMPTS["SentimentalAgent"]
            system_tmpl = pp.get("system")
            user_tmpl = pp.get("user")

        if not system_tmpl:
            system_tmpl = (
                "ë‹¹ì‹ ì€ ê°ì„± ê¸°ë°˜ ë‹¨ê¸° ì£¼ê°€ ë¶„ì„ê°€ì…ë‹ˆë‹¤. "
                "ì´ˆì•ˆ ì˜ê²¬ê³¼ ë°˜ë°•ë“¤ì„ ê²€í† í•´ í•µì‹¬ë§Œ ë‚¨ê¸°ê³ , ë°ì´í„°ì— ê·¼ê±°í•´ ê²°ë¡ ì„ ë” ëª…í™•íˆ ë‹¤ë“¬ìŠµë‹ˆë‹¤. "
                "ë¶ˆí™•ì‹¤ì„±/ì‹ ë¢°ë„ í•´ì„ì„ í¬í•¨í•˜ì—¬ í•œ ë‹¨ê³„ ë” ê²¬ê³ í•œ ìµœì¢… ì˜ê²¬ìœ¼ë¡œ ìˆ˜ì •í•˜ì„¸ìš”."
            )

        if not user_tmpl:
            user_tmpl = (
                "í‹°ì»¤: {ticker}\n"
                "ì´ˆì•ˆ ì˜ê²¬:\n{prev}\n\n"
                "ìˆ˜ì‹ í•œ ë°˜ë°• ìš”ì•½:\n{rebuts}\n\n"
                "ì—…ë°ì´íŠ¸ëœ ìˆ˜ì¹˜:\n- next_close: {pred_close}\n- ì˜ˆìƒ ë³€í™”ìœ¨: {chg}\n"
                "ê°ì„± ê·¼ê±° ìŠ¤ëƒ…ìƒ·:\n- mean7={mean7}, mean30={mean30}, pos7={pos7}, neg7={neg7}\n"
                "- vol7={vol7}, trend7={trend7}, news7={news7}\n\n"
                "ìš”ì²­: ì´ˆì•ˆì—ì„œ ê³¼ì¥/ì¤‘ë³µ/ì•½í•œ ê·¼ê±°ë¥¼ ì •ë¦¬í•˜ê³ , ê°•í•œ ê·¼ê±°(ê°ì„± ì¶”ì„¸, ë³€ë™ì„± ì•ˆì •/í™•ëŒ€, ë‰´ìŠ¤ ìˆ˜ ë³€í™”)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ "
                "ìµœì¢… ì˜ê²¬ì„ 3~5ë¬¸ì¥ìœ¼ë¡œ ì¬ì‘ì„±í•˜ì„¸ìš”. ë¶ˆí™•ì‹¤ì„±(í‘œì¤€í¸ì°¨)/ì‹ ë¢°ë„ í•´ì„ì„ í•¨ê»˜ ì œì‹œí•˜ì„¸ìš”."
            )

        rebuts_joined = "- " + "\n- ".join([s for s in reb_texts if s]) if reb_texts else "(ë°˜ë°• ì—†ìŒ)"

        user_text = user_tmpl.format(
            ticker=self.ticker,
            prev=prev_reason if prev_reason else "(ì´ˆì•ˆ ì—†ìŒ)",
            rebuts=rebuts_joined,
            pred_close=f"{pred_close:.4f}",
            chg=("NA" if change_ratio is None else f"{change_ratio*100:.2f}%"),
            mean7=f"{sent.get('mean_7d', 0.0):.4f}",
            mean30=f"{sent.get('mean_30d', 0.0):.4f}",
            pos7=f"{sent.get('pos_ratio_7d', 0.0):.4f}",
            neg7=f"{sent.get('neg_ratio_7d', 0.0):.4f}",
            vol7=("NA" if vol7 is None else f"{vol7:.4f}"),
            trend7=("NA" if trend7 is None else f"{trend7:.4f}"),
            news7=("NA" if news7 is None else f"{news7}"),
        )
        return system_tmpl, user_text

    # --------------------------
    # Opinion ìƒì„±
    # --------------------------
    def get_opinion(self, idx: int = 0, ticker: Optional[str] = None) -> Opinion:
        if ticker and ticker != self.ticker:
            self.ticker = str(ticker).upper()

        pred_close, uncertainty_std, confidence, _ = self._predict_next_close()
        target = Target(
            next_close=float(pred_close),
            uncertainty=float(uncertainty_std),
            confidence=float(confidence),
        )

        # LLM ê²½ë¡œ ì‹œë„
        try:
            if hasattr(self, "reviewer_draft"):
                op = self.reviewer_draft(getattr(self, "stockdata", None), target)
                return op
        except Exception as e:
            print("[SentimentalAgent] reviewer_draft ì‚¬ìš© ì‹¤íŒ¨:", e)

        # fallback (context ë°˜ë“œì‹œ í¬í•¨)
        ctx = self.build_ctx()
        fi = ctx["feature_importance"]
        sent = fi["sentiment_summary"]

        reason = (
            f"{self.ticker}ì˜ ìµœê·¼ 7ì¼ ê°ì„± í‰ê· ì€ {sent['mean_7d']:.3f}ì´ë©° "
            f"ë‰´ìŠ¤ ê°œìˆ˜(7d)ëŠ” {fi['news_count']['count_7d']}ê±´ì…ë‹ˆë‹¤. "
            f"ê°ì„± ë³€ë™ì„±(vol_7d)={fi['sentiment_volatility']['vol_7d']:.3f}, "
            f"ê°ì„± ì¶”ì„¸(trend_7d)={fi['trend_7d']:.3f}ì…ë‹ˆë‹¤."
        )

        return Opinion(
            agent_id=self.agent_id,
            target=target,
            reason=reason,
            context=ctx,      # â˜… DebateAgentê°€ ë³´ëŠ” context
        )
