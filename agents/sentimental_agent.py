# agents/sentimental_agent.py

from __future__ import annotations

import os
import json
from typing import Optional, Tuple, Dict, Any, List, Union
from pathlib import Path
from datetime import datetime, timedelta, date

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import joblib
import yfinance as yf

from agents.base_agent import BaseAgent, StockData, Target, Opinion, Rebuttal
from config.agents import agents_info, dir_info
from core.utils_datetime import today_kst
from core.data_set import load_dataset, build_dataset, get_latest_close_price
from core.data_set import StockData, Target
from core.sentimental_classes.lstm_model import SentimentalLSTM
from core.sentimental_classes.news import merge_price_with_news_features
from prompts import OPINION_PROMPTS, REBUTTAL_PROMPTS, REVISION_PROMPTS
from core.sentimental_classes.train_sentimental import LSTMModel 
from sklearn.preprocessing import StandardScaler
from core.sentimental_classes.train_sentimental import (
    LSTMModel,
    FEATURE_COLS,
    WINDOW_SIZE,
    HIDDEN_DIM,
    NUM_LAYERS,
    DROPOUT,
)

# FinBERT / ë‰´ìŠ¤ ìœ í‹¸
FinBertScorer: Any | None = None
load_or_fetch_news: Any | None = None
score_news_items: Any | None = None
attach_scores_to_items: Any | None = None
compute_finbert_features: Any | None = None
from core.sentimental_classes.train_sentimental import (
    LSTMModel,
    FEATURE_COLS,
    WINDOW_SIZE,
    HIDDEN_DIM,
    NUM_LAYERS,
    DROPOUT,
)

try:
    from core.sentimental_classes.finbert_utils import (
        FinBertScorer,
        load_or_fetch_news,
        score_news_items,
        attach_scores_to_items,
        compute_finbert_features,
    )
except Exception as e:
    print("[warn] FinBERT ìœ í‹¸ ë¡œë“œ ì‹¤íŒ¨:", repr(e))
    FinBertScorer = None
    load_or_fetch_news = None
    score_news_items = None
    attach_scores_to_items = None
    compute_finbert_features = None

USE_FINBERT = all(
    x is not None
    for x in [
        FinBertScorer,
        score_news_items,
        attach_scores_to_items,
        compute_finbert_features,
    ]
)

FEATURE_COLS_8 = [
    "return_1d",
    "hl_range",
    "Volume",
    "news_count_1d",
    "news_count_7d",
    "sentiment_mean_1d",
    "sentiment_mean_7d",
    "sentiment_vol_7d",
]

class DataScaler:
    """
    SentimentalAgent ì „ìš© ìŠ¤ì¼€ì¼ëŸ¬
    - X: (N, T, F) ì‹œí€€ìŠ¤ë¥¼ ë°›ì•„ feature ë‹¨ìœ„ë¡œ StandardScaler ì ìš©
    - BaseAgent.pretrainì—ì„œ ê¸°ëŒ€í•˜ëŠ” ì¸í„°í˜ì´ìŠ¤(ì˜ˆìƒ):
      * fit_scalers(X, y)
      * transform_dataset(X, y) -> (X_scaled, y_scaled)
      * save_meta(ticker, agent_id)
      * load_meta(ticker, agent_id)
    """

    def __init__(self, feature_cols: List[str], window_size: int = 40):
        self.feature_cols = list(feature_cols)
        self.window_size = int(window_size)
        self.scaler = StandardScaler()

    def fit_scalers(self, X: np.ndarray, y: np.ndarray | None = None):
        """(N, T, F) ì „ì²´ì— ëŒ€í•´ feature ë‹¨ìœ„ í‰ê· /í‘œì¤€í¸ì°¨ í•™ìŠµ"""
        if X.ndim != 3:
            raise ValueError(f"DataScaler.fit_scalers expects 3D array, got shape={X.shape}")
        n, t, f = X.shape
        X_flat = X.reshape(n * t, f)
        self.scaler.fit(X_flat)
        return self

    def transform_dataset(self, X: np.ndarray, y: np.ndarray):
        """í•™ìŠµëœ ìŠ¤ì¼€ì¼ëŸ¬ë¡œ Xë§Œ ë³€í™˜, yëŠ” ê·¸ëŒ€ë¡œ ë°˜í™˜"""
        if X.ndim != 3:
            raise ValueError(f"DataScaler.transform_dataset expects 3D array, got shape={X.shape}")
        n, t, f = X.shape
        X_flat = X.reshape(n * t, f)
        X_scaled = self.scaler.transform(X_flat)
        X_scaled = X_scaled.reshape(n, t, f)
        return X_scaled.astype(np.float32), y.astype(np.float32)

    def save_meta(self, ticker: str, agent_id: str = "SentimentalAgent"):
        """ìŠ¤ì¼€ì¼ëŸ¬ì™€ ë©”íƒ€ ì •ë³´ë¥¼ models/scalers ì•„ë˜ì— ì €ì¥"""
        model_dir = Path("models/scalers")
        model_dir.mkdir(parents=True, exist_ok=True)
        path = model_dir / f"{ticker}_{agent_id}.pkl"
        joblib.dump(self, path)
        print(f"[DataScaler.save_meta] saved to {path}")

    @classmethod
    def load_meta(cls, ticker: str, agent_id: str = "SentimentalAgent"):
        """ì €ì¥ëœ ìŠ¤ì¼€ì¼ëŸ¬ ë©”íƒ€ê°€ ìˆìœ¼ë©´ ë¡œë“œ, ì—†ìœ¼ë©´ None"""
        path = Path("models/scalers") / f"{ticker}_{agent_id}.pkl"
        if not path.exists():
            print(f"[DataScaler.load_meta] no scaler file: {path}")
            return None
        scaler = joblib.load(path)
        print(f"[DataScaler.load_meta] loaded from {path}")
        return scaler

class SentimentalAgent(BaseAgent):
    def __init__(self, ticker: str, agent_id: str = "SentimentalAgent", **kwargs):
        # 0) BaseAgent ì´ˆê¸°í™” (í•œ ë²ˆë§Œ!)
        super().__init__(ticker=ticker, agent_id=agent_id, **kwargs)

        # 1) ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # 2) train_sentimental.py ì˜ ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë°˜ì˜
        #    (ì´ë¯¸ ìƒë‹¨ì—ì„œ HIDDEN_DIM, NUM_LAYERS, DROPOUT, WINDOW_SIZE, FEATURE_COLS import ë˜ì–´ ìˆë‹¤ê³  ê°€ì •)
        self.window_size: int = int(WINDOW_SIZE)
        self.hidden_dim: int = int(HIDDEN_DIM)
        self.num_layers: int = int(NUM_LAYERS)
        self.dropout: float = float(DROPOUT)

        # 3) feature ëª©ë¡ (í›ˆë ¨ ë•Œ ì‚¬ìš©í•œ ì „ì²´ ë¦¬ìŠ¤íŠ¸)
        self.feature_cols: List[str] = list(FEATURE_COLS)
        input_dim = len(self.feature_cols)

        # 4) agents_info ì„¤ì •ìœ¼ë¡œ override (ìˆìœ¼ë©´)
        cfg = (agents_info or {}).get(agent_id, {})
        if not cfg:
            print("[WARN] agents_info['SentimentalAgent'] ì—†ìŒ â†’ ê¸°ë³¸ê°’ ì‚¬ìš©")
            cfg = {
                "window_size": self.window_size,
                "hidden_dim": self.hidden_dim,
                "dropout": self.dropout,
                "epochs": 30,
                "learning_rate": 1e-3,
                "batch_size": 64,
                "gamma": 0.3,
                "delta_limit": 0.05,
            }

        # config ê¸°ë°˜ìœ¼ë¡œ ë®ì–´ì“°ê¸°
        self.window_size = cfg.get("window_size", self.window_size)
        self.hidden_dim = cfg.get("hidden_dim", self.hidden_dim)
        self.dropout = cfg.get("dropout", self.dropout)
        # num_layers ë„ configì— ìˆìœ¼ë©´ ë°˜ì˜
        self.num_layers = cfg.get("num_layers", self.num_layers)

        # 5) LSTM ëª¨ë¸ êµ¬ì„± (í•œ ë²ˆë§Œ!)
        self.model: nn.Module = SentimentalLSTM(
            input_dim=input_dim,
            hidden_dim=self.hidden_dim,
            num_layers=self.num_layers,
            dropout=self.dropout,
        ).to(self.device)

        self.model_loaded: bool = False

        # 6) ì‚¬ì „ í•™ìŠµ weight ë¡œë“œ
        state_path = f"models/{ticker}_SentimentalAgent.pt"
        try:
            state = torch.load(state_path, map_location=self.device)
            self.model.load_state_dict(state)
            self.model.eval()
            self.model_loaded = True
            print(f"[SentimentalAgent] ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ë¡œë“œ: {state_path}")
        except Exception as e:
            print(f"[SentimentalAgent] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

        # 7) ê¸°íƒ€ ìƒíƒœ ë³€ìˆ˜
        self.last_price: Optional[float] = None
        self.currency: str = "USD"
        self._last_input: Optional[np.ndarray] = None  # (1, T, F)
        self.stockdata: Optional[StockData] = None
        self.window_size = cfg.get("window_size", self.window_size)
        self.hidden_dim = cfg.get("hidden_dim", self.hidden_dim)
        self.dropout = cfg.get("dropout", self.dropout)
        self.epochs = cfg.get("epochs", 30)
        self.learning_rate = cfg.get("learning_rate", 1e-3)
        self.batch_size = cfg.get("batch_size", 64)
        self.gamma = cfg.get("gamma", 0.3)
        self.delta_limit = cfg.get("delta_limit", 0.05)

        # --- LSTM ê°€ì¤‘ì¹˜ ë¡œë“œ ---
        try:
            self._load_model_only()
        except Exception as e:
            print(f"[SentimentalAgent] ì´ˆê¸° ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜ˆì™¸ (ë¬´ì‹œ): {e}")

    def _load_model_only(self) -> None:
        """ìŠ¤ì¼€ì¼ëŸ¬ëŠ” DataScalerê°€ ê´€ë¦¬í•˜ë‹ˆê¹Œ, ì—¬ê¸°ì„  LSTM ê°€ì¤‘ì¹˜ë§Œ ë¡œë“œ"""
        base_name = f"{self.ticker}_SentimentalAgent"
        model_path = Path("models") / f"{base_name}.pt"

        if model_path.exists():
            try:
                state = torch.load(model_path, map_location=self.device)
                missing, unexpected = self.model.load_state_dict(state, strict=False)
                print(f"[SentimentalAgent] ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ë¡œë“œ: {model_path}")
                if missing or unexpected:
                    print("[SentimentalAgent] state_dict mismatch:",
                          "missing:", missing, "/ unexpected:", unexpected)
                else:
                    self.model_loaded = True
            except Exception as e:
                print(f"[SentimentalAgent] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.model_loaded = False
        else:
            print(f"[SentimentalAgent] ì‚¬ì „ í•™ìŠµ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
            self.model_loaded = False

    def _convert_uncertainty_to_confidence(self, sigma: float) -> float:
        """
        í‘œì¤€í¸ì°¨ sigmaê°€ ì‘ì„ìˆ˜ë¡ confidence(0~1)ê°€ ì»¤ì§€ë„ë¡ ë³€í™˜.
        """
        import numpy as np
        sigma = float(abs(sigma) or 1e-6)
        return float(1.0 / (1.0 + np.log1p(sigma)))

    def run_dataset(self, days: int = 365) -> StockData:
        """
        ìµœê·¼ daysì¼ì¹˜ ê°€ê²© + ë‰´ìŠ¤ í”¼ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ
        1) FEATURE_COLS ì…ë ¥ í–‰ë ¬ ìƒì„±
        2) LSTM ì…ë ¥ ìœˆë„ìš°(1, T, F) ìƒì„±
        3) StockData ì´ˆê¸° ìŠ¤ëƒ…ìƒ· ìƒì„±
        """

        import pandas as pd
        import numpy as np
        from core.sentimental_classes.news import merge_price_with_news_features
        from core.sentimental_classes.train_sentimental import FEATURE_COLS, WINDOW_SIZE

        # ------------------------------------------------------------
        # 0) ë‚ ì§œ ë²”ìœ„ ì„¤ì •
        # ------------------------------------------------------------
        end = pd.Timestamp.today().normalize()
        start = end - pd.Timedelta(days=days)

        # ------------------------------------------------------------
        # 1) ê°€ê²© ë°ì´í„° (yfinance)
        # ------------------------------------------------------------
        df_price = yf.download(self.ticker, start=start, end=end)

        # yfinance MultiIndex column ëŒ€ì‘ + ì†Œë¬¸ì í†µì¼
        if isinstance(df_price.columns, pd.MultiIndex):
            df_price.columns = [c[0].lower() for c in df_price.columns]
        else:
            df_price.columns = [c.lower() for c in df_price.columns]

        df_price = df_price.rename(
            columns={
                "open": "open",
                "high": "high",
                "low": "low",
                "close": "close",
                "volume": "volume",
            }
        )

        df_price["date"] = df_price.index
        df_price = df_price.reset_index(drop=True)

        # ------------------------------------------------------------
        # 2) ë‰´ìŠ¤ + ê°€ê²© ë³‘í•© (7ì¼ ì§‘ê³„ í”¼ì²˜ í¬í•¨)
        # ------------------------------------------------------------
        df_merged = merge_price_with_news_features(
            df_price=df_price,
            ticker=self.ticker,
            asof_kst=end.date(),
            base_dir=os.path.join("data", "raw", "news"),
        )

        # merge_price_with_news_features ê°€ (df, meta) íŠœí”Œì„ ë°˜í™˜í•˜ëŠ” ê²½ìš° ë°©ì–´
        if isinstance(df_merged, tuple):
            df_merged_df = df_merged[0]
        else:
            df_merged_df = df_merged

        # ------------------------------------------------------------
        # 3) FEATURE_COLS ëˆ„ë½ ìë™ ë³´ì •
        # ------------------------------------------------------------
        df_feat = df_merged_df.sort_values("date").reset_index(drop=True)

        required_cols = list(FEATURE_COLS)
        missing = [c for c in required_cols if c not in df_feat.columns]
        print("[SentimentalAgent.run_dataset] missing(before):", missing)

        # --- ì»¬ëŸ¼ ëŒ€ì†Œë¬¸ì í†µì¼ (ì´ë¯¸ ì†Œë¬¸ìì¼ ê°€ëŠ¥ì„±ì´ ë†’ì§€ë§Œ ë°©ì–´) ---
        close_col = "close" if "close" in df_feat.columns else None
        high_col = "high" if "high" in df_feat.columns else None
        low_col = "low" if "low" in df_feat.columns else None

        # --- return_1d: ì¢…ê°€ ê¸°ì¤€ 1ì¼ ìˆ˜ìµë¥  ---
        if "return_1d" in missing:
            if close_col is not None:
                df_feat["return_1d"] = df_feat[close_col].pct_change().fillna(0.0)
            else:
                print("[SentimentalAgent.run_dataset] WARN: close column not found, return_1d filled with 0.0")
                df_feat["return_1d"] = 0.0

        # --- hl_range: (ê³ ê°€-ì €ê°€)/ì¢…ê°€ ---
        if "hl_range" in missing:
            if high_col is not None and low_col is not None and close_col is not None:
                rng = (df_feat[high_col] - df_feat[low_col]) / df_feat[close_col].replace(0, np.nan)
                df_feat["hl_range"] = rng.fillna(0.0)
            else:
                print("[SentimentalAgent.run_dataset] WARN: high/low/close missing, hl_range filled with 0.0")
                df_feat["hl_range"] = 0.0

        # --- Volume: ì†Œë¬¸ì volume â†’ ëŒ€ë¬¸ì Volume ë§ì¶”ê¸° ---
        if "Volume" not in df_feat.columns:
            if "volume" in df_feat.columns:
                df_feat["Volume"] = df_feat["volume"].fillna(0.0)
            else:
                df_feat["Volume"] = 0.0

        # --- ë‰´ìŠ¤ 1ì¼ ê¸°ì¤€ í”¼ì²˜(ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì±„ìš°ê¸°) ---
        for col in ["news_count_1d", "sentiment_mean_1d"]:
            if col not in df_feat.columns:
                df_feat[col] = 0.0

        # ------------------------------------------------------------
        # 4) ìµœì¢… FEATURE_COLS ê²€ì¦
        # ------------------------------------------------------------
        missing_after = [c for c in required_cols if c not in df_feat.columns]
        if missing_after:
            raise ValueError(
                f"[SentimentalAgent.run_dataset] FEATURE_COLS ì¤‘ ì•„ì§ ì—†ëŠ” ì»¬ëŸ¼: {missing_after}\n"
                f"í˜„ì¬ df_feat.columns = {df_feat.columns.tolist()}"
            )

        print("[SentimentalAgent.run_dataset] all FEATURE_COLS present.")

        # ------------------------------------------------------------
        # 5) ì‹œê³„ì—´ íŠ¹ì„± í–‰ë ¬ ìƒì„±
        # ------------------------------------------------------------
        feat_values = df_feat[required_cols].values.astype("float32")

        if len(feat_values) < WINDOW_SIZE:
            raise ValueError(
                f"ìœˆë„ìš° í¬ê¸°({WINDOW_SIZE})ë³´ë‹¤ ë°ì´í„° ê¸¸ì´({len(feat_values)})ê°€ ì§§ìŠµë‹ˆë‹¤."
            )

        X_last = feat_values[-WINDOW_SIZE:]      # (T, F)
        X_last = X_last[None, :, :]              # (1, T, F)
        self._last_input = X_last                # predict() ì—ì„œ ì‚¬ìš©

        # ------------------------------------------------------------
        # 6) StockData ìƒì„± + ë©”íƒ€ ì •ë³´ ë¶€ì°©
        # ------------------------------------------------------------
        last_row = df_feat.iloc[-1]
        last_price = float(last_row.get("close", np.nan))
        self.last_price = last_price  # predict ì—ì„œ current_price ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©
        currency = "USD"

        # StockData ìƒì„±ìì—ëŠ” ìµœì†Œ ì¸ìë§Œ
        sd = StockData(
            ticker=self.ticker,
            last_price=last_price,
            currency=currency,
        )

        # ë¶€ê°€ ì •ë³´ëŠ” ì†ì„±ìœ¼ë¡œ ë‹¬ê¸° (BaseAgent / DebateAgentì—ì„œ ì‚¬ìš© ê°€ëŠ¥)
        sd.feature_cols = FEATURE_COLS
        sd.window_size = WINDOW_SIZE
        sd.news_feats = {
            "news_count_7d": float(last_row.get("news_count_7d", 0)),
            "sentiment_mean_7d": float(last_row.get("sentiment_mean_7d", 0)),
            "sentiment_vol_7d": float(last_row.get("sentiment_vol_7d", 0)),
        }
        sd.raw_df = df_feat
        sd.agent_id = getattr(self, "agent_id", None)

        # ì˜ˆì „ ì½”ë“œì™€ í˜¸í™˜ë˜ë„ë¡ snapshot ë„ ë§Œë“¤ì–´ ì¤Œ
        sd.snapshot = {
            "agent_id": sd.agent_id,
            "feature_cols": sd.feature_cols,
            "window_size": sd.window_size,
            "news_feats": sd.news_feats,
            "raw_df": sd.raw_df,
        }

        # LSTM ì…ë ¥ ì‹œí€€ìŠ¤
        sd.X_seq = X_last  # (1, T, F)

        return sd


    from agents.base_agent import StockData  # íŒŒì¼ ìƒë‹¨ import ìª½ì— ì¶”ê°€ë˜ì–´ ìˆì§€ ì•Šë‹¤ë©´ ì¶”ê°€

    def predict(
        self,
        X,
        n_samples: int = 100,
        current_price: float | None = None,
    ):
        """
        Xë¡œ StockData ë˜ëŠ” (T, F)/(1, T, F) ë„˜íŒŒì´/í…ì„œë¥¼ ëª¨ë‘ í—ˆìš©í•œë‹¤.
        StockDataê°€ ë“¤ì–´ì˜¤ë©´ ë‚´ë¶€ì—ì„œ X_seqì™€ last_priceë¥¼ êº¼ë‚´ ì“´ë‹¤.
        """
        # 1) StockDataê°€ ë“¤ì–´ì˜¨ ê²½ìš° ì²˜ë¦¬
        if isinstance(X, StockData):
            sd = X

            # run_datasetì—ì„œ X_seqë¥¼ ì„¸íŒ…í–ˆëŠ”ì§€ í™•ì¸
            if getattr(sd, "X_seq", None) is None:
                raise ValueError(
                    "StockDataì— X_seqê°€ ì—†ìŠµë‹ˆë‹¤. SentimentalAgent.run_dataset()ì—ì„œ "
                    "sd.X_seqë¥¼ ì„¤ì •í–ˆëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”."
                )

            X_in = sd.X_seq

            # current_priceê°€ ì•ˆ ë“¤ì–´ì™”ìœ¼ë©´ StockDataì˜ last_price ì‚¬ìš©
            if current_price is None and getattr(sd, "last_price", None) is not None:
                current_price = float(sd.last_price)

            # ë””ë²„ê¹…/ì„¤ëª…ìš©ìœ¼ë¡œ ë³´ê´€
            self._last_stockdata = sd
            self._last_input = X_in

        else:
            # ì´ë¯¸ ë„˜íŒŒì´/í…ì„œì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
            X_in = X

        # 2) BaseAgent.predict í˜¸ì¶œ (ì—¬ê¸°ëŠ” ë„˜íŒŒì´/í…ì„œë§Œ ë°›ë„ë¡ ìœ ì§€)
        target = super().predict(X_in, n_samples=n_samples, current_price=current_price)

        # 3) íƒ€ê²Ÿì— ë©”íƒ€ì •ë³´ ë³´ê°•
        target.ticker = self.ticker
        target.agent_id = getattr(self, "agent_id", "SentimentalAgent")
        self.target = target

        return target


    # BaseAgent.decode_prediction
    def decode_prediction(self, y_pred_raw, stock_data=None, current_price=None) -> float:
        """
        BaseAgent.predict ë‚´ë¶€ì—ì„œ ì‚¬ìš©í•  ë””ì½”ë”.
        ëª¨ë¸ ì¶œë ¥(ìˆ˜ìµë¥  ë¹„ìŠ·í•œ ê°’)ì„ [-20%, +20%]ë¡œ ì œí•œ í›„ ê°€ê²©ìœ¼ë¡œ ë³€í™˜.
        """
        y_raw = float(np.asarray(y_pred_raw).reshape(-1)[-1])

        y_scaler = None
        if self.scaler is not None:
            if isinstance(self.scaler, dict):
                y_scaler = self.scaler.get("y_scaler", None)
            else:
                y_scaler = getattr(self.scaler, "y_scaler", None)

        if y_scaler is not None:
            try:
                y_decoded = float(y_scaler.inverse_transform([[y_raw]])[0, 0])
            except Exception:
                y_decoded = y_raw
        else:
            y_decoded = y_raw

        max_abs_return = 0.20
        predicted_return = max(min(y_decoded, max_abs_return), -max_abs_return)

        base_price = None
        if stock_data is not None:
            base_price = getattr(stock_data, "last_price", None)
        if base_price is None:
            base_price = current_price
        if base_price is None:
            base_price = 1.0

        next_close = float(base_price * (1.0 + predicted_return))
        return next_close

    def build_finbert_news_features(
        self,
        ticker: str,
        asof_kst: datetime,
        base_dir: str = "data/raw/news",
        days_list = [7, 30],
    ):
        from core.sentimental_classes.eodhd_client import fetch_news_from_eodhd
        from core.sentimental_classes.finbert_utils import FinBertScorer
        import numpy as np
        import os

        scorer = FinBertScorer()
        feats = {}

        for d in days_list:
            news = fetch_news_from_eodhd(ticker, days=d)

            # ğŸ”¥ ë‰´ìŠ¤ ì—†ìœ¼ë©´ ë°”ë¡œ ì‹¤íŒ¨
            if (news is None) or (len(news) == 0):
                raise RuntimeError(
                    f"[NewsError] {ticker} ìµœê·¼ {d}ì¼ ë‰´ìŠ¤ ì—†ìŒ (fetch_news_from_eodhd)"
                )

            scores = []
            for item in news:
                title = item.get("title", "") or ""
                score = scorer.score(title) or 0
                scores.append(score)

            scores = np.array(scores)

            feats[f"sentiment_mean_{d}d"] = float(np.mean(scores))
            feats[f"sentiment_vol_{d}d"] = float(np.std(scores))
            feats[f"news_count_{d}d"] = len(scores)

            # Trend: ë§ˆì§€ë§‰ 25% í‰ê·  - ì²˜ìŒ 25% í‰ê· 
            if len(scores) >= 4:
                q = len(scores) // 4
                early = np.mean(scores[:q])
                late = np.mean(scores[-q:])
                feats[f"sentiment_trend_{d}d"] = float(late - early)
            else:
                feats[f"sentiment_trend_{d}d"] = 0.0

            # Shock: z-score of last score
            if len(scores) >= 2:
                feats[f"sentiment_shock_z_{d}d"] = float(
                    (scores[-1] - np.mean(scores)) / (np.std(scores) + 1e-6)
                )
            else:
                feats[f"sentiment_shock_z_{d}d"] = 0.0

        return feats


        news_feats = self.build_finbert_news_features(
            ticker=self.ticker,
            asof_kst=asof_date_kst,
            base_dir=os.path.join("data", "raw", "news"),
        )

        if (not news_feats) or (news_feats.get("news_count_7d", 0) == 0 and
                                news_feats.get("news_count_30d", 0) == 0):
            raise RuntimeError(
                f"[SentimentalAgent] ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {self.ticker} ìµœê·¼ 7/30ì¼ ê¸°ì‚¬ 0ê±´"
            )

        # 5) StockData ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        sd = StockData()
        sd.ticker = self.ticker
        sd.last_price = last_price
        sd.currency = currency

        # SentimentalAgent ì „ìš© ìŠ¤ëƒ…ìƒ· dictì— ë„£ê¸°
        sd.SentimentalAgent = {
            "X_seq": X_latest,
            "feature_cols": feature_cols,
            "asof_date": asof_date_kst,
            "news_features": news_feats,
        }

        sd.X_seq = X_latest
        sd.feature_cols = feature_cols

        # 6) self.stockdataì— ë³´ê´€ í›„ ë°˜í™˜
        self.stockdata = sd
        return sd

    def _load_scaler_and_model(self) -> None:
        # train_sentimental.pyì—ì„œ ì €ì¥í•œ ìŠ¤ì¼€ì¼ëŸ¬/ëª¨ë¸ ë¡œë“œ
        base_name = f"{self.ticker}_SentimentalAgent"
        scaler_path = Path("models") / "scalers" / f"{base_name}.pkl"
        model_path = Path("models") / f"{base_name}.pt"

        # ìŠ¤ì¼€ì¼ëŸ¬/ë©”íƒ€
        if scaler_path.exists():
            meta = joblib.load(scaler_path)
            meta_feature_cols = None
            meta_window_size = None

            if isinstance(meta, dict) and ("x_scaler" in meta or "y_scaler" in meta):
                self.scaler = meta
                meta_feature_cols = meta.get("feature_cols", None)
                meta_window_size = meta.get("window_size", None)
            elif isinstance(meta, dict) and "scaler" in meta:
                self.scaler = meta.get("scaler", None)
                meta_feature_cols = meta.get("feature_cols", None)
                meta_window_size = meta.get("window_size", None)
            else:
                self.scaler = meta

            if meta_feature_cols is not None:
                self.feature_cols = list(meta_feature_cols)
            if meta_window_size is not None:
                self.window_size = int(meta_window_size)

            print(f"[SentimentalAgent] ìŠ¤ì¼€ì¼ëŸ¬/ë©”íƒ€ ë¡œë“œ: {scaler_path}")
        else:
            print(f"[SentimentalAgent] ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ ì—†ìŒ: {scaler_path}")
            self.scaler = None

        # LSTM ê°€ì¤‘ì¹˜
        if model_path.exists():
            try:
                state = torch.load(model_path, map_location=self.device)
                missing, unexpected = self.model.load_state_dict(state, strict=False)
                print(f"[SentimentalAgent] ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ë¡œë“œ: {model_path}")
                if missing or unexpected:
                    print("[SentimentalAgent] state_dict mismatch:",
                          "missing:", missing, "/ unexpected:", unexpected)
                else:
                    self.model_loaded = True
            except Exception as e:
                print(f"[SentimentalAgent] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.model_loaded = False
        else:
            print(f"[SentimentalAgent] ì‚¬ì „ í•™ìŠµ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
            self.model_loaded = False

    # BaseAgent.pretrain()ìš©
    def _build_model(self) -> nn.Module:
        """BaseAgent.pretrainì—ì„œ ì‚¬ìš©í•  ëª¨ë¸ ìƒì„±."""
        try:
            X, y, cols = _load_dataset_compat(
                self.ticker,
                self.agent_id,
                window_size=self.window_size,
            )
        except Exception:
            _build_dataset_compat(
                self.ticker,
                self.agent_id,
                window_size=self.window_size,
            )
            X, y, cols = _load_dataset_compat(
                self.ticker,
                self.agent_id,
                window_size=self.window_size,
            )

        input_dim = X.shape[-1]
        self.feature_cols = list(cols)

        net = SentimentalLSTM(
            input_dim=input_dim,
            hidden_dim=self.hidden_dim,
            num_layers=self.num_layers,
            dropout=self.dropout,
        )
        return net

    def model_path(self) -> str:
        """ëª¨ë¸ ì €ì¥ ê²½ë¡œ í†µì¼."""
        try:
            model_dir = dir_info["model_dir"]
        except Exception:
            model_dir = "models"

        ticker = getattr(self, "ticker", "UNKNOWN")
        agent_id = getattr(self, "agent_id", "SentimentalAgent")
        return os.path.join(model_dir, f"{ticker}_{agent_id}.pt")

    def _load_model_if_exists(self) -> None:
        """model_path ê¸°ì¤€ìœ¼ë¡œ íŒŒì¼ì´ ìˆìœ¼ë©´ BaseAgent.load_model ì‚¬ìš©."""
        model_path = self.model_path()
        if not os.path.exists(model_path):
            self.model_loaded = False
            return

        ok = False
        try:
            ok = self.load_model(model_path)
        except Exception as e:
            print(f"[SentimentalAgent] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            ok = False

        self.model_loaded = bool(ok)

    # MC Dropout helper (dataset ê¸°ë°˜)
    @torch.inference_mode()
    def _mc_dropout_predict(self, x: torch.Tensor, T: int = 30) -> Tuple[float, float]:
        """ì…ë ¥ xì— ëŒ€í•´ MC Dropoutìœ¼ë¡œ (mean, std) ìˆ˜ìµë¥  ì˜ˆì¸¡."""
        if self.model is None:
            raise RuntimeError("model is None for MC Dropout")

        self.model.train()
        outs = []
        for _ in range(T):
            outs.append(self.model(x).detach())
        self.model.eval()

        y = torch.stack(outs, dim=0).squeeze(-1)
        mean = y.mean(dim=0)
        std = y.std(dim=0)
        return float(mean.squeeze().item()), float(std.squeeze().item())

    @torch.inference_mode()
    def _predict_next_close(self) -> Tuple[float, float, float, List[str]]:
        """
        âœ… ìƒˆ íŒŒì´í”„ë¼ì¸ ê¸°ë°˜ ë‹¤ìŒë‚  ì¢…ê°€ ì˜ˆì¸¡
        - run_dataset() ìœ¼ë¡œ ìµœê·¼ 40ì¼ X_seq + last_price ìƒì„±
        - LSTM ì¶œë ¥ = 'ë‹¤ìŒë‚  ìˆ˜ìµë¥ '
        - last_price * (1 + return) = next_close
        """
        if not self.ticker:
            raise ValueError("ticker is None in _predict_next_close")

        # 1) ìµœì‹  ë°ì´í„°ì…‹ / ì…ë ¥ ìœˆë„ìš° ë§Œë“¤ê¸°
        X = getattr(self, "_last_input", None)
        if X is None:
            # run_dataset() ì´ self._last_input, self.last_price ì±„ì›Œì¤Œ
            X = self.run_dataset()

        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)

        # 2) LSTMìœ¼ë¡œ ìˆ˜ìµë¥  ì˜ˆì¸¡
        self.model.eval()
        with torch.no_grad():
            out = self.model(X_tensor)

        out = out.reshape(-1)
        mean_ret = float(out[0])          # ì˜ˆ: -0.003 â†’ -0.3%
        std_ret = 0.01                    # í•„ìš”í•˜ë©´ MC Dropoutë¡œ êµì²´

        # 3) í˜„ì¬ ì¢…ê°€ (run_datasetì—ì„œ ì„¸íŒ…í•œ ì‹¤ì œ Close)
        last_close = float(getattr(self, "last_price", 0.0) or 0.0)

        if last_close > 0:
            pred_close = float(last_close * (1.0 + mean_ret))
        else:
            # í˜¹ì‹œë¼ë„ last_price ëª» êµ¬í•˜ë©´ ê·¸ëƒ¥ returnë§Œ ë¦¬í„´
            pred_close = float(mean_ret)

        uncertainty_std = float(std_ret)
        confidence = float(1.0 / (1.0 + max(1e-6, uncertainty_std)))

        # cols: íŠ¹ì§• ì´ë¦„ ë¦¬ìŠ¤íŠ¸ (í•„ìš”í•˜ë©´ self.feature_cols ì‚¬ìš©)
        cols = list(getattr(self, "feature_cols", []))
        return pred_close, uncertainty_std, confidence, cols


    # ctx êµ¬ì„± (ê°€ê²© + ë‰´ìŠ¤ ê°ì„± ìŠ¤ëƒ…ìƒ·)
    def build_ctx(self, asof_date_kst: Optional[str] = None) -> Dict[str, Any]:
        # 0) StockData í™•ë³´
        stockdata: StockData | None = getattr(self, "stockdata", None)
        if stockdata is None:
            raise ValueError(
                "[SentimentalAgent] build_ctx í˜¸ì¶œ ì „ì— run_dataset()ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”."
            )

        senti_snap = getattr(stockdata, "SentimentalAgent", None) or {}

        # 1) ê¸°ì¤€ ë‚ ì§œ(asof_date_kst)
        if asof_date_kst is None:
            asof_date_kst = senti_snap.get("asof_date") or datetime.now().strftime("%Y-%m-%d")

        # 2) ì˜ˆì¸¡ ê°’ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        pred_close, uncertainty_std, confidence, cols = self._predict_next_close()

        # 3) ê°€ê²© ìŠ¤ëƒ…ìƒ·
        price_snapshot: Dict[str, Optional[float]] = {}

        # ìš°ì„  run_dataset()ì—ì„œ ì €ì¥í•´ë‘” X_seq / feature_cols ì‚¬ìš©
        x_seq = senti_snap.get("X_seq", None)
        feat_cols = senti_snap.get("feature_cols", None)

        try:
            if isinstance(x_seq, np.ndarray) and feat_cols:
                # X_seq: (1, T, F) ê°€ì • â†’ ë§ˆì§€ë§‰ ì‹œì 
                last = x_seq[-1, -1, :]
                snap_map = {c: float(v) for c, v in zip(feat_cols, last)}
                for k in ("Close", "Open", "High", "Low", "Volume", "returns"):
                    if k in snap_map:
                        price_snapshot[k] = snap_map[k]
            else:
                # fallback: ì˜ˆì „ì²˜ëŸ¼ datasetì—ì„œ ë‹¤ì‹œ ë¡œë“œ
                X, _, cols2 = _load_dataset_compat(
                    self.ticker, self.agent_id, window_size=self.window_size
                )
                last = X[-1, -1, :]
                snap_map = {c: float(v) for c, v in zip(cols2, last)}
                for k in ("Close", "Open", "High", "Low", "Volume", "returns"):
                    if k in snap_map:
                        price_snapshot[k] = snap_map[k]
        except Exception:
            pass

        # 4) âœ… ë‰´ìŠ¤/ê°ì„± í”¼ì²˜: run_dataset()ì—ì„œ ì €ì¥í•œ ê²ƒë§Œ ì‚¬ìš©
        news_feats = senti_snap.get("news_features", None)
        if not news_feats:
            # ì—†ìœ¼ë©´ 0 í”¼ì²˜
            news_feats = _zero_news_feats()

        # ì•ˆì „í•˜ê²Œ êº¼ë‚´ê¸°
        sentiment_summary = news_feats.get("sentiment_summary", {})
        sentiment_vol = news_feats.get("sentiment_volatility", {})
        news_count = news_feats.get("news_count", {})
        trend_7d = news_feats.get("trend_7d", 0.0)
        has_news = bool(news_feats.get("has_news", False))

        # 5) snapshot / prediction êµ¬ì„± (ê¸°ì¡´ê³¼ ê±°ì˜ ë™ì¼)
        snapshot = {
            "asof_date": asof_date_kst,
            "last_price": price_snapshot.get("Close", np.nan),
            "currency": stockdata.currency or "USD",
            "window_size": self.window_size,
            "feature_cols_preview": [c for c in (cols or [])[:8]],
        }

        last_price = snapshot["last_price"]
        if last_price and last_price == last_price:
            pred_return = float(pred_close / last_price - 1.0)
        else:
            pred_return = None

        feature_importance = {
            "sentiment_score": sentiment_summary.get("mean_7d", 0.0),
            "sentiment_summary": sentiment_summary,
            "sentiment_volatility": {
                "vol_7d": sentiment_vol.get("vol_7d", 0.0),
            },
            "trend_7d": trend_7d,
            "news_count": news_count,
            "has_news": has_news,
            "price_snapshot": {
                "Close": price_snapshot.get("Close"),
                "Open": price_snapshot.get("Open"),
                "High": price_snapshot.get("High"),
                "Low": price_snapshot.get("Low"),
                "Volume": price_snapshot.get("Volume"),
                "ret_1d": None,
                "ret_5d": None,
                "ret_20d": None,
                "zscore_20d": None,
                "vol_change_5d": None,
            },
        }

        ctx = {
            "agent_id": self.agent_id,
            "ticker": self.ticker,
            "snapshot": snapshot,
            "prediction": {
                "pred_close": pred_close,
                "pred_return": pred_return,
                "uncertainty": {
                    "std": uncertainty_std,
                    "ci95": float(1.96 * uncertainty_std),
                },
                "confidence": confidence,
                "pred_next_close": pred_close,
            },
            "feature_importance": feature_importance,
        }
        return ctx

    # Opinion / Rebuttal / Revision í”„ë¡¬í”„íŠ¸
    def _build_messages_opinion(
        self,
        stock_data: StockData,
        target: Target,
    ) -> Tuple[str, str]:
        if stock_data is None:
            stock_data = self.stockdata

        ctx: Dict[str, Any] = {}

        # ë©”íƒ€
        ctx["ticker"] = getattr(stock_data, "ticker", self.ticker)
        ctx["currency"] = getattr(stock_data, "currency", "USD")

        # ê°€ê²©
        last_close = getattr(stock_data, "last_price", None)
        ctx["last_close"] = last_close
        ctx["next_close"] = float(getattr(target, "next_close", 0.0))

        change_ratio = None
        if isinstance(last_close, (int, float)) and last_close not in (0, None):
            try:
                change_ratio = ctx["next_close"] / float(last_close) - 1.0
            except ZeroDivisionError:
                change_ratio = None
        ctx["change_ratio"] = change_ratio

        ctx["uncertainty_std"] = getattr(target, "uncertainty", None)
        ctx["confidence"] = getattr(target, "confidence", None)

        # SentimentalAgent ì „ìš© ìŠ¤ëƒ…ìƒ· (stock_data.SentimentalAgent dict ê°€ì •)
        snap = getattr(stock_data, "SentimentalAgent", None)
        if isinstance(snap, dict):
            for k, v in snap.items():
                if isinstance(v, np.ndarray):
                    if v.ndim == 0:
                        ctx[k] = v.item()
                    elif v.size > 0:
                        flat = v.reshape(-1)
                        last_val = flat[-1]
                        try:
                            ctx[k] = float(last_val)
                        except Exception:
                            ctx[k] = last_val
                    else:
                        ctx[k] = None
                elif isinstance(v, (list, tuple)) and len(v) > 0:
                    ctx[k] = v[-1]
                else:
                    ctx[k] = v

        ctx_json = json.dumps(ctx, ensure_ascii=False, indent=2)

        prompts = OPINION_PROMPTS["SentimentalAgent"]
        system_text = prompts["system"]
        user_tmpl = prompts["user"]

        try:
            user_text = user_tmpl.format(context=ctx_json)
        except KeyError:
            user_text = user_tmpl.replace("{context}", ctx_json)

        return system_text, user_text

    def _build_messages_rebuttal(self, *args, **kwargs) -> Tuple[str, str]:
        stock_data = args[0] if len(args) > 0 else kwargs.get("stock_data")
        target: Optional[Target] = args[1] if len(args) > 1 else kwargs.get("target")

        opponent = None
        for key in ("opponent", "opponent_opinion", "other_opinion", "other", "opinion"):
            if key in kwargs:
                opponent = kwargs[key]
                break
        if opponent is None and len(args) > 2:
            opponent = args[2]

        if isinstance(opponent, Opinion):
            opp_agent = getattr(opponent, "agent_id", "UnknownAgent")
            opp_reason = getattr(opponent, "reason", "")
        elif isinstance(opponent, dict):
            opp_agent = opponent.get("agent_id", "UnknownAgent")
            opp_reason = opponent.get("reason", "")
        else:
            opp_agent = "UnknownAgent"
            opp_reason = str(opponent) if opponent is not None else ""

        ctx = self.build_ctx()
        fi = ctx.get("feature_importance", {})
        sent = fi.get("sentiment_summary", {})
        vol7 = fi.get("sentiment_volatility", {}).get("vol_7d", None)
        trend7 = fi.get("trend_7d", None)
        news7 = fi.get("news_count", {}).get("count_7d", None)

        pred_close = float(target.next_close) if target else float(
            ctx["prediction"]["pred_next_close"]
        )
        last_price = ctx.get("snapshot", {}).get("last_price")
        change_ratio = None
        if last_price and last_price == last_price and last_price != 0:
            change_ratio = pred_close / last_price - 1.0

        pp = REBUTTAL_PROMPTS.get("SentimentalAgent", {})
        system_tmpl = pp.get(
            "system",
            "ë‹¹ì‹ ì€ ê°ì„± ê¸°ë°˜ ë‹¨ê¸° ì£¼ê°€ ë¶„ì„ê°€ë¡œì„œ ìƒëŒ€ ì˜ê²¬ì˜ í—ˆì ì„ ê°ì„± ì§€í‘œì™€ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°˜ë°•í•©ë‹ˆë‹¤.",
        )
        user_tmpl = pp.get(
            "user",
            (
                "í‹°ì»¤: {ticker}\n"
                "ìƒëŒ€ ì—ì´ì „íŠ¸: {opp_agent}\n"
                "ìƒëŒ€ ì˜ê²¬:\n{opp_reason}\n\n"
                "ìš°ë¦¬ ì˜ˆì¸¡:\n- next_close: {pred_close}\n- ì˜ˆìƒ ë³€í™”ìœ¨(í˜„ì¬ê°€ ëŒ€ë¹„): {chg}\n"
                "ê°ì„± ê·¼ê±°:\n- mean7={mean7}, mean30={mean30}, pos7={pos7}, neg7={neg7}\n"
                "- vol7={vol7}, trend7={trend7}, news7={news7}\n\n"
                "ìš”ì²­: ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒëŒ€ ì˜ê²¬ì˜ ì•½ì  2~4ê°œë¥¼ ì¡°ëª©ì¡°ëª© ë°˜ë°•í•˜ì„¸ìš”."
            ),
        )

        user_text = user_tmpl.format(
            ticker=self.ticker,
            opp_agent=opp_agent,
            opp_reason=opp_reason if opp_reason else "(ìƒëŒ€ ì˜ê²¬ ë‚´ìš© ì—†ìŒ)",
            pred_close=f"{pred_close:.4f}",
            chg=("NA" if change_ratio is None else f"{change_ratio*100:.2f}%"),
            mean7=f"{sent.get('mean_7d', 0.0):.4f}",
            mean30=f"{sent.get('mean_30d', 0.0):.4f}",
            pos7=f"{sent.get('pos_ratio_7d', 0.0):.4f}",
            neg7=f"{sent.get('neg_ratio_7d', 0.0):.4f}",
            vol7=("NA" if vol7 is None else f"{vol7:.4f}"),
            trend7=("NA" if trend7 is None else f"{trend7:.4f}"),
            news7=("NA" if news7 is None else f"{news7}"),
        )
        return system_tmpl, user_text

    def _build_messages_revision(self, *args, **kwargs) -> Tuple[str, str]:
        stock_data = args[0] if len(args) > 0 else kwargs.get("stock_data")
        target: Optional[Target] = args[1] if len(args) > 1 else kwargs.get("target")

        # ì´ˆì•ˆ
        prev = None
        rebs = None
        for key in ("previous", "previous_opinion", "draft", "opinion"):
            if key in kwargs:
                prev = kwargs[key]
                break
        if prev is None and len(args) > 2:
            prev = args[2]

        # ë°˜ë°•ë“¤
        for key in ("rebuttals", "replies", "responses"):
            if key in kwargs:
                rebs = kwargs[key]
                break
        if rebs is None and len(args) > 3:
            rebs = args[3]

        def _op_text(x: Union[Opinion, Dict[str, Any], str, None]) -> str:
            if isinstance(x, Opinion):
                return getattr(x, "reason", "")
            if isinstance(x, dict):
                return x.get("reason", "")
            return x or ""

        prev_reason = _op_text(prev)

        reb_texts: List[str] = []
        if isinstance(rebs, list):
            for r in rebs:
                reb_texts.append(_op_text(r))
        elif rebs is not None:
            reb_texts.append(_op_text(rebs))

        ctx = self.build_ctx()
        fi = ctx.get("feature_importance", {})
        sent = fi.get("sentiment_summary", {})
        vol7 = fi.get("sentiment_volatility", {}).get("vol_7d", None)
        trend7 = fi.get("trend_7d", None)
        news7 = fi.get("news_count", {}).get("count_7d", None)

        pred_info = ctx.get("prediction", {}) or {}
        unc_dict = pred_info.get("uncertainty", {}) or {}
        unc_std = unc_dict.get("std", None)
        confidence = pred_info.get("confidence", None)

        pred_close = float(target.next_close) if target else float(
            pred_info.get("pred_next_close")
        )
        last_price = ctx.get("snapshot", {}).get("last_price")
        change_ratio = None
        if last_price and last_price == last_price and last_price != 0:
            change_ratio = pred_close / last_price - 1.0

        # context ìš”ì•½
        context_parts: List[str] = []
        if last_price is not None:
            if change_ratio is not None:
                context_parts.append(
                    f"í˜„ì¬ ì£¼ê°€ëŠ” {last_price:.2f}ì´ê³ , ëª¨ë¸ì€ ë‹¤ìŒ ê±°ë˜ì¼ ì¢…ê°€ë¥¼ {pred_close:.2f}ë¡œ ì˜ˆì¸¡í–ˆìŠµë‹ˆë‹¤ "
                    f"(ë³€í™”ìœ¨ ì•½ {change_ratio*100:.2f}%)."
                )
            else:
                context_parts.append(
                    f"í˜„ì¬ ì£¼ê°€ëŠ” {last_price:.2f}ì´ë©°, ë‹¤ìŒ ê±°ë˜ì¼ ì¢…ê°€ ì˜ˆì¸¡ê°’ì€ {pred_close:.2f}ì…ë‹ˆë‹¤."
                )
        else:
            context_parts.append(
                f"ë‹¤ìŒ ê±°ë˜ì¼ ì¢…ê°€ ì˜ˆì¸¡ê°’ì€ {pred_close:.2f}ì…ë‹ˆë‹¤."
            )

        mean7 = sent.get("mean_7d", None)
        mean30 = sent.get("mean_30d", None)
        pos7 = sent.get("pos_ratio_7d", None)
        neg7 = sent.get("neg_ratio_7d", None)

        if mean7 is not None and mean30 is not None:
            context_parts.append(
                f"ìµœê·¼ 7ì¼ í‰ê·  ê°ì„± ì ìˆ˜ëŠ” {mean7:.3f}, ìµœê·¼ 30ì¼ í‰ê· ì€ {mean30:.3f}ì…ë‹ˆë‹¤."
            )
        if pos7 is not None and neg7 is not None:
            context_parts.append(
                f"ìµœê·¼ 7ì¼ ê¸°ì¤€ ê¸ì • ê¸°ì‚¬ ë¹„ìœ¨ì€ {pos7:.2%}, ë¶€ì • ê¸°ì‚¬ ë¹„ìœ¨ì€ {neg7:.2%}ì…ë‹ˆë‹¤."
            )
        if vol7 is not None:
            context_parts.append(
                f"ìµœê·¼ 7ì¼ ê°ì„± ì ìˆ˜ì˜ ë³€ë™ì„±(í‘œì¤€í¸ì°¨)ì€ {vol7:.3f}ì…ë‹ˆë‹¤."
            )
        if trend7 is not None:
            context_parts.append(
                f"ìµœê·¼ 7ì¼ ê°ì„± ì¶”ì„¸(íšŒê·€ ê¸°ìš¸ê¸°)ëŠ” {trend7:.4f}ì…ë‹ˆë‹¤."
            )
        if news7 is not None:
            context_parts.append(
                f"ìµœê·¼ 7ì¼ ë™ì•ˆ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ê°œìˆ˜ëŠ” {news7}ê±´ì…ë‹ˆë‹¤."
            )

        if unc_std is not None and confidence is not None:
            context_parts.append(
                f"ì˜ˆì¸¡ í‘œì¤€í¸ì°¨ëŠ” {unc_std:.4f}, ì‹ ë¢°ë„ëŠ” {confidence:.3f}ì…ë‹ˆë‹¤."
            )

        context_str = " ".join(context_parts) if context_parts else (
            "ìµœê·¼ ë‰´ìŠ¤ ê°ì„± ì ìˆ˜, ë³€ë™ì„±, ê¸Â·ë¶€ì • ë¹„ìœ¨, ë‰´ìŠ¤ ìˆ˜, ì˜ˆì¸¡ ë¶ˆí™•ì‹¤ì„± ë“±ì„ ì¢…í•©í•´ ë‹¨ê¸° ì£¼ê°€ë¥¼ í•´ì„í•©ë‹ˆë‹¤."
        )

        pp = REVISION_PROMPTS.get("SentimentalAgent", {})
        system_tmpl = pp.get(
            "system",
            (
                "ë‹¹ì‹ ì€ ê°ì„± ê¸°ë°˜ ë‹¨ê¸° ì£¼ê°€ ë¶„ì„ê°€ì…ë‹ˆë‹¤. "
                "ì´ˆì•ˆ ì˜ê²¬ê³¼ ë°˜ë°•ë“¤ì„ ê²€í† í•´ í•µì‹¬ë§Œ ë‚¨ê¸°ê³ , ë°ì´í„°ì— ê·¼ê±°í•´ ê²°ë¡ ì„ ë‹¤ë“¬ìŠµë‹ˆë‹¤."
            ),
        )
        user_tmpl = pp.get(
            "user",
            (
                "í‹°ì»¤: {ticker}\n"
                "ì´ˆì•ˆ ì˜ê²¬:\n{prev}\n\n"
                "ìˆ˜ì‹ í•œ ë°˜ë°• ìš”ì•½:\n{rebuts}\n\n"
                "ì—…ë°ì´íŠ¸ëœ ìˆ˜ì¹˜:\n- next_close: {pred_close}\n- ì˜ˆìƒ ë³€í™”ìœ¨: {chg}\n"
                "ê°ì„± ê·¼ê±° ìŠ¤ëƒ…ìƒ·:\n- mean7={mean7}, mean30={mean30}, pos7={pos7}, neg7={neg7}\n"
                "- vol7={vol7}, trend7={trend7}, news7={news7}\n\n"
                "ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸:\n{context}\n\n"
                "ìš”ì²­: ì´ˆì•ˆì˜ ê³¼ì¥/ì¤‘ë³µ/ì•½í•œ ê·¼ê±°ë¥¼ ì •ë¦¬í•˜ê³ , ê°•í•œ ê·¼ê±°(ê°ì„± ì¶”ì„¸, ë³€ë™ì„±, ë‰´ìŠ¤ ìˆ˜ ë³€í™”)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ "
                "ìµœì¢… ì˜ê²¬ì„ 3~5ë¬¸ì¥ìœ¼ë¡œ ì¬ì‘ì„±í•˜ì„¸ìš”. ë¶ˆí™•ì‹¤ì„±/ì‹ ë¢°ë„ í•´ì„ì„ í¬í•¨í•˜ì„¸ìš”."
            ),
        )

        rebuts_joined = "- " + "\n- ".join(
            [s for s in reb_texts if s]
        ) if reb_texts else "(ë°˜ë°• ì—†ìŒ)"

        user_text = user_tmpl.format(
            ticker=self.ticker,
            prev=prev_reason if prev_reason else "(ì´ˆì•ˆ ì—†ìŒ)",
            rebuts=rebuts_joined,
            pred_close=f"{pred_close:.4f}",
            chg=("NA" if change_ratio is None else f"{change_ratio*100:.2f}%"),
            mean7=("NA" if mean7 is None else f"{mean7:.4f}"),
            mean30=("NA" if mean30 is None else f"{mean30:.4f}"),
            pos7=("NA" if pos7 is None else f"{pos7:.4f}"),
            neg7=("NA" if neg7 is None else f"{neg7:.4f}"),
            vol7=("NA" if vol7 is None else f"{vol7:.4f}"),
            trend7=("NA" if trend7 is None else f"{trend7:.4f}"),
            news7=("NA" if news7 is None else f"{news7}"),
            context=context_str,
        )
        return system_tmpl, user_text


    # ë ˆê±°ì‹œ Opinion API
    def get_opinion(self, idx: int = 0, ticker: Optional[str] = None) -> Opinion:
        if ticker and ticker != self.ticker:
            self.ticker = str(ticker).upper()

        pred_close, uncertainty_std, confidence, _ = self._predict_next_close()
        target = Target(
            next_close=float(pred_close),
            uncertainty=float(uncertainty_std),
            confidence=float(confidence),
        )

        # BaseAgent.reviewer_draft ì‚¬ìš© ì‹œë„
        try:
            if hasattr(self, "reviewer_draft"):
                op = self.reviewer_draft(getattr(self, "stockdata", None), target)
                return op
        except Exception as e:
            print("[SentimentalAgent] reviewer_draft ì‚¬ìš© ì‹¤íŒ¨:", e)

        # fallback: ë‹¨ìˆœ í…ìŠ¤íŠ¸ ìš”ì•½
        ctx = self.build_ctx()
        fi = ctx["feature_importance"]
        sent = fi["sentiment_summary"]

        reason = (
            f"{self.ticker}ì˜ ìµœê·¼ 7ì¼ ê°ì„± í‰ê· ì€ {sent['mean_7d']:.3f}ì´ë©° "
            f"ë‰´ìŠ¤ ê°œìˆ˜(7d)ëŠ” {fi['news_count']['count_7d']}ê±´ì…ë‹ˆë‹¤. "
            f"ê°ì„± ë³€ë™ì„±(vol_7d)={fi['sentiment_volatility']['vol_7d']:.3f}, "
            f"ê°ì„± ì¶”ì„¸(trend_7d)={fi['trend_7d']:.3f}ì…ë‹ˆë‹¤."
        )

        return Opinion(
            agent_id=self.agent_id,
            target=target,
            reason=reason,
        )
