# agents/sentimental_agent.py
# ===============================================================
# SentimentalAgent: ê°ì„±(ë‰´ìŠ¤/í…ìŠ¤íŠ¸) + LSTM ê¸°ë°˜ ì˜ˆì¸¡ ì—ì´ì „íŠ¸
#  - LSTM ì¶œë ¥ì€ "ë‹¤ìŒë‚  ìˆ˜ìµë¥ (return)"ì„ ì˜ˆì¸¡í•œë‹¤ê³  ê°€ì •í•˜ê³ ,
#    ë§ˆì§€ë§‰ ì¢…ê°€(last_close)ì— ê³±í•´ì„œ ë‹¤ìŒ ì¢…ê°€(pred_next_close)ë¥¼ ê³„ì‚°í•œë‹¤.
# ===============================================================

from __future__ import annotations
import os
import json
from dataclasses import dataclass
from typing import Optional, Tuple, Dict, Any, List, Union

from pathlib import Path
from datetime import datetime, timedelta, date

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

from typing import Any
from core.data_set import load_dataset

# ---------------------------
# í”„ë¡œì íŠ¸ ì˜ì¡´ ëª¨ë“ˆ (ì•ˆì „ import)
# ---------------------------
# ì´ë¯¸ ìˆëŠ” íƒ€ì… íŒíŠ¸ìš© ì½”ë“œë„ í™œìš©
try:
    from agents.base_agent import StockData, Target, Opinion, Rebuttal
except Exception:
    StockData = Any
    Target = Any
    Opinion = Any
    Rebuttal = Any

# dir_info ì“°ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ì„œ (ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)
try:
    from config.agents import dir_info
except Exception:
    dir_info = {}

try:
    from agents.base_agent import BaseAgent, StockData, Target, Opinion  # type: ignore
except Exception:
    BaseAgent = object  # type: ignore

    @dataclass
    class Target:  # type: ignore
        next_close: float
        uncertainty: float
        confidence: float

    @dataclass
    class Opinion:  # type: ignore
        agent_id: str
        target: Target
        reason: str

try:
    from config.agents import agents_info, dir_info  # type: ignore
except Exception:
    agents_info = {
        "SentimentalAgent": {
            "window_size": 40,
            "hidden_dim": 128,
            "dropout": 0.2,
            "epochs": 30,
            "learning_rate": 1e-3,
            "batch_size": 64,
            "x_scaler": "StandardScaler",
            "y_scaler": "StandardScaler",
            "gamma": 0.3,
            "delta_limit": 0.05,
        }
    }
    dir_info = {
        "data_dir": "data",
        "model_dir": "models",
        "scaler_dir": os.path.join("models", "scalers"),
    }

try:
    from core.data_set import build_dataset, load_dataset  # type: ignore
except Exception:
    build_dataset = None  # type: ignore

    def load_dataset(*args, **kwargs):  # type: ignore
        raise RuntimeError("core.data_set.load_dataset ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# í”„ë¡¬í”„íŠ¸ ì„¸íŠ¸ (ìˆëŠ” ê²½ìš° ì‚¬ìš©)
try:
    from prompts import OPINION_PROMPTS, REBUTTAL_PROMPTS, REVISION_PROMPTS  # type: ignore
except Exception:
    OPINION_PROMPTS = REBUTTAL_PROMPTS = REVISION_PROMPTS = None  # type: ignore


# ---------------------------
# FinBERT / ë‰´ìŠ¤ ìœ í‹¸ import
# ---------------------------
from typing import Any  # íŒŒì¼ ë§¨ ìœ„ì— ì´ë¯¸ ìˆìœ¼ë©´ ìƒëµ

FinBertScorer: Any | None = None
load_or_fetch_news: Any | None = None
score_news_items: Any | None = None
attach_scores_to_items: Any | None = None
compute_finbert_features: Any | None = None

try:
    # âœ… FinBERT ê´€ë ¨ ìœ í‹¸ì€ ì „ë¶€ ì´ ëª¨ë“ˆì—ì„œ ê°€ì ¸ì˜¨ë‹¤
    from core.sentimental_classes.finbert_utils import (
        FinBertScorer,
        load_or_fetch_news,
        score_news_items,
        attach_scores_to_items,
        compute_finbert_features,
    )
except Exception as e:
    print("[warn] core.sentimental_classes.finbert_utils ì—ì„œ FinBERT ê´€ë ¨ ìœ í‹¸ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤:", repr(e))
    FinBertScorer = None
    load_or_fetch_news = None
    score_news_items = None
    attach_scores_to_items = None
    compute_finbert_features = None

USE_FINBERT = all(
    x is not None
    for x in [
        FinBertScorer,
        score_news_items,
        attach_scores_to_items,
        compute_finbert_features,
    ]
)

try:
    from core.data_set import load_dataset  # í”„ë¡œì íŠ¸ ê³µí†µ ë°ì´í„° ë¡œë”
except Exception:
    load_dataset = None  # íƒ€ì… íŒíŠ¸ìš©/ì•ˆì „ì¥ì¹˜

# ---------------------------------------------------------------
# ëª¨ë¸ ì •ì˜: LSTM + Dropout (MC Dropout ì§€ì›)
#   âš ï¸ ì¶œë ¥ì€ "ë‹¤ìŒë‚  ìˆ˜ìµë¥ (return)" ê°’ìœ¼ë¡œ ê°€ì •
# ---------------------------------------------------------------
class SentimentalNet(nn.Module):
    def __init__(self, input_dim: int, hidden_dim: int = 128, dropout: float = 0.2):
        super().__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=1, batch_first=True)
        self.drop = nn.Dropout(dropout)
        self.fc = nn.Linear(hidden_dim, 1)

    def forward(self, x):
        # x: [B, T, F]
        out, _ = self.lstm(x)
        out = self.drop(out[:, -1, :])
        out = self.fc(out)  # [B, 1]  â† "ì˜ˆì¸¡ëœ ìˆ˜ìµë¥ " (return)
        return out


# ---------------------------------------------------------------
# load/build dataset ì‹œê·¸ë‹ˆì²˜ í˜¸í™˜ ìœ í‹¸
# ---------------------------------------------------------------
def _load_dataset_compat(ticker: str, agent_id: str, window_size: Optional[int] = None):
    if not ticker:
        raise ValueError("load_dataset_compat: empty ticker")
    try:
        return load_dataset(ticker, agent_id, window_size=window_size)  # type: ignore
    except TypeError:
        pass
    try:
        return load_dataset(ticker, agent_id, seq_len=window_size)  # type: ignore
    except TypeError:
        pass
    return load_dataset(ticker, agent_id)  # type: ignore


def _build_dataset_compat(ticker: str, agent_id: str, window_size: Optional[int] = None):
    if not ticker:
        raise ValueError("build_dataset_compat: empty ticker")
    if build_dataset is None:
        return
    try:
        return build_dataset(ticker, agent_id, window_size=window_size)  # type: ignore
    except TypeError:
        pass
    try:
        return build_dataset(ticker, agent_id, seq_len=window_size)  # type: ignore
    except TypeError:
        pass
    return build_dataset(ticker, agent_id)  # type: ignore


# ---------------------------------------------------------------
# ìœ í‹¸: ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸ê°€ ì €ì¥í•œ ë‰´ìŠ¤ ìºì‹œë¥¼ ì½ì–´ FinBERT ì§‘ê³„ í”¼ì²˜ ìƒì„±
# ---------------------------------------------------------------
def _utc_from_kst_asof(asof_kst: str, lookback_days: int = 40) -> Tuple[str, str, date]:
    kst_dt = datetime.fromisoformat(asof_kst)
    utc_today = (kst_dt - timedelta(hours=9)).date()
    to_utc_date = utc_today - timedelta(days=1)
    from_utc_date = to_utc_date - timedelta(days=lookback_days)
    return from_utc_date.isoformat(), to_utc_date.isoformat(), to_utc_date


def _zero_news_feats() -> Dict[str, Any]:
    """ë‰´ìŠ¤/FinBERT í”¼ì²˜ê°€ ì—†ì„ ë•Œ ê¸°ë³¸ê°’."""
    return {
        "sentiment_summary": {
            "mean_7d": 0.0,
            "mean_30d": 0.0,
            "pos_ratio_7d": 0.0,
            "neg_ratio_7d": 0.0,
        },
        "sentiment_volatility": {"vol_7d": 0.0},
        "news_count": {"count_1d": 0, "count_7d": 0},
        "trend_7d": 0.0,
        "has_news": False,
    }


def build_finbert_news_features(
    ticker: str,
    asof_kst: str,
    base_dir: str = "data/raw/news",
    text_fields: Tuple[str, ...] = ("title", "content", "text", "summary"),
) -> Dict[str, Any]:
    """
    SentimentalAgent ê°€ ì‚¬ìš©í•  FinBERT ì…ë ¥ìš© ë‰´ìŠ¤ í”¼ì²˜ ìƒì„±.
    - base_dir ê°€ ìƒëŒ€ê²½ë¡œë©´, í•­ìƒ 'í”„ë¡œì íŠ¸ ë£¨íŠ¸/ë°ì´í„°' ê¸°ì¤€ìœ¼ë¡œ í•´ì„
    - ì •í™•í•œ ê¸°ê°„ íŒŒì¼ì´ ì—†ìœ¼ë©´ ë™ì¼ í‹°ì»¤ì˜ ìµœì‹  ìºì‹œ íŒŒì¼ì„ fallback ìœ¼ë¡œ ì‚¬ìš©
    """
    
    # FinBERT ìì²´ê°€ ë¹„í™œì„±í™”ëœ ê²½ìš°: ì•ˆì „í•˜ê²Œ 0 í”¼ì²˜ ë°˜í™˜
    if FinBertScorer is None:
        print("[FinBERT] FinBertScorer ì—†ìŒ â†’ ê°ì„± í”¼ì²˜ë¥¼ 0ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        return _zero_news_feats()

    fr, to, to_date_utc = _utc_from_kst_asof(asof_kst, lookback_days=40)
    symbol_us = f"{ticker}.US"

    project_root = Path(__file__).resolve().parent.parent
    base = Path(base_dir)
    if not base.is_absolute():
        base = project_root / base

    # 1) ì •í™•í•œ ê¸°ê°„ íŒŒì¼ ìš°ì„  íƒìƒ‰
    path = base / f"{symbol_us}_{fr}_{to}.json"
    print(f"[FinBERT] ìºì‹œ íƒìƒ‰: {path} (exists={path.exists()})")

    if not path.exists():
        # 2) fallback: ë™ì¼ í‹°ì»¤ì˜ ìµœì‹  ìºì‹œ íŒŒì¼ ì‚¬ìš©
        pattern = f"{symbol_us}_*.json"
        candidates = sorted(base.glob(pattern))
        if candidates:
            latest = max(candidates, key=lambda p: p.stat().st_mtime)
            print(
                f"[FinBERT] ë‰´ìŠ¤ ìºì‹œ ì—†ìŒ(ì •í™•í•œ ê¸°ê°„): {path.name}, "
                f"ëŒ€ì‹  ìµœì‹  íŒŒì¼ ì‚¬ìš©: {latest.name}"
            )
            path = latest
        else:
            print(f"[FinBERT] ë‰´ìŠ¤ ìºì‹œ ì—†ìŒ: {path} (ê¸€ë¡œë²Œ ë§¤ì¹˜ë„ ì—†ìŒ)")
            return _zero_news_feats()

    try:
        items = json.loads(path.read_text(encoding="utf-8"))
    except Exception as e:
        print(f"[FinBERT] ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {path} ({e})")
        return _zero_news_feats()

    if not isinstance(items, list):
        print(f"[FinBERT] ìºì‹œ í˜•ì‹ ê²½ê³ (list ì•„ë‹˜): {path}")
        return _zero_news_feats()

    for it in items:
        for k in ("date", "published_date", "time", "pubDate"):
            if not isinstance(it.get(k), str):
                it[k] = ""

    print(f"[FinBERT] {len(items)}ê±´ ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ì‹œì‘... ({path.name})")
    try:
        scorer = FinBertScorer()
        scores = score_news_items(items, scorer=scorer, text_fields=text_fields)
        items_scored = attach_scores_to_items(items, scores)
        feats = compute_finbert_features(items_scored, asof_utc_date=to_date_utc)
    except Exception as e:
        print(f"[FinBERT] ê°ì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ â†’ 0 í”¼ì²˜ë¡œ ëŒ€ì²´: {e}")
        return _zero_news_feats()

    vol7 = feats.get("sentiment_volatility", {}).get("vol_7d", 0.0)
    feats["sentiment_volatility"] = {"vol_7d": vol7}

    print(
        f"[FinBERT] 7d_mean={feats['sentiment_summary']['mean_7d']:.3f} "
        f"7d_cnt={feats['news_count']['count_7d']}"
    )
    feats["has_news"] = True
    return feats


# ---------------------------------------------------------------
# ë³¸ì²´: SentimentalAgent
# ---------------------------------------------------------------
class SentimentalAgent(BaseAgent):  # type: ignore
    agent_id: str = "SentimentalAgent"

    def __init__(
        self,
        ticker: str | None = None,
        agent_id: str = "SentimentalAgent",
        *args,
        **kwargs,
    ):
        # âœ… BaseAgent í•œ ë²ˆë§Œ ì´ˆê¸°í™”
        agent_id = agent_id or "SentimentalAgent"
        super().__init__(agent_id=agent_id, ticker=ticker, *args, **kwargs)

        # í‹°ì»¤ ì •ë¦¬
        if not getattr(self, "ticker", None):
            self.ticker = ticker
        if self.ticker is None or str(self.ticker).strip() == "":
            raise ValueError("SentimentalAgent: ticker is None/empty")
        self.ticker = str(self.ticker).upper()
        setattr(self, "symbol", self.ticker)

        # ì„¤ì • ë¡œë“œ
        cfg = (agents_info or {}).get(self.agent_id, {})
        if not cfg:
            print("[WARN] agents_info['SentimentalAgent'] ê°€ ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©")
            cfg = {
                "window_size": 40,
                "hidden_dim": 128,
                "dropout": 0.2,
                "epochs": 30,
                "learning_rate": 1e-3,
                "batch_size": 64,
                "x_scaler": "StandardScaler",
                "y_scaler": "StandardScaler",
                "gamma": 0.3,
                "delta_limit": 0.05,
            }
        self.window_size = cfg.get("window_size", 40)
        self.hidden_dim = cfg.get("hidden_dim", 128)
        self.dropout = cfg.get("dropout", 0.2)

        self.model: Optional[nn.Module] = None
        self.feature_cols: List[str] = []  # ctxì—ì„œ ì¨ë¨¹ì„ ìš©ë„
        self.model_loaded: bool = False

        # âœ… ì´ˆê¸°í™” ì‹œ ìë™ ëª¨ë¸ ë¡œë“œ (ìˆìœ¼ë©´)
        try:
            self._load_model_if_exists()
        except Exception as e:
            # ì—¬ê¸°ì„œëŠ” ì¡°ìš©íˆ ë„˜ê¸°ê³ , ì‹¤ì œ ì˜ˆì¸¡ ì‹œ BaseAgent.predictì—ì„œ ë‹¤ì‹œ ì²˜ë¦¬
            print(f"[SentimentalAgent] ì´ˆê¸° ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜ˆì™¸ ë°œìƒ (ë¬´ì‹œí•˜ê³  ì§„í–‰): {e}")
            
    def run_dataset(self, save_dir: str | None = None) -> "StockData":
        """
        core.data_set.load_dataset()ë¥¼ í˜¸ì¶œí•´ì„œ
        (X, y, feature_cols)ë¥¼ ë¡œë“œí•˜ê³ ,
        BaseAgentì—ì„œ ì‚¬ìš©í•˜ëŠ” StockData í˜•íƒœë¡œ ê°ì‹¸ì„œ self.stockdataì— ì €ì¥.

        ë°˜í™˜ê°’: StockData ì¸ìŠ¤í„´ìŠ¤
        """

        # 1) save_dir ê¸°ë³¸ê°’ ì„¤ì •
        if save_dir is None:
            # config.agents.dir_info ì—ì„œ ì²˜ë¦¬ ê²½ë¡œë¥¼ ê´€ë¦¬í•˜ê³  ìˆë‹¤ë©´ ìš°ì„  ì‚¬ìš©
            # (í‚¤ ì´ë¦„ì€ í”„ë¡œì íŠ¸ ìƒí™©ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
            save_dir = (
                dir_info.get("processed_dir")
                or dir_info.get("data_processed")
                or "data/processed"
            )

        # 2) ê³µí†µ ë°ì´í„°ì…‹ ë¡œë” í˜¸ì¶œ
        # ì‹œê·¸ë‹ˆì²˜: load_dataset(ticker: str, agent_id: str, save_dir: str)
        X, y, feature_cols = load_dataset(
            ticker=self.ticker,
            agent_id=self.agent_id,
            save_dir=save_dir,
        )

        # 3) StockData ë˜í•‘ (positional ì¸ìë¡œë§Œ ì „ë‹¬)
        stock_data = StockData(X, y, feature_cols)

        # 4) BaseAgent ìª½ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì €ì¥
        self.stockdata = stock_data

        return stock_data


        # 4) BaseAgentì—ì„œ ì°¸ì¡°í•  ìˆ˜ ìˆë„ë¡ ì €ì¥
        self.stockdata = stock_data

        return stock_data

    # -----------------------------------------------------------
    # ëª¨ë¸ ê´€ë ¨ ìœ í‹¸
    # -----------------------------------------------------------
    def _build_model(self) -> nn.Module:
        """
        BaseAgent.pretrain()ì—ì„œ í˜¸ì¶œí•˜ëŠ” ëª¨ë¸ ìƒì„± í•¨ìˆ˜.
        SentimentalNet(LSTM) êµ¬ì¡°ë¥¼ ìƒì„±í•´ì„œ ë°˜í™˜.
        """
        try:
            X, y, cols = _load_dataset_compat(
                self.ticker,
                self.agent_id,
                window_size=self.window_size,
            )
        except Exception:
            # ë°ì´í„°ì…‹ì´ ì—†ë‹¤ë©´ ë¨¼ì € ìƒì„±
            _build_dataset_compat(
                self.ticker,
                self.agent_id,
                window_size=self.window_size,
            )
            X, y, cols = _load_dataset_compat(
                self.ticker,
                self.agent_id,
                window_size=self.window_size,
            )

        input_dim = X.shape[-1]
        self.feature_cols = list(cols)

        net = SentimentalNet(
            input_dim=input_dim,
            hidden_dim=self.hidden_dim,
            dropout=self.dropout,
        )
        return net

    def model_path(self) -> str:
        try:
            from config.agents import dir_info  # ì¬-import ë°©ì§€ìš©
            model_dir = dir_info["model_dir"]
        except Exception:
            model_dir = "models"

        ticker = getattr(self, "ticker", "UNKNOWN")
        agent_id = getattr(self, "agent_id", "SentimentalAgent")
        return os.path.join(model_dir, f"{ticker}_{agent_id}.pt")

    def _load_model_if_exists(self) -> None:
        """
        TechnicalAgent ì™€ ë™ì¼í•œ ì „ëµ:
        - model_path() ê¸°ì¤€ìœ¼ë¡œ íŒŒì¼ ì¡´ì¬ ì‹œ BaseAgent.load_model() ì‚¬ìš©
        - ì§ì ‘ torch.load / load_state_dict í˜¸ì¶œ âŒ
        """
        model_path = self.model_path()

        if not os.path.exists(model_path):
            # ëª¨ë¸ íŒŒì¼ ì—†ìœ¼ë©´ ì¡°ìš©íˆ íŒ¨ìŠ¤ (ê²½ê³  X)
            self.model_loaded = False
            return

        ok = False
        try:
            ok = self.load_model(model_path)
        except Exception as e:
            print(f"[SentimentalAgent] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            ok = False

        self.model_loaded = bool(ok)

    # -----------------------------------------------------------
    # MC Dropout ê¸°ë°˜ helper (ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€)
    # -----------------------------------------------------------
    @torch.inference_mode()
    def _mc_dropout_predict(self, x: torch.Tensor, T: int = 30) -> Tuple[float, float]:
        """
        x: [1, T, F]
        ë°˜í™˜: (mean_return, std_return)
        """
        if self.model is None:
            raise RuntimeError("model is None for MC Dropout")

        self.model.train()
        outs = []
        for _ in range(T):
            outs.append(self.model(x).detach())
        self.model.eval()

        y = torch.stack(outs, dim=0).squeeze(-1)
        mean = y.mean(dim=0)
        std = y.std(dim=0)
        return float(mean.squeeze().item()), float(std.squeeze().item())

    @torch.inference_mode()
    def _predict_next_close(self) -> Tuple[float, float, float, List[str]]:
        """
        LSTM ì¶œë ¥ì€ "ë‹¤ìŒë‚  ìˆ˜ìµë¥ (return)"ë¡œ ê°€ì •í•˜ê³ ,
        ë§ˆì§€ë§‰ ì¢…ê°€(last_close)ì— ê³±í•´ ë‹¤ìŒ ì¢…ê°€(pred_close)ë¥¼ ê³„ì‚°í•œë‹¤.
        ë°˜í™˜:
            pred_close      : ì˜ˆì¸¡ëœ ë‹¤ìŒ ì¢…ê°€ (price)
            uncertainty_std : ì˜ˆì¸¡ ìˆ˜ìµë¥ (return)ì˜ í‘œì¤€í¸ì°¨
            confidence      : 1 / (1 + uncertainty_std)
            cols            : feature ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
        """
        if not self.ticker:
            raise ValueError("ticker is None in _predict_next_close")

        try:
            X, y, cols = _load_dataset_compat(self.ticker, self.agent_id, window_size=self.window_size)
        except Exception:
            _build_dataset_compat(self.ticker, self.agent_id, window_size=self.window_size)
            X, y, cols = _load_dataset_compat(self.ticker, self.agent_id, window_size=self.window_size)

        # ë§ˆì§€ë§‰ ì¢…ê°€ ì¶”ì¶œ
        last_close_idx = cols.index("Close") if "Close" in cols else -1
        last_close = None
        if last_close_idx >= 0:
            last_close = float(X[-1, -1, last_close_idx])

        # last_closeê°€ ì—†ìœ¼ë©´ fallback ê°’ (ì´ ê²½ìš°ì—” ë„¤íŠ¸ì›Œí¬ ì¶œë ¥ì„ ê·¸ëŒ€ë¡œ priceì²˜ëŸ¼ ì·¨ê¸‰)
        if last_close is None or not (last_close == last_close):
            last_close = None

        # ëª¨ë¸ì´ ì—†ìœ¼ë©´: ë§ˆì§€ë§‰ ì¢…ê°€ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ìˆ˜ìµë¥  0 ê°€ì •)
        if self.model is None:
            pred_close = float(last_close) if last_close is not None else float("nan")
            uncertainty_std = 0.10  # return ê¸°ì¤€ ëŒ€ëµ 10% ì •ë„ë¡œ ê°€ì •
            confidence = 1.0 / (1.0 + uncertainty_std)
            return pred_close, uncertainty_std, confidence, cols

        # ëª¨ë¸ì´ ìˆìœ¼ë©´: ìˆ˜ìµë¥ (return) ì˜ˆì¸¡ í›„ priceë¡œ ë³€í™˜
        x_last = torch.tensor(X[-1:]).float()
        mean_ret, std_ret = self._mc_dropout_predict(x_last, T=30)

        if last_close is not None:
            pred_close = float(last_close * (1.0 + mean_ret))
        else:
            # ì–´ì©” ìˆ˜ ì—†ì´ return ê°’ì„ ê·¸ëŒ€ë¡œ priceì²˜ëŸ¼ ì‚¬ìš© (ì´ ê²½ìš°ëŠ” ê±°ì˜ ì—†ì„ ê²ƒ)
            pred_close = float(mean_ret)

        uncertainty_std = float(std_ret)  # "ìˆ˜ìµë¥ "ì˜ í‘œì¤€í¸ì°¨
        confidence = float(1.0 / (1.0 + max(1e-6, uncertainty_std)))

        # ë””ë²„ê¹…ìš© ë¡œê·¸ (í•„ìš”í•˜ë©´ ì£¼ì„ í•´ì œ)
        # print(f"[SentimentalAgent] last_close={last_close}, mean_ret={mean_ret}, pred_close={pred_close}")

        return pred_close, uncertainty_std, confidence, cols

    # -----------------------------------------------------------
    # ctx ìƒì„± (FinBERT + ê°€ê²© ìŠ¤ëƒ…ìƒ·)
    # -----------------------------------------------------------
    def build_ctx(self, asof_date_kst: Optional[str] = None) -> Dict[str, Any]:
        if asof_date_kst is None:
            asof_date_kst = datetime.now().strftime("%Y-%m-%d")

        pred_close, uncertainty_std, confidence, cols = self._predict_next_close()

        price_snapshot: Dict[str, Optional[float]] = {}
        try:
            X, _, cols2 = _load_dataset_compat(self.ticker, self.agent_id, window_size=self.window_size)
            last = X[-1, -1, :]
            snap_map = {c: float(v) for c, v in zip(cols2, last)}
            for k in ("Close", "Open", "High", "Low", "Volume", "returns"):
                if k in snap_map:
                    price_snapshot[k] = snap_map[k]
        except Exception:
            pass

        news_feats = build_finbert_news_features(
            self.ticker, asof_date_kst, base_dir=os.path.join("data", "raw", "news")
        )

        snapshot = {
            "asof_date": asof_date_kst,
            "last_price": price_snapshot.get("Close", np.nan),
            "currency": "USD",
            "window_size": self.window_size,
            "feature_cols_preview": [c for c in (cols or [])[:8]],
        }

        last_price = snapshot["last_price"]
        pred_return = float(pred_close / last_price - 1.0) if (last_price and last_price == last_price) else None

        feature_importance = {
            "sentiment_score": news_feats["sentiment_summary"]["mean_7d"],
            "sentiment_summary": news_feats["sentiment_summary"],
            "sentiment_volatility": {"vol_7d": news_feats["sentiment_volatility"].get("vol_7d", 0.0)},
            "trend_7d": news_feats["trend_7d"],
            "news_count": news_feats["news_count"],
            "has_news": news_feats.get("has_news", False),
            "price_snapshot": {
                "Close": price_snapshot.get("Close"),
                "Open": price_snapshot.get("Open"),
                "High": price_snapshot.get("High"),
                "Low": price_snapshot.get("Low"),
                "Volume": price_snapshot.get("Volume"),
                "ret_1d": None,
                "ret_5d": None,
                "ret_20d": None,
                "zscore_20d": None,
                "vol_change_5d": None,
            },
        }

        ctx = {
            "agent_id": self.agent_id,
            "ticker": self.ticker,
            "snapshot": snapshot,
            "prediction": {
                "pred_close": pred_close,
                "pred_return": pred_return,
                "uncertainty": {"std": uncertainty_std, "ci95": float(1.96 * uncertainty_std)},
                "confidence": confidence,
                "pred_next_close": pred_close,
            },
            "feature_importance": feature_importance,
        }
        return ctx

    # --------------------------
    # BaseAgent ê·œì•½ ì¶©ì¡±: Opinion í”„ë¡¬í”„íŠ¸
    # --------------------------
    def _build_messages_opinion(
        self,
        stock_data: "StockData",
        target: "Target",
    ):
        from prompts import OPINION_PROMPTS  # ìƒë‹¨ì— ì´ë¯¸ ìˆìœ¼ë©´ ìƒëµ ê°€ëŠ¥
        import json
        from typing import Dict, Any
        import numpy as np

        if stock_data is None:
            stock_data = self.stockdata

        ctx: Dict[str, Any] = {}

        # ê¸°ë³¸ ë©”íƒ€ ì •ë³´
        ctx["ticker"] = getattr(stock_data, "ticker", self.ticker)
        ctx["currency"] = getattr(stock_data, "currency", "USD")

        # í˜„ì¬ê°€ / ë‹¤ìŒë‚  ì˜ˆì¸¡ ì¢…ê°€
        last_close = getattr(stock_data, "last_price", None)
        ctx["last_close"] = last_close
        ctx["next_close"] = float(getattr(target, "next_close", None) or 0.0)

        # ì˜ˆìƒ ìˆ˜ìµë¥  (ë¹„ìœ¨)
        change_ratio = None
        if isinstance(last_close, (int, float)) and last_close not in (0, None):
            try:
                change_ratio = ctx["next_close"] / float(last_close) - 1.0
            except ZeroDivisionError:
                change_ratio = None
        ctx["change_ratio"] = change_ratio

        # ì˜ˆì¸¡ ë¶ˆí™•ì‹¤ì„± / ì‹ ë¢°ë„
        ctx["uncertainty_std"] = getattr(target, "uncertainty", None)
        ctx["confidence"] = getattr(target, "confidence", None)

        # --- SentimentalAgent ì „ìš© ìŠ¤ëƒ…ìƒ· ì£¼ì… ---
        # ì´ì „ ì½”ë“œ: snap = getattr(stock_data, "SentimentalAgent", {}) or {}
        # â†’ numpy ë°°ì—´ì¼ ë•Œ truth value ì—ëŸ¬ ë°œìƒí•˜ë¯€ë¡œ ìˆ˜ì •
        snap = getattr(stock_data, "SentimentalAgent", None)

        if isinstance(snap, dict):
            for k, v in snap.items():
                # numpy ë°°ì—´ì´ë©´ ë§ˆì§€ë§‰ ê°’ ìœ„ì£¼ë¡œ ì‚¬ìš©
                if isinstance(v, np.ndarray):
                    if v.ndim == 0:
                        ctx[k] = v.item()
                    elif v.size > 0:
                        flat = v.reshape(-1)
                        last_val = flat[-1]
                        try:
                            ctx[k] = float(last_val)
                        except Exception:
                            ctx[k] = last_val
                    else:
                        ctx[k] = None
                # ë¦¬ìŠ¤íŠ¸/íŠœí”Œì´ë©´ ë§ˆì§€ë§‰ ê°’ ì‚¬ìš©
                elif isinstance(v, (list, tuple)) and len(v) > 0:
                    ctx[k] = v[-1]
                else:
                    ctx[k] = v
        # dict ê°€ ì•„ë‹ˆë©´(ì˜ˆ: np.array ì§ì ‘ í• ë‹¹) ê·¸ëƒ¥ ë¬´ì‹œ

        # JSON ì§ë ¬í™”
        ctx_json = json.dumps(ctx, ensure_ascii=False, indent=2)

        # í”„ë¡¬í”„íŠ¸ ë¡œë”©
        prompts = OPINION_PROMPTS.get("SentimentalAgent", {}) if OPINION_PROMPTS else {}
        system_text = prompts.get("system", "ë„ˆëŠ” ê°ì„±/ë‰´ìŠ¤ ì¤‘ì‹¬ì˜ ë‹¨ê¸° ì£¼ê°€ ë¶„ì„ê°€ë‹¤.")
        user_tmpl = prompts.get(
            "user",
            "ctx(JSON):\n{context}\n\nìœ„ ctxë¥¼ ë°”íƒ•ìœ¼ë¡œ reasonì„ ìƒì„±í•˜ë¼.",
        )

        # í…œí”Œë¦¿ í¬ë§· ì•ˆì „ ì²˜ë¦¬
        try:
            user_text = user_tmpl.format(context=ctx_json)
        except KeyError:
            try:
                user_text = user_tmpl.format(ctx_json)
            except Exception:
                user_text = user_tmpl.replace("{context}", ctx_json)

        return system_text, user_text

    # --------------------------
    # BaseAgent ê·œì•½ ì¶©ì¡±: Rebuttal í”„ë¡¬í”„íŠ¸
    # --------------------------
    def _build_messages_rebuttal(self, *args, **kwargs) -> Tuple[str, str]:
        stock_data = args[0] if len(args) > 0 else kwargs.get("stock_data")
        target: Optional[Target] = args[1] if len(args) > 1 else kwargs.get("target")

        opponent = None
        for key in ("opponent", "opponent_opinion", "other_opinion", "other", "opinion"):
            if key in kwargs:
                opponent = kwargs[key]
                break
        if opponent is None and len(args) > 2:
            opponent = args[2]

        if isinstance(opponent, Opinion):
            opp_agent = getattr(opponent, "agent_id", "UnknownAgent")
            opp_reason = getattr(opponent, "reason", "")
        elif isinstance(opponent, dict):
            opp_agent = opponent.get("agent_id", "UnknownAgent")
            opp_reason = opponent.get("reason", "")
        else:
            opp_agent = "UnknownAgent"
            opp_reason = str(opponent) if opponent is not None else ""

        ctx = self.build_ctx()
        fi = ctx.get("feature_importance", {})
        sent = fi.get("sentiment_summary", {})
        vol7 = fi.get("sentiment_volatility", {}).get("vol_7d", None)
        trend7 = fi.get("trend_7d", None)
        news7 = fi.get("news_count", {}).get("count_7d", None)

        pred_close = float(target.next_close) if target else float(ctx["prediction"]["pred_next_close"])
        last_price = ctx.get("snapshot", {}).get("last_price")
        change_ratio = None
        if last_price and last_price == last_price and last_price != 0:
            change_ratio = pred_close / last_price - 1.0

        system_tmpl = None
        user_tmpl = None
        if REBUTTAL_PROMPTS and "SentimentalAgent" in REBUTTAL_PROMPTS:
            pp = REBUTTAL_PROMPTS["SentimentalAgent"]
            system_tmpl = pp.get("system")
            user_tmpl = pp.get("user")

        if not system_tmpl:
            system_tmpl = (
                "ë‹¹ì‹ ì€ ê°ì„± ê¸°ë°˜ ë‹¨ê¸° ì£¼ê°€ ë¶„ì„ê°€ë¡œì„œ ìƒëŒ€ ì˜ê²¬ì˜ ë…¼ë¦¬ì /ìˆ˜ì¹˜ì  í—ˆì ì„ ë¶„ì„í•´ ë°˜ë°•í•©ë‹ˆë‹¤. "
                "ê°ì„±ì§€í‘œ(í‰ê· , ì¶”ì„¸, ë³€ë™ì„±)ì™€ ë‰´ìŠ¤ ê°œìˆ˜, ì˜ˆì¸¡ì˜ ë¶ˆí™•ì‹¤ì„±ì„ ê·¼ê±°ë¡œ ì‚¼ë˜, "
                "í•©ë¦¬ì  í¬ì¸íŠ¸ëŠ” ì¸ì •í•˜ê³  í•µì‹¬ ìŸì  ìœ„ì£¼ë¡œ ê°„ê²°íˆ ë°˜ë°•í•˜ì„¸ìš”."
            )

        if not user_tmpl:
            user_tmpl = (
                "í‹°ì»¤: {ticker}\n"
                "ìƒëŒ€ ì—ì´ì „íŠ¸: {opp_agent}\n"
                "ìƒëŒ€ ì˜ê²¬:\n{opp_reason}\n\n"
                "ìš°ë¦¬ ì˜ˆì¸¡:\n- next_close: {pred_close}\n- ì˜ˆìƒ ë³€í™”ìœ¨(í˜„ì¬ê°€ ëŒ€ë¹„): {chg}\n"
                "ê°ì„± ê·¼ê±°:\n- mean7={mean7}, mean30={mean30}, pos7={pos7}, neg7={neg7}\n"
                "- vol7={vol7}, trend7={trend7}, news7={news7}\n\n"
                "ìš”ì²­: ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒëŒ€ ì˜ê²¬ì˜ ì•½ì  2~4ê°œë¥¼ ì¡°ëª©ì¡°ëª© ë°˜ë°•í•˜ì„¸ìš”. "
                "íŠ¹íˆ ê°ì„± ì¶”ì„¸/ë³€ë™ì„±, ë‰´ìŠ¤ ìˆ˜ì˜ ë§¥ë½, ì˜ˆì¸¡ ë¶ˆí™•ì‹¤ì„±(ë†’/ë‚®ìŒ)ì´ "
                "ìƒëŒ€ ì£¼ì¥ê³¼ ì–´ë–»ê²Œ ìƒì¶©/ë³´ì™„ë˜ëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì§€ì í•˜ì„¸ìš”."
            )

        user_text = user_tmpl.format(
            ticker=self.ticker,
            opp_agent=opp_agent,
            opp_reason=opp_reason if opp_reason else "(ìƒëŒ€ ì˜ê²¬ ë‚´ìš© ì—†ìŒ)",
            pred_close=f"{pred_close:.4f}",
            chg=("NA" if change_ratio is None else f"{change_ratio*100:.2f}%"),
            mean7=f"{sent.get('mean_7d', 0.0):.4f}",
            mean30=f"{sent.get('mean_30d', 0.0):.4f}",
            pos7=f"{sent.get('pos_ratio_7d', 0.0):.4f}",
            neg7=f"{sent.get('neg_ratio_7d', 0.0):.4f}",
            vol7=("NA" if vol7 is None else f"{vol7:.4f}"),
            trend7=("NA" if trend7 is None else f"{trend7:.4f}"),
            news7=("NA" if news7 is None else f"{news7}"),
        )
        return system_tmpl, user_text

    # --------------------------
    # BaseAgent ê·œì•½ ì¶©ì¡±: Revision í”„ë¡¬í”„íŠ¸
    # --------------------------
    def _build_messages_revision(self, *args, **kwargs) -> Tuple[str, str]:
        stock_data = args[0] if len(args) > 0 else kwargs.get("stock_data")
        target: Optional[Target] = args[1] if len(args) > 1 else kwargs.get("target")

        # previous opinion ì°¾ê¸°
        prev = None
        rebs = None
        for key in ("previous", "previous_opinion", "draft", "opinion"):
            if key in kwargs:
                prev = kwargs[key]
                break
        if prev is None and len(args) > 2:
            prev = args[2]

        # rebuttals ì°¾ê¸°
        for key in ("rebuttals", "replies", "responses"):
            if key in kwargs:
                rebs = kwargs[key]
                break
        if rebs is None and len(args) > 3:
            rebs = args[3]

        # Opinion/Dict/str â†’ text
        def _op_text(x: Union[Opinion, Dict[str, Any], str, None]) -> str:
            if isinstance(x, Opinion):
                return getattr(x, "reason", "")
            if isinstance(x, dict):
                return x.get("reason", "")
            return x or ""

        prev_reason = _op_text(prev)

        reb_texts: List[str] = []
        if isinstance(rebs, list):
            for r in rebs:
                reb_texts.append(_op_text(r))
        elif rebs is not None:
            reb_texts.append(_op_text(rebs))

        # ê³µí†µ ctx ë¡œë”©
        ctx = self.build_ctx()
        fi = ctx.get("feature_importance", {})
        sent = fi.get("sentiment_summary", {})
        vol7 = fi.get("sentiment_volatility", {}).get("vol_7d", None)
        trend7 = fi.get("trend_7d", None)
        news7 = fi.get("news_count", {}).get("count_7d", None)

        # ë¶ˆí™•ì‹¤ì„±/ì‹ ë¢°ë„ (prediction ë¸”ë¡ì—ì„œ ê°€ì ¸ì˜´)
        pred_info = ctx.get("prediction", {}) or {}
        unc_dict = pred_info.get("uncertainty", {}) or {}
        unc_std = unc_dict.get("std", None)
        confidence = pred_info.get("confidence", None)

        pred_close = float(target.next_close) if target else float(pred_info.get("pred_next_close"))
        last_price = ctx.get("snapshot", {}).get("last_price")
        change_ratio = None
        if last_price and last_price == last_price and last_price != 0:
            change_ratio = pred_close / last_price - 1.0

        # === ê°ì„±/ì˜ˆì¸¡ ìš”ì•½ context ë¬¸ìì—´ ìƒì„± ===
        context_parts: List[str] = []

        if last_price is not None:
            if change_ratio is not None:
                context_parts.append(
                    f"í˜„ì¬ ì£¼ê°€ëŠ” {last_price:.2f}ì´ê³ , ëª¨ë¸ì€ ë‹¤ìŒ ê±°ë˜ì¼ ì¢…ê°€ë¥¼ {pred_close:.2f}ë¡œ ì˜ˆì¸¡í–ˆìŠµë‹ˆë‹¤ "
                    f"(ë³€í™”ìœ¨ ì•½ {change_ratio*100:.2f}%)."
                )
            else:
                context_parts.append(
                    f"í˜„ì¬ ì£¼ê°€ëŠ” {last_price:.2f}ì´ë©°, ë‹¤ìŒ ê±°ë˜ì¼ ì¢…ê°€ ì˜ˆì¸¡ê°’ì€ {pred_close:.2f}ì…ë‹ˆë‹¤."
                )
        else:
            context_parts.append(
                f"ë‹¤ìŒ ê±°ë˜ì¼ ì¢…ê°€ ì˜ˆì¸¡ê°’ì€ {pred_close:.2f}ì…ë‹ˆë‹¤."
            )

        mean7 = sent.get("mean_7d", None)
        mean30 = sent.get("mean_30d", None)
        pos7 = sent.get("pos_ratio_7d", None)
        neg7 = sent.get("neg_ratio_7d", None)

        if mean7 is not None and mean30 is not None:
            context_parts.append(
                f"ìµœê·¼ 7ì¼ í‰ê·  ê°ì„± ì ìˆ˜ëŠ” {mean7:.3f}, ìµœê·¼ 30ì¼ í‰ê· ì€ {mean30:.3f}ì…ë‹ˆë‹¤."
            )
        if pos7 is not None and neg7 is not None:
            context_parts.append(
                f"ìµœê·¼ 7ì¼ ê¸°ì¤€ ê¸ì • ê¸°ì‚¬ ë¹„ìœ¨ì€ {pos7:.2%}, ë¶€ì • ê¸°ì‚¬ ë¹„ìœ¨ì€ {neg7:.2%}ì…ë‹ˆë‹¤."
            )
        if vol7 is not None:
            context_parts.append(
                f"ìµœê·¼ 7ì¼ ê°ì„± ì ìˆ˜ì˜ ë³€ë™ì„±(í‘œì¤€í¸ì°¨)ì€ {vol7:.3f}ì…ë‹ˆë‹¤."
            )
        if trend7 is not None:
            context_parts.append(
                f"ìµœê·¼ 7ì¼ ê°ì„± ì¶”ì„¸(íšŒê·€ ê¸°ìš¸ê¸°)ëŠ” {trend7:.4f}ì…ë‹ˆë‹¤."
            )
        if news7 is not None:
            context_parts.append(
                f"ìµœê·¼ 7ì¼ ë™ì•ˆ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ê°œìˆ˜ëŠ” {news7}ê±´ì…ë‹ˆë‹¤."
            )

        if unc_std is not None and confidence is not None:
            context_parts.append(
                f"Monte Carlo Dropout ê¸°ë°˜ ì˜ˆì¸¡ í‘œì¤€í¸ì°¨ëŠ” {unc_std:.4f}, ì‹ ë¢°ë„ëŠ” {confidence:.3f}ì…ë‹ˆë‹¤."
            )

        context_str = " ".join(context_parts) if context_parts else (
            "ìµœê·¼ ë‰´ìŠ¤ ê°ì„± ì ìˆ˜, ë³€ë™ì„±, ê¸Â·ë¶€ì • ë¹„ìœ¨, ë‰´ìŠ¤ ìˆ˜, ì˜ˆì¸¡ ë¶ˆí™•ì‹¤ì„± ë“±ì„ ì¢…í•©í•´ ë‹¨ê¸° ì£¼ê°€ë¥¼ í•´ì„í•©ë‹ˆë‹¤."
        )

        # ==========================
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„ íƒ
        # ==========================
        system_tmpl = None
        user_tmpl = None
        if REVISION_PROMPTS and "SentimentalAgent" in REVISION_PROMPTS:
            pp = REVISION_PROMPTS["SentimentalAgent"]
            system_tmpl = pp.get("system")
            user_tmpl = pp.get("user")

        if not system_tmpl:
            system_tmpl = (
                "ë‹¹ì‹ ì€ ê°ì„± ê¸°ë°˜ ë‹¨ê¸° ì£¼ê°€ ë¶„ì„ê°€ì…ë‹ˆë‹¤. "
                "ì´ˆì•ˆ ì˜ê²¬ê³¼ ë°˜ë°•ë“¤ì„ ê²€í† í•´ í•µì‹¬ë§Œ ë‚¨ê¸°ê³ , ë°ì´í„°ì— ê·¼ê±°í•´ ê²°ë¡ ì„ ë” ëª…í™•íˆ ë‹¤ë“¬ìŠµë‹ˆë‹¤. "
                "ë¶ˆí™•ì‹¤ì„±/ì‹ ë¢°ë„ í•´ì„ì„ í¬í•¨í•˜ì—¬ í•œ ë‹¨ê³„ ë” ê²¬ê³ í•œ ìµœì¢… ì˜ê²¬ìœ¼ë¡œ ìˆ˜ì •í•˜ì„¸ìš”."
            )

        if not user_tmpl:
            # ê¸°ë³¸ í…œí”Œë¦¿ì€ context ì—†ì´ ë™ì‘ (ê¸°ì¡´ í˜•ì‹ ìœ ì§€)
            user_tmpl = (
                "í‹°ì»¤: {ticker}\n"
                "ì´ˆì•ˆ ì˜ê²¬:\n{prev}\n\n"
                "ìˆ˜ì‹ í•œ ë°˜ë°• ìš”ì•½:\n{rebuts}\n\n"
                "ì—…ë°ì´íŠ¸ëœ ìˆ˜ì¹˜:\n- next_close: {pred_close}\n- ì˜ˆìƒ ë³€í™”ìœ¨: {chg}\n"
                "ê°ì„± ê·¼ê±° ìŠ¤ëƒ…ìƒ·:\n- mean7={mean7}, mean30={mean30}, pos7={pos7}, neg7={neg7}\n"
                "- vol7={vol7}, trend7={trend7}, news7={news7}\n\n"
                "ìš”ì²­: ì´ˆì•ˆì—ì„œ ê³¼ì¥/ì¤‘ë³µ/ì•½í•œ ê·¼ê±°ë¥¼ ì •ë¦¬í•˜ê³ , ê°•í•œ ê·¼ê±°(ê°ì„± ì¶”ì„¸, ë³€ë™ì„± ì•ˆì •/í™•ëŒ€, ë‰´ìŠ¤ ìˆ˜ ë³€í™”)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ "
                "ìµœì¢… ì˜ê²¬ì„ 3~5ë¬¸ì¥ìœ¼ë¡œ ì¬ì‘ì„±í•˜ì„¸ìš”. ë¶ˆí™•ì‹¤ì„±(í‘œì¤€í¸ì°¨)/ì‹ ë¢°ë„ í•´ì„ì„ í•¨ê»˜ ì œì‹œí•˜ì„¸ìš”."
            )

        rebuts_joined = "- " + "\n- ".join([s for s in reb_texts if s]) if reb_texts else "(ë°˜ë°• ì—†ìŒ)"

        # ğŸ”´ í•µì‹¬: contextë¥¼ í•­ìƒ í•¨ê»˜ ë„˜ê²¨ì¤Œ
        user_text = user_tmpl.format(
            ticker=self.ticker,
            prev=prev_reason if prev_reason else "(ì´ˆì•ˆ ì—†ìŒ)",
            rebuts=rebuts_joined,
            pred_close=f"{pred_close:.4f}",
            chg=("NA" if change_ratio is None else f"{change_ratio*100:.2f}%"),
            mean7=("NA" if mean7 is None else f"{mean7:.4f}"),
            mean30=("NA" if mean30 is None else f"{mean30:.4f}"),
            pos7=("NA" if pos7 is None else f"{pos7:.4f}"),
            neg7=("NA" if neg7 is None else f"{neg7:.4f}"),
            vol7=("NA" if vol7 is None else f"{vol7:.4f}"),
            trend7=("NA" if trend7 is None else f"{trend7:.4f}"),
            news7=("NA" if news7 is None else f"{news7}"),
            context=context_str,  # âœ… REVISION_PROMPTSì—ì„œ {context}ë¥¼ ì¨ë„ ì•ˆì „í•˜ê²Œ
        )
        return system_tmpl, user_text

    # Opinion ìƒì„± (legacy ê²½ë¡œ)
    # --------------------------
    def get_opinion(self, idx: int = 0, ticker: Optional[str] = None) -> Opinion:
        if ticker and ticker != self.ticker:
            self.ticker = str(ticker).upper()

        pred_close, uncertainty_std, confidence, _ = self._predict_next_close()
        target = Target(
            next_close=float(pred_close),
            uncertainty=float(uncertainty_std),
            confidence=float(confidence),
        )

        try:
            if hasattr(self, "reviewer_draft"):
                op = self.reviewer_draft(getattr(self, "stockdata", None), target)
                return op
        except Exception as e:
            print("[SentimentalAgent] reviewer_draft ì‚¬ìš© ì‹¤íŒ¨:", e)

        ctx = self.build_ctx()
        fi = ctx["feature_importance"]
        sent = fi["sentiment_summary"]

        reason = (
            f"{self.ticker}ì˜ ìµœê·¼ 7ì¼ ê°ì„± í‰ê· ì€ {sent['mean_7d']:.3f}ì´ë©° "
            f"ë‰´ìŠ¤ ê°œìˆ˜(7d)ëŠ” {fi['news_count']['count_7d']}ê±´ì…ë‹ˆë‹¤. "
            f"ê°ì„± ë³€ë™ì„±(vol_7d)={fi['sentiment_volatility']['vol_7d']:.3f}, "
            f"ê°ì„± ì¶”ì„¸(trend_7d)={fi['trend_7d']:.3f}ì…ë‹ˆë‹¤."
        )

        return Opinion(
            agent_id=self.agent_id,
            target=target,
            reason=reason,
        )
