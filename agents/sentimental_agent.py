# agents/sentimental_agent.py
# ===============================================================
# SentimentalAgent: ê°ì„±(ë‰´ìŠ¤/í…ìŠ¤íŠ¸) + LSTM ê¸°ë°˜ ì˜ˆì¸¡ ì—ì´ì „íŠ¸
#  - BaseAgent í˜¸í™˜ (reviewer_* ë¡œì§ì€ BaseAgent êµ¬í˜„ ì‚¬ìš©)
#  - ë°ì´í„°ëŠ” core/data_set.pyì—ì„œ ë§Œë“  CSVë¥¼ ë¡œë“œ
#  - FinBERT ê¸°ë°˜ ë‰´ìŠ¤ ê°ì„± í”¼ì²˜ë¥¼ ctx.feature_importanceì— ì£¼ì…
#  - ë°˜ì˜ì‚¬í•­:
#      1) super().__init__(agent_id, ticker) ìˆœì„œ ê³ ì • + ticker ê°€ë“œ/ì •ê·œí™”
#      2) load_dataset/build_dataset ì‹œê·¸ë‹ˆì²˜ í˜¸í™˜ ìœ í‹¸ ì¶”ê°€
#      3) finbert_utils ë‹¨ì¼ ê²½ë¡œ(core.finbert_utils)ë¡œ ê³ ì •
#      4) ë‰´ìŠ¤ ìºì‹œ íŒŒì¼ í´ë°±(glob ìµœì‹  íŒŒì¼ ì„ íƒ) ì¶”ê°€
#      5) ëª¨ë¸ state_dict ì–¸ë©(model_state_dict) + strict=False ë¡œë“œ
#      6) Target ìƒì„± ì‹œ 3ê°œ ì¸ìë§Œ ì „ë‹¬
#      7) MC Dropoutë¡œ uncertainty/confidence ì‹¤ì œ ê³„ì‚°
#      8) sentiment_vol_30 ë…¸ì¶œ ì œê±° (vol_7dë§Œ ì œê³µ)
# ===============================================================

from __future__ import annotations
import os
import json
from dataclasses import dataclass
from typing import Optional, Tuple, Dict, Any, List

from pathlib import Path
from datetime import datetime, timedelta, date

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

# ---------------------------
# í”„ë¡œì íŠ¸ ì˜ì¡´ ëª¨ë“ˆ (ì•ˆì „ import)
# ---------------------------
try:
    from agents.base_agent import BaseAgent, StockData, Target, Opinion  # type: ignore
except Exception:
    BaseAgent = object  # type: ignore

    @dataclass
    class Target:  # type: ignore
        next_close: float
        uncertainty: float
        confidence: float

    @dataclass
    class Opinion:  # type: ignore
        agent_id: str
        target: Target
        reason: str

try:
    from config.agents import agents_info, dir_info  # type: ignore
except Exception:
    agents_info = {
        "SentimentalAgent": {
            "window_size": 40,
            "hidden_dim": 128,
            "dropout": 0.2,
            "epochs": 30,
            "learning_rate": 1e-3,
            "batch_size": 64,
            "x_scaler": "StandardScaler",
            "y_scaler": "StandardScaler",
            "gamma": 0.3,
            "delta_limit": 0.05,
        }
    }
    dir_info = {
        "data_dir": "data",
        "model_dir": "models",
        "scaler_dir": os.path.join("models", "scalers"),
    }

try:
    from core.data_set import build_dataset, load_dataset  # type: ignore
except Exception:
    build_dataset = None  # type: ignore
    def load_dataset(*args, **kwargs):  # type: ignore
        raise RuntimeError("core.data_set.load_dataset ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# í”„ë¡¬í”„íŠ¸ ì„¸íŠ¸ (ìˆëŠ” ê²½ìš° ì‚¬ìš©)
try:
    from prompts import OPINION_PROMPTS, REBUTTAL_PROMPTS, REVISION_PROMPTS  # type: ignore
except Exception:
    OPINION_PROMPTS = REBUTTAL_PROMPTS = REVISION_PROMPTS = None  # type: ignore

# FinBERT ìœ í‹¸ (ë‹¨ì¼ ê²½ë¡œë¡œ ê³ ì •)
from core.finbert_utils import (
    FinBertScorer,
    score_news_items,
    attach_scores_to_items,
    compute_finbert_features,
)

# ---------------------------------------------------------------
# ëª¨ë¸ ì •ì˜: LSTM + Dropout (MC Dropout ì§€ì›)
# ---------------------------------------------------------------
class SentimentalNet(nn.Module):
    def __init__(self, input_dim: int, hidden_dim: int = 128, dropout: float = 0.2):
        super().__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=1, batch_first=True)
        self.drop = nn.Dropout(dropout)
        self.fc = nn.Linear(hidden_dim, 1)

    def forward(self, x):
        # x: [B, T, F]
        out, _ = self.lstm(x)
        out = self.drop(out[:, -1, :])
        out = self.fc(out)  # [B, 1]
        return out


# ---------------------------------------------------------------
# load/build dataset ì‹œê·¸ë‹ˆì²˜ í˜¸í™˜ ìœ í‹¸
# ---------------------------------------------------------------
def _load_dataset_compat(ticker: str, agent_id: str, window_size: Optional[int] = None):
    """
    load_dataset ì‹œê·¸ë‹ˆì²˜ê°€ íŒ€ë³„ë¡œ ë‹¤ë¥¸ ê²½ìš°ë¥¼ í˜¸í™˜.
    ì‹œë„ ìˆœì„œ:
      1) load_dataset(ticker, agent_id, window_size=..)
      2) load_dataset(ticker, agent_id, seq_len=..)
      3) load_dataset(ticker, agent_id)
    """
    if not ticker:
        raise ValueError("load_dataset_compat: empty ticker")
    try:
        return load_dataset(ticker, agent_id, window_size=window_size)  # type: ignore
    except TypeError:
        pass
    try:
        return load_dataset(ticker, agent_id, seq_len=window_size)  # type: ignore
    except TypeError:
        pass
    return load_dataset(ticker, agent_id)  # type: ignore


def _build_dataset_compat(ticker: str, agent_id: str, window_size: Optional[int] = None):
    """
    build_dataset ì‹œê·¸ë‹ˆì²˜ í˜¸í™˜: window_size/seq_len/ë¬´ì¸ì ìˆœìœ¼ë¡œ ì‹œë„.
    """
    if not ticker:
        raise ValueError("build_dataset_compat: empty ticker")
    if build_dataset is None:
        return
    try:
        return build_dataset(ticker, agent_id, window_size=window_size)  # type: ignore
    except TypeError:
        pass
    try:
        return build_dataset(ticker, agent_id, seq_len=window_size)  # type: ignore
    except TypeError:
        pass
    return build_dataset(ticker, agent_id)  # type: ignore


# ---------------------------------------------------------------
# ìœ í‹¸: ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸ê°€ ì €ì¥í•œ ë‰´ìŠ¤ ìºì‹œë¥¼ ì½ì–´ FinBERT ì§‘ê³„ í”¼ì²˜ ìƒì„±
# ---------------------------------------------------------------
def _utc_from_kst_asof(asof_kst: str, lookback_days: int = 40) -> Tuple[str, str, date]:
    """
    asof_kst(YYYY-MM-DD) ê¸°ì¤€ìœ¼ë¡œ UTC ë‚ ì§œ ë²”ìœ„ë¥¼ ìƒì„±
      - ë¯¸ë˜ ì»·ì˜¤í”„ ë°©ì§€ ìœ„í•´ to_utc = (kst-9h).date() - 1day
      - from_utc = to_utc - lookback_days
    ë°˜í™˜: (from_utc_str, to_utc_str, to_utc_date)
    """
    kst_dt = datetime.fromisoformat(asof_kst)
    utc_today = (kst_dt - timedelta(hours=9)).date()
    to_utc_date = utc_today - timedelta(days=1)
    from_utc_date = to_utc_date - timedelta(days=lookback_days)
    return from_utc_date.isoformat(), to_utc_date.isoformat(), to_utc_date


def build_finbert_news_features(
    ticker: str,
    asof_kst: str,
    base_dir: str = "data/raw/news",
    text_fields: Tuple[str, ...] = ("title", "content", "text", "summary"),
) -> Dict[str, Any]:
    """
    ì €ì¥ëœ ë‰´ìŠ¤ JSONì„ ì½ê³  FinBERTë¡œ ê°ì„± ì ìˆ˜ ê³„ì‚° í›„ ìš”ì•½ í”¼ì²˜ ë°˜í™˜
    - diagnostics_news.pyê°€ ë§Œë“¤ì–´ë‘” íŒŒì¼ëª… í¬ë§·ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    - ìºì‹œ ë¯¸ì¡´ì¬ ì‹œ í•´ë‹¹ í‹°ì»¤ì˜ ìµœì‹  íŒŒì¼ë¡œ í´ë°±
    """
    fr, to, to_date_utc = _utc_from_kst_asof(asof_kst, lookback_days=40)
    symbol_us = f"{ticker}.US"
    base = Path(base_dir)
    path = base / f"{symbol_us}_{fr}_{to}.json"

    if not path.exists():
        # í´ë°±: ë™ì¼ í‹°ì»¤ì˜ ìµœì‹  íŒŒì¼ ìë™ ì„ íƒ
        cands = sorted(base.glob(f"{symbol_us}_*.json"))
        if cands:
            latest = cands[-1]
            print(f"[FinBERT] ìºì‹œ ë¯¸ë°œê²¬ â†’ ìµœì‹  íŒŒì¼ ì‚¬ìš©: {latest.name}")
            path = latest
        else:
            print(f"[FinBERT] ë‰´ìŠ¤ ìºì‹œ ì—†ìŒ: {path}")
            return {
                "sentiment_summary": {"mean_7d": 0.0, "mean_30d": 0.0, "pos_ratio_7d": 0.0, "neg_ratio_7d": 0.0},
                "sentiment_volatility": {"vol_7d": 0.0},
                "news_count": {"count_1d": 0, "count_7d": 0},
                "trend_7d": 0.0,
                "has_news": False,
            }

    items = json.loads(path.read_text(encoding="utf-8"))
    if not isinstance(items, list):
        print(f"[FinBERT] ìºì‹œ í˜•ì‹ ê²½ê³ (list ì•„ë‹˜): {path}")
        return {
            "sentiment_summary": {"mean_7d": 0.0, "mean_30d": 0.0, "pos_ratio_7d": 0.0, "neg_ratio_7d": 0.0},
            "sentiment_volatility": {"vol_7d": 0.0},
            "news_count": {"count_1d": 0, "count_7d": 0},
            "trend_7d": 0.0,
            "has_news": False,
        }

    # ë‚ ì§œ í•„ë“œ ë¹„ë¬¸ì ë°©ì–´ (ê³µê¸‰ì ë³€í˜•/None ë°©ì§€)
    for it in items:
        for k in ("date", "published_date", "time", "pubDate"):
            if not isinstance(it.get(k), str):
                it[k] = ""

    print(f"[FinBERT] {len(items)}ê±´ ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ì‹œì‘... ({path.name})")
    scorer = FinBertScorer()
    scores = score_news_items(items, scorer=scorer, text_fields=text_fields)
    items_scored = attach_scores_to_items(items, scores)

    feats = compute_finbert_features(items_scored, asof_utc_date=to_date_utc)

    # â–¶ vol_30dëŠ” ë²„ë¦¬ê³  vol_7dë§Œ ë‚¨ê¹€
    vol7 = feats.get("sentiment_volatility", {}).get("vol_7d", 0.0)
    feats["sentiment_volatility"] = {"vol_7d": vol7}

    print(
        f"[FinBERT] 7d_mean={feats['sentiment_summary']['mean_7d']:.3f} "
        f"7d_cnt={feats['news_count']['count_7d']}"
    )
    return feats


# ---------------------------------------------------------------
# ë³¸ì²´: SentimentalAgent
# ---------------------------------------------------------------
class SentimentalAgent(BaseAgent):  # type: ignore
    agent_id: str = "SentimentalAgent"

    def __init__(self, ticker: str, **kwargs):
        # âœ… BaseAgent.__init__(agent_id, ticker, ...) ìˆœì„œ
        try:
            super().__init__(self.agent_id, ticker, **kwargs)  # type: ignore
        except TypeError:
            super().__init__(agent_id=self.agent_id, ticker=ticker, **kwargs)  # type: ignore

        # ğŸ”§ ticker ê°€ë“œ/ì •ê·œí™”
        if not getattr(self, "ticker", None):
            self.ticker = ticker
        if self.ticker is None or str(self.ticker).strip() == "":
            raise ValueError("SentimentalAgent: ticker is None/empty")
        self.ticker = str(self.ticker).upper()
        setattr(self, "symbol", self.ticker)

        cfg = (agents_info or {}).get(self.agent_id, {})
        if not cfg:
            print("[WARN] agents_info['SentimentalAgent'] ê°€ ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©")
            cfg = {
                "window_size": 40,
                "hidden_dim": 128,
                "dropout": 0.2,
                "epochs": 30,
                "learning_rate": 1e-3,
                "batch_size": 64,
                "x_scaler": "StandardScaler",
                "y_scaler": "StandardScaler",
                "gamma": 0.3,
                "delta_limit": 0.05,
            }
        self.window_size = cfg.get("window_size", 40)
        self.hidden_dim = cfg.get("hidden_dim", 128)
        self.dropout = cfg.get("dropout", 0.2)

        # ëª¨ë¸ ë¡œë“œ (ë°ì´í„°ì…‹ ë¡œë“œ í›„ input_dim íŒŒì•…)
        self.model: Optional[nn.Module] = None
        try:
            self._load_model_if_exists()
        except Exception as e:
            print("[SentimentalAgent] ëª¨ë¸ ë¡œë“œ ìŠ¤í‚µ:", e)

    # --------------------------
    # ëª¨ë¸ ë¡œë“œ/ì„¸ì´ë¸Œ
    # --------------------------
    def model_path(self) -> str:
        mdir = dir_info.get("model_dir", "models")
        Path(mdir).mkdir(parents=True, exist_ok=True)
        return os.path.join(mdir, f"{self.ticker}_{self.agent_id}.pt")

    def _load_model_if_exists(self):
        p = self.model_path()
        if os.path.exists(p):
            if not self.ticker:
                raise ValueError("ticker is None in _load_model_if_exists")

            try:
                X, y, cols = _load_dataset_compat(self.ticker, self.agent_id, window_size=self.window_size)
            except Exception:
                _build_dataset_compat(self.ticker, self.agent_id, window_size=self.window_size)
                X, y, cols = _load_dataset_compat(self.ticker, self.agent_id, window_size=self.window_size)

            input_dim = X.shape[-1]
            net = SentimentalNet(input_dim=input_dim, hidden_dim=self.hidden_dim, dropout=self.dropout)

            sd = torch.load(p, map_location="cpu")
            if isinstance(sd, dict) and "model_state_dict" in sd:
                sd = sd["model_state_dict"]
            net.load_state_dict(sd, strict=False)  # ê´€ìš© ë¡œë“œ
            net.eval()
            self.model = net
            print(f"âœ… {self.ticker} {self.agent_id} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({p})")

    # --------------------------
    # MC Dropout ìœ í‹¸
    # --------------------------
    @torch.inference_mode()
    def _mc_dropout_predict(self, x: torch.Tensor, T: int = 30) -> Tuple[float, float]:
        """
        MC Dropoutë¡œ ì˜ˆì¸¡ ë¶„í¬(mean, std) ì¶”ì •
        - ëª¨ë¸ì€ dropout ë ˆì´ì–´ë¥¼ í¬í•¨í•´ì•¼ í•¨
        """
        if self.model is None:
            raise RuntimeError("model is None for MC Dropout")

        self.model.train()  # Dropout í™œì„±í™”
        outs = []
        for _ in range(T):
            outs.append(self.model(x).detach())  # [B, 1]
        self.model.eval()

        y = torch.stack(outs, dim=0).squeeze(-1)  # [T, B]
        mean = y.mean(dim=0)                      # [B]
        std = y.std(dim=0)                        # [B]
        return float(mean.squeeze().item()), float(std.squeeze().item())

    # --------------------------
    # ì˜ˆì¸¡ (MC Dropout ì‚¬ìš©)
    # --------------------------
    @torch.inference_mode()
    def _predict_next_close(self) -> Tuple[float, float, float, List[str]]:
        """
        ë°˜í™˜: (pred_close, uncertainty_std, confidence, feature_cols)
        """
        if not self.ticker:
            raise ValueError("ticker is None in _predict_next_close")

        try:
            X, y, cols = _load_dataset_compat(self.ticker, self.agent_id, window_size=self.window_size)
        except Exception:
            _build_dataset_compat(self.ticker, self.agent_id, window_size=self.window_size)
            X, y, cols = _load_dataset_compat(self.ticker, self.agent_id, window_size=self.window_size)

        # ëª¨ë¸ ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ close í´ë°±
        last_close_idx = cols.index("Close") if "Close" in cols else -1
        fallback = float(X[-1, -1, last_close_idx]) if last_close_idx >= 0 else float("nan")

        if self.model is None:
            pred_close = fallback
            uncertainty_std = 0.10
            confidence = 1.0 / (1.0 + uncertainty_std)
            return pred_close, uncertainty_std, confidence, cols

        x_last = torch.tensor(X[-1:]).float()  # [1, T, F]

        # â–¶ MC Dropoutë¡œ mean/std ì¶”ì •
        pred_close, uncertainty_std = self._mc_dropout_predict(x_last, T=30)

        # ê°„ë‹¨ confidence ìŠ¤ì¼€ì¼ë§ (0~1): stdê°€ ì‘ì„ìˆ˜ë¡ â†‘
        confidence = float(1.0 / (1.0 + max(1e-6, uncertainty_std)))

        return pred_close, uncertainty_std, confidence, cols

    # --------------------------
    # ctx ìƒì„±: ì—¬ê¸°ì„œ FinBERT ë‰´ìŠ¤ í”¼ì²˜ë¥¼ ì£¼ì…í•œë‹¤
    # --------------------------
    def build_ctx(self, asof_date_kst: Optional[str] = None) -> Dict[str, Any]:
        if asof_date_kst is None:
            # KST ê¸°ì¤€ "ì˜¤ëŠ˜" ë‚ ì§œ ë¬¸ìì—´
            asof_date_kst = datetime.now().strftime("%Y-%m-%d")

        pred_close, uncertainty_std, confidence, cols = self._predict_next_close()

        # ê°€ê²© ìŠ¤ëƒ…ìƒ·(ê°€ëŠ¥í•œ ë²”ìœ„ì—ì„œ ìˆ˜ì§‘)
        price_snapshot: Dict[str, Optional[float]] = {}
        try:
            X, _, cols2 = _load_dataset_compat(self.ticker, self.agent_id, window_size=self.window_size)
            last = X[-1, -1, :]
            snap_map = {c: float(v) for c, v in zip(cols2, last)}
            for k in ("Close", "Open", "High", "Low", "Volume", "returns"):
                if k in snap_map:
                    price_snapshot[k] = snap_map[k]
        except Exception:
            pass

        # FinBERT ë‰´ìŠ¤ í”¼ì²˜
        news_feats = build_finbert_news_features(
            self.ticker, asof_date_kst, base_dir=os.path.join("data", "raw", "news")
        )

        # ìŠ¤ëƒ…ìƒ· ìƒë‹¨ë¶€
        snapshot = {
            "asof_date": asof_date_kst,
            "last_price": price_snapshot.get("Close", np.nan),
            "currency": "USD",
            "window_size": self.window_size,
            "feature_cols_preview": [c for c in (cols or [])[:8]],
        }

        last_price = snapshot["last_price"]
        pred_return = float(pred_close / last_price - 1.0) if (last_price and last_price == last_price) else None

        feature_importance = {
            "sentiment_score": news_feats["sentiment_summary"]["mean_7d"],
            "sentiment_summary": news_feats["sentiment_summary"],
            "sentiment_volatility": {"vol_7d": news_feats["sentiment_volatility"].get("vol_7d", 0.0)},
            "trend_7d": news_feats["trend_7d"],
            "news_count": news_feats["news_count"],
            "has_news": news_feats.get("has_news", False),
            "price_snapshot": {
                "Close": price_snapshot.get("Close"),
                "Open": price_snapshot.get("Open"),
                "High": price_snapshot.get("High"),
                "Low": price_snapshot.get("Low"),
                "Volume": price_snapshot.get("Volume"),
                "ret_1d": None,
                "ret_5d": None,
                "ret_20d": None,
                "zscore_20d": None,
                "vol_change_5d": None,
            },
        }

        ctx = {
            "agent_id": self.agent_id,
            "ticker": self.ticker,
            "snapshot": snapshot,
            "prediction": {
                "pred_close": pred_close,
                "pred_return": pred_return,
                "uncertainty": {
                    "std": uncertainty_std,
                    "ci95": float(1.96 * uncertainty_std),
                },
                "confidence": confidence,
                "pred_next_close": pred_close,
            },
            "feature_importance": feature_importance,
        }
        return ctx

    # --------------------------
    # Opinion ìƒì„± (BaseAgent ê·œì•½ì„ ë”°ë¥´ê±°ë‚˜, í´ë°± ì œê³µ)
    # --------------------------
    def get_opinion(self, idx: int = 0, ticker: Optional[str] = None) -> Opinion:  # type: ignore[override]
        """
        DebateAgentì—ì„œ í˜¸ì¶œë˜ëŠ” ì§„ì…ì ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ.
        - ê°€ëŠ¥í•œ í•œ BaseAgentì˜ LLM í”„ë¡¬í”„íŠ¸ íë¦„ì„ ì‚¬ìš©
        - ì—†ë‹¤ë©´ ê°„ë‹¨ reasonì„ ë§Œë“¤ì–´ Opinion ë°˜í™˜
        """
        _ = idx
        if ticker and ticker != self.ticker:
            self.ticker = str(ticker).upper()

        ctx = self.build_ctx()

        # BaseAgentê°€ LLM ê¸°ë°˜ ì˜ê²¬ ìƒì„±ê¸°ë¥¼ ì œê³µí•œë‹¤ë©´ ì‚¬ìš©
        try:
            if hasattr(self, "reviewer_opinion"):
                op: Opinion = self.reviewer_opinion(ctx=ctx)  # type: ignore
                return op
        except Exception as e:
            print("[SentimentalAgent] reviewer_opinion ì‚¬ìš© ì‹¤íŒ¨:", e)

        # í´ë°±: ê°„ë‹¨ reason êµ¬ì„±
        fi = ctx["feature_importance"]
        sent = fi["sentiment_summary"]
        reason = (
            f"{self.ticker}ì˜ ìµœê·¼ 7ì¼ ê°ì„± í‰ê· ì€ {sent['mean_7d']:.3f}ì´ë©° "
            f"ë‰´ìŠ¤ ê°œìˆ˜(7d)ëŠ” {fi['news_count']['count_7d']}ê±´ì…ë‹ˆë‹¤. "
            f"ê°ì„± ë³€ë™ì„±(vol_7d)={fi['sentiment_volatility']['vol_7d']:.3f}, "
            f"ê°ì„± ì¶”ì„¸(trend_7d)={fi['trend_7d']:.3f}ì…ë‹ˆë‹¤."
        )
        target = Target(
            next_close=float(ctx["prediction"]["pred_next_close"]),
            uncertainty=float(ctx["prediction"]["uncertainty"]["std"]),
            confidence=float(ctx["prediction"]["confidence"]),
        )
        return Opinion(agent_id=self.agent_id, target=target, reason=reason)
